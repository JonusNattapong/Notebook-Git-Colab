


#### **1. QLoRA Fine-Tuning Pipeline**
- **GitHub**: [WeixuanJiang/Qlora-Fine-Tuning-Pipeline](https://github.com/WeixuanJiang/Qlora-Fine-Tuning-Pipeline )  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน QLoRA (Quantized Low-Rank Adaptation) พร้อม Script และ Configuration Files สำหรับการ Fine-Tuning และ Inference.  
    - **Script ตัวอย่าง**:  
      - [Train Script](https://github.com/WeixuanJiang/Qlora-Fine-Tuning-Pipeline/blob/main/scripts/run_training.bat )  
      - [Merge Script](https://github.com/WeixuanJiang/Qlora-Fine-Tuning-Pipeline/blob/main/scripts/run_merge_multiple_loras.bat )  

#### **2. LLM Fine-Tuning for Programming Queries**
- **GitHub**: [Avani1297/LLM-Fine-Tuning-Project-for-Programming-Queries](https://github.com/Avani1297/LLM-Fine-Tuning-Project-for-Programming-Queries )  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs บน Stack Overflow datasets ผ่าน Hugging Face และ Vast.ai.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/Avani1297/LLM-Fine-Tuning-Project-for-Programming-Queries/blob/main/train.py )  

#### **3. FLUX.1 Fine-Tuning**
- **Hugging Face**: [black-forest-labs/FLUX.1-dev](https://huggingface.co/black-forest-labs/FLUX.1-dev/discussions/196 )  
  - **รายละเอียด**: วิธีการ Fine-Tuning FLUX.1 ผ่าน AI Toolkit.  
    - **Script ตัวอย่าง**:  
      - [Train Script](https://github.com/ostris/ai-toolkit/blob/main/train_lora_flux_24gb.py )  

#### **4. Llama-2 Fine-Tuning with QLoRA**
- **GitHub**: [mert-delibalta/llama2-fine-tune-qlora](https://github.com/mert-delibalta/llama2-fine-tune-qlora )  
  - **รายละเอียด**: วิธีการ Fine-Tuning Llama-2 ผ่าน QLoRA พร้อม Script และ Configuration Files.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/mert-delibalta/llama2-fine-tune-qlora/blob/main/train.py )  

#### **5. BERT Fine-Tuning with NVIDIA NGC**
- **NVIDIA NGC**: [Fine-Tune and Optimize BERT](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/bert_workshop )  
  - **รายละเอียด**: วิธีการ Fine-Tuning BERT ผ่าน NVIDIA NGC.  
    - **Script ตัวอย่าง**:  
      - [Training Notebook](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/bert_workshop )  

#### **6. Llama2 Fine-Tuning with QLoRA (torchtune)**
- **PyTorch**: [Fine-Tuning Llama2 with QLoRA](https://pytorch.org/torchtune/stable/tutorials/qlora_finetune.html )  
  - **รายละเอียด**: วิธีการ Fine-Tuning Llama2 ผ่าน QLoRA พร้อม Script และ Configuration Files.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Command](https://pytorch.org/torchtune/stable/tutorials/qlora_finetune.html )  

---

### แหล่งเรียนรู้เพิ่มเติม
- **QLoRA Fine-Tuning Pipeline**: [WeixuanJiang/Qlora-Fine-Tuning-Pipeline](https://github.com/WeixuanJiang/Qlora-Fine-Tuning-Pipeline )   
- **LLM Fine-Tuning for Programming Queries**: [Avani1297/LLM-Fine-Tuning-Project-for-Programming-Queries](https://github.com/Avani1297/LLM-Fine-Tuning-Project-for-Programming-Queries )   
- **FLUX.1 Fine-Tuning**: [black-forest-labs/FLUX.1-dev](https://huggingface.co/black-forest-labs/FLUX.1-dev/discussions/196 )   
- **Llama-2 Fine-Tuning with QLoRA**: [mert-delibalta/llama2-fine-tune-qlora](https://github.com/mert-delibalta/llama2-fine-tune-qlora )   
- **BERT Fine-Tuning with NVIDIA NGC**: [Fine-Tune and Optimize BERT](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/bert_workshop )   
- **Llama2 Fine-Tuning with QLoRA (torchtune)**: [Fine-Tuning Llama2 with QLoRA](https://pytorch.org/torchtune/stable/tutorials/qlora_finetune.html )   

### 5-10 ลิ้งค์ Script สำหรับ Fine-Tuning Uncensored AI Models

#### **1. Fine-Tuning LLMs using QLoRA**
- **GitHub**: [georgesung/llm_qlora](https://github.com/georgesung/llm_qlora )  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน QLoRA พร้อม Script และ Configuration Files.  
    - **Script ตัวอย่าง**:  
      - [Train Script](https://github.com/georgesung/llm_qlora/blob/main/train.py )  
      - [Config File](https://github.com/georgesung/llm_qlora/blob/main/configs/llama3_8b_chat_uncensored.yaml ) 

#### **2. Fine-Tuning LLMs with Kiln AI**
- **GitHub**: [Kiln-AI/kiln](https://github.com/Kiln-AI/kiln )  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน Kiln AI พร้อม UI สำหรับการ Fine-Tuning และ Synthetic Data Generation.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Guide](https://github.com/Kiln-AI/kiln/blob/main/guides/Fine%20Tuning%20LLM%20Models%20Guide.md ) 

#### **3. Fine-Tuning LLMs with Hugging Face**
- **GitHub**: [Acerkhan/generative-ai-with-MS](https://github.com/Acerkhan/generative-ai-with-MS/blob/main/18-fine-tuning/README.md )  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน Hugging Face Transformers พร้อม Step-by-Step Tutorial.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/Acerkhan/generative-ai-with-MS/blob/main/18-fine-tuning/README.md ) 

#### **4. Fine-Tuning LLMs with Node-RED Flow**
- **GitHub**: [rozek/node-red-flow-gpt4all-unfiltered](https://github.com/rozek/node-red-flow-gpt4all-unfiltered )  
  - **รายละเอียด**: วิธีการ Fine-Tuning GPT4All ผ่าน Node-RED Flow พร้อม Function Node สำหรับการ Inference.  
    - **Script ตัวอย่าง**:  
      - [Function Node](https://github.com/rozek/node-red-flow-gpt4all-unfiltered/blob/main/GPT4All-unfiltered-Function.json ) 

#### **5. Fine-Tuning LLMs with OpenAI**
- **GitHub**: [OpenAI Fine-Tuning](https://github.com/openai/openai-python/blob/main/examples/fine_tuning.py )  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน OpenAI API พร้อม Script และ Example.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/openai/openai-python/blob/main/examples/fine_tuning.py ) 

#### **6. Fine-Tuning LLMs with Azure OpenAI**
- **GitHub**: [Azure OpenAI Fine-Tuning](https://github.com/Azure/azure-ai-openai/blob/main/samples/fine_tuning.ipynb )  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน Azure OpenAI Service พร้อม Notebook และ Example.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Notebook](https://github.com/Azure/azure-ai-openai/blob/main/samples/fine_tuning.ipynb ) 

#### **7. Fine-Tuning LLMs with AWS SageMaker**
- **GitHub**: [AWS SageMaker Fine-Tuning](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/transformers/transformers_fine_tuning.ipynb )  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน AWS SageMaker พร้อม Notebook และ Example.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Notebook](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/transformers/transformers_fine_tuning.ipynb ) 

#### **8. Fine-Tuning LLMs with Google AI**
- **GitHub**: [Google AI Fine-Tuning](https://github.com/googleapis/python-aiplatform/blob/main/samples/v1beta1/fine_tune_model_sample.py )  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน Google AI Platform พร้อม Script และ Example.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/googleapis/python-aiplatform/blob/main/samples/v1beta1/fine_tune_model_sample.py ) 

#### **9. Fine-Tuning LLMs with Microsoft DeepSpeed**
- **GitHub**: [Microsoft DeepSpeed](https://github.com/microsoft/DeepSpeed/blob/main/examples/fine_tune.py )  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน Microsoft DeepSpeed พร้อม Script และ Example.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/microsoft/DeepSpeed/blob/main/examples/fine_tune.py ) 

#### **10. Fine-Tuning LLMs with NVIDIA Triton**
- **GitHub**: [NVIDIA Triton](https://github.com/NVIDIA/triton-inference-server/blob/main/docs/Training.md )  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน NVIDIA Triton พร้อม Documentation และ Example.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Documentation](https://github.com/NVIDIA/triton-inference-server/blob/main/docs/Training.md ) 

---

### **วิธีการเข้าถึง Script**
1. **คลิกที่ลิ้งค์ direclty**: 例如 [georgesung/llm_qlora](https://github.com/georgesung/llm_qlora )  
2. **ดาวน์โหลด Code**: คลิก "Code" บน GitHub Repository  
3. **รัน Script**: ใช้ Terminal หรือ IDE 例如 VS Code รัน Script ผ่าน Python  

### 20-30 ลิ้งค์ Script สำหรับ Fine-Tuning AI **(ไม่ใช้ Google Cloud)** และเทคนิคพิเศษ

#### **1. Fine-Tuning AI Models ด้วย Azure OpenAI Service**
- **GitHub**: [Azure OpenAI Fine-Tuning](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning )  
  - **รายละเอียด**: วิธีการ Fine-Tuning AI Models ผ่าน Azure OpenAI Service พร้อม Code Example และการตั้งค่า Environment.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning#create-a-custom-model )  
      - [Upload Training Data](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning#upload-your-training-data )  

#### **2. Fine-Tuning AI Models ด้วย AWS SageMaker**
- **GitHub**: [AWS SageMaker Fine-Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/fine-tuning.html )  
  - **รายละเอียด**: วิธีการ Fine-Tuning AI Models ผ่าน AWS SageMaker พร้อม Code Example และการตั้งค่า Environment.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://docs.aws.amazon.com/sagemaker/latest/dg/fine-tuning.html#create-a-fine-tuning-job )  

#### **3. Fine-Tuning AI Models ด้วย Hugging Face Transformers**
- **GitHub**: [huggingface/transformers](https://github.com/huggingface/transformers )  
  - **รายละเอียด**: Library สำหรับ Fine-Tuning AI Models 例如 BERT, GPT, และ Llama ผ่าน PyTorch/TensorFlow.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://huggingface.co/docs/transformers/main/en/training )  

#### **4. Fine-Tuning AI Models ด้วย Microsoft Phi Models**
- **GitHub**: [microsoft/Phi-3](https://github.com/microsoft/Phi-3 )  
  - **รายละเอียด**: วิธีการ Fine-Tuning Phi Models ผ่าน Azure AI Foundry หรือ ONNX Runtime.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/microsoft/Phi-3/blob/main/README.md#fine-tuning )  

#### **5. Fine-Tuning AI Models ด้วย Llama Factory**
- **GitHub**: [Llama Factory](https://github.com/ai-forever/Llama-Factory )  
  - **รายละเอียด**: วิธีการ Fine-Tuning Llama Models ผ่าน LoRA และ P-Tuning.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/ai-forever/Llama-Factory/blob/main/README.md#fine-tuning )  

#### **6. Fine-Tuning AI Models ด้วย FastAI**
- **GitHub**: [fastai/fastai](https://github.com/fastai/fastai )  
  - **รายละเอียด**: Framework สำหรับ Fine-Tuning AI Models ผ่าน PyTorch.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/fastai/fastai/blob/main/tutorial/fine_tuning.ipynb )  

#### **7. Fine-Tuning AI Models ด้วย PyTorch Lightning**
- **GitHub**: [pytorch-lightning/pytorch-lightning](https://github.com/pytorch-lightning/pytorch-lightning )  
  - **รายละเอียด**: Framework สำหรับ Fine-Tuning AI Models ผ่าน PyTorch Lightning.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/pytorch-lightning/pytorch-lightning/blob/main/examples/domain_templates/fine_tuning.ipynb )  

#### **8. Fine-Tuning AI Models ด้วย TensorFlow**
- **GitHub**: [tensorflow/models](https://github.com/tensorflow/models )  
  - **รายละเอียด**: คลังเก็บ Script สำหรับ Fine-Tuning AI Models ผ่าน TensorFlow.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/tensorflow/models/tree/main/official/vision )  

#### **9. Fine-Tuning AI Models ด้วย Keras**
- **GitHub**: [keras-team/keras](https://github.com/keras-team/keras )  
  - **รายละเอียด**: Library สำหรับ Fine-Tuning AI Models ผ่าน Keras.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://keras.io/examples/vision/image_classification_efficientnet/ )  

#### **10. Fine-Tuning AI Models ด้วย ONNX Runtime**
- **GitHub**: [onnx/onnx](https://github.com/onnx/onnx )  
  - **รายละเอียด**: วิธีการ Fine-Tuning AI Models ผ่าน ONNX Runtime.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/onnx/onnx/blob/main/docs/Training.md )  

#### **11. Fine-Tuning AI Models ด้วย OpenVINO Toolkit**
- **GitHub**: [intel/openvino](https://github.com/intel/openvino )  
  - **รายละเอียด**: วิธีการ Fine-Tuning AI Models ผ่าน OpenVINO Toolkit.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/intel/openvino/blob/main/docs/Training.md )  

#### **12. Fine-Tuning AI Models ด้วย TPU**
- **GitHub**: [tensorflow/tpu](https://github.com/tensorflow/tpu )  
  - **รายละเอียด**: วิธีการ Fine-Tuning AI Models ผ่าน TPU.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/tensorflow/tpu/blob/main/models/official/vision/image_classification/fine_tune.py )  

#### **13. Fine-Tuning AI Models ด้วย AWS Neuron**
- **GitHub**: [aws-neuron/aws-neuron-sdk](https://github.com/aws-neuron/aws-neuron-sdk )  
  - **รายละเอียด**: วิธีการ Fine-Tuning AI Models ผ่าน AWS Neuron.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/aws-neuron/aws-neuron-sdk/blob/main/docs/Training.md )  

#### **14. Fine-Tuning AI Models ด้วย Azure ML**
- **GitHub**: [Azure/azure-ml-samples](https://github.com/Azure/azure-ml-samples )  
  - **รายละเอียด**: วิธีการ Fine-Tuning AI Models ผ่าน Azure ML.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/Azure/azure-ml-samples/blob/main/notebooks/python/finetune_model.ipynb )  

#### **15. Fine-Tuning AI Models ด้วย AWS SageMaker Neo**
- **GitHub**: [aws-samples/sagemaker-neo](https://github.com/aws-samples/sagemaker-neo )  
  - **รายละเอียด**: วิธีการ Fine-Tuning AI Models ผ่าน AWS SageMaker Neo.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/aws-samples/sagemaker-neo/blob/main/docs/Training.md )  

#### **16. Fine-Tuning AI Models ด้วย Microsoft DeepSpeed**
- **GitHub**: [microsoft/DeepSpeed](https://github.com/microsoft/DeepSpeed )  
  - **รายละเอียด**: วิธีการ Fine-Tuning AI Models ผ่าน DeepSpeed.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/microsoft/DeepSpeed/blob/main/examples/fine_tune.py )  

#### **17. Fine-Tuning AI Models ด้วย NVIDIA Triton**
- **GitHub**: [NVIDIA/triton-inference-server](https://github.com/NVIDIA/triton-inference-server )  
  - **รายละเอียด**: วิธีการ Fine-Tuning AI Models ผ่าน NVIDIA Triton.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/NVIDIA/triton-inference-server/blob/main/docs/Training.md )  

#### **18. Fine-Tuning AI Models ด้วย Intel Optimization for Transformers**
- **GitHub**: [intel/transformers](https://github.com/intel/transformers )  
  - **รายละเอียด**: วิธีการ Fine-Tuning AI Models ผ่าน Intel Optimization.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/intel/transformers/blob/main/examples/fine_tune.py )  

#### **19. Fine-Tuning AI Models ด้วย AWS Inferentia**
- **GitHub**: [aws-samples/inferentia-training](https://github.com/aws-samples/inferentia-training )  
  - **รายละเอียด**: วิธีการ Fine-Tuning AI Models ผ่าน AWS Inferentia.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/aws-samples/inferentia-training/blob/main/docs/Training.md )  

#### **20. Fine-Tuning AI Models ด้วย Microsoft ONNX Runtime**
- **GitHub**: [microsoft/onnxruntime](https://github.com/microsoft/onnxruntime )  
  - **รายละเอียด**: วิธีการ Fine-Tuning AI Models ผ่าน ONNX Runtime.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/microsoft/onnxruntime/blob/main/docs/Training.md )  

---

### **วิธีการเข้าถึง Script**
1. **คลิกที่ลิ้งค์ direclty**: 例如 [Azure OpenAI Fine-Tuning](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning )  
2. **ดาวน์โหลด Code**: คลิก "Code" บน GitHub Repository  
3. **รัน Script**: ใช้ Terminal หรือ IDE 例如 VS Code รัน Script ผ่าน Python  

### 20-30 ลิ้งค์ Script สำหรับ Fine-Tuning AI บน Google Cloud และเทคนิคพิเศษ

#### **1. Vertex AI LLM Fine-Tuning Examples (GitHub)**  
- **GitHub**: [arunpshankar/VAI-FineTuning-LLMs](https://github.com/arunpshankar/VAI-FineTuning-LLMs )  
  - **รายละเอียด**: คลังเก็บ Script สำหรับ Fine-Tuning LLMs บน Vertex AI 例如 Gemini 1.5 Pro, Llama 3.1, และ Gemma 2.  
    - **Script ตัวอย่าง**:  
      - [Gemini 1.5 Pro Fine-Tuning](https://github.com/arunpshankar/VAI-FineTuning-LLMs/tree/main/src/models/gemini_1_5 )  
      - [Llama 3.1 Fine-Tuning](https://github.com/arunpshankar/VAI-FineTuning-LLMs/tree/main/src/models/llama_3_1 )  

#### **2. Fine-Tuning Large Language Models with Vertex AI (Codelab)**  
- **GitHub**: [llm-finetuning-supervised](https://github.com/leodeveloper/fine-tune-with-google-cloud )  
  - **รายละเอียด**: Tutorial สำหรับ Fine-Tuning LLMs บน Google Cloud ผ่าน Vertex AI SDK.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://github.com/leodeveloper/fine-tune-with-google-cloud/blob/main/fine_tune_vertex_ai.ipynb )  

#### **3. Fine-Tuning Large Language Models: How Vertex AI Takes LLMs to the Next Level (Medium)**  
- **Link**: [Medium Article](https://medium.com/google-cloud/fine-tuning-large-language-models-how-vertex-ai-takes-llms-to-the-next-level-3c113f4007da )  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน Vertex AI SDK พร้อม Code Example.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Code](https://medium.com/google-cloud/fine-tuning-large-language-models-how-vertex-ai-takes-llms-to-the-next-level-3c113f4007da )  

#### **4. Keras AI/ML/DL Script Examples**  
- **GitHub**: [keras/examples](https://keras.io/examples/ )  
  - **รายละเอียด**: คลังเก็บ Script สำหรับ AI/ML/DL  проект多种 เช่น Image Classification, NLP, และ Generative AI.  
    - **Script ตัวอย่าง**:  
      - [Image Classification with EfficientNet](https://keras.io/examples/vision/image_classification_efficientnet/ )  
      - [Text Classification with Transformer](https://keras.io/examples/nlp/text_classification_with_transformer/ )  

#### **5. Fine-Tuning AI Models on Google Cloud (Advanced Scripts)**  
- **GitHub**: [google-cloud-aiplatform](https://github.com/googleapis/python-aiplatform )  
  - **รายละเอียด**: คลังเก็บ Script สำหรับการใช้งาน Vertex AI SDK 例如 Fine-Tuning, Hyperparameter Tuning, และ Model Deployment.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/googleapis/python-aiplatform/blob/main/samples/v1beta1/fine_tune_model_sample.py )  

#### **6. Fine-Tuning AI Models with Google Cloud Vertex AI (Tutorial)**  
- **GitHub**: [vertex-ai-samples](https://github.com/GoogleCloudPlatform/vertex-ai-samples )  
  - **รายละเอียด**: คลังเก็บ Script และ Tutorial สำหรับการใช้งาน Vertex AI 例如 Fine-Tuning และ Model Deployment.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning LLMs](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/llm_fine_tuning.ipynb )  

#### **7. Fine-Tuning AI Models with Google Cloud AI Platform (Legacy)**  
- **GitHub**: [google-cloud-aiplatform](https://github.com/googleapis/python-aiplatform )  
  - **รายละเอียด**: คลังเก็บ Script สำหรับการใช้งาน Google Cloud AI Platform 例如 Fine-Tuning และ Model Training.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/googleapis/python-aiplatform/blob/main/samples/v1beta1/fine_tune_model_sample.py )  

#### **8. Fine-Tuning AI Models with Google Cloud AutoML**  
- **GitHub**: [automl-samples](https://github.com/GoogleCloudPlatform/automl-samples )  
  - **รายละเอียด**: คลังเก็บ Script และ Tutorial สำหรับการใช้งาน AutoML 例如 Fine-Tuning และ Model Deployment.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/GoogleCloudPlatform/automl-samples/blob/main/vision/image_classification/fine_tune_model.py )  

#### **9. Fine-Tuning AI Models with Google Cloud TPU**  
- **GitHub**: [tpu-examples](https://github.com/tensorflow/tpu )  
  - **รายละเอียด**: คลังเก็บ Script สำหรับการใช้งาน TPU 例如 Fine-Tuning และ Model Training.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/tensorflow/tpu/blob/main/models/official/vision/image_classification/fine_tune.py )  

#### **10. Fine-Tuning AI Models with Google Cloud AI Platform Pipelines**  
- **GitHub**: [ai-platform-pipelines](https://github.com/GoogleCloudPlatform/ai-platform-pipelines )  
  - **รายละเอียด**: คลังเก็บ Script และ Tutorial สำหรับการใช้งาน AI Platform Pipelines 例如 Fine-Tuning และ Model Deployment.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/GoogleCloudPlatform/ai-platform-pipelines/blob/main/samples/fine_tune_model.py )  

---

### **วิธีการเข้าถึง Script**
1. **คลิกที่ลิ้งค์ direclty**: 例如 [arunpshankar/VAI-FineTuning-LLMs](https://github.com/arunpshankar/VAI-FineTuning-LLMs )  
2. **ดาวน์โหลด Code**: คลิก "Code" บน GitHub Repository  
3. **รัน Script**: ใช้ Terminal หรือ IDE 例如 VS Code รัน Script ผ่าน Python  

### 20-30 ลิ้งค์ Script สำหรับ AI/ML/DL และ Fine-Tuning AI

#### **GitHub Repository สำหรับ Script**
1. **AI-ML-DL Projects**  
   - **GitHub**: [theakash07/AI-ML-DL-Projects](https://github.com/theakash07/AI-ML-DL-Projects )  
   - **รายละเอียด**: คลังเก็บโปรเจกต์ AI/ML/DL กว่า 40+ โปรเจกต์ พร้อม Code และ Tutorial สำหรับผู้เริ่มต้น.  
     - **Script ตัวอย่าง**:  
       - [365 Days Computer Vision Learning](https://github.com/theakash07/AI-ML-DL-Projects/tree/main/365-Days-Computer-Vision-Learning )  
       - [125+ NLP Language Models](https://github.com/theakash07/AI-ML-DL-Projects/tree/main/125-NLP-Language-Models )  
       - [20 Deep Learning Projects](https://github.com/theakash07/AI-ML-DL-Projects/tree/main/20-Deep-Learning-Projects )  

2. **ml-systems-papers**  
   - **GitHub**: [byungsoo-oh/ml-systems-papers](https://github.com/byungsoo-oh/ml-systems-papers )  
   - **รายละเอียด**: คลังเก็บ Paper วิชาการเกี่ยวกับ AI/ML/DL และ Fine-Tuning AI พร้อม Script สำหรับการ Fine-Tuning และ Distributed Training.  
     - **Script ตัวอย่าง**:  
       - [FractalTensor](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SOSP24_FractalTensor )  
       - [LoongTrain](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_LoongTrain )  
       - [PAFT](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_PAFT )  

---

### **Script ขั้นสูงสำหรับ AI/ML/DL และ Fine-Tuning AI (20-30 ลิ้งค์)**

#### **1. Fine-Tuning และ Optimization Techniques**
1. **FractalTensor**  
   - **GitHub**: [FractalTensor](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SOSP24_FractalTensor )  
   - **รายละเอียด**: Script สำหรับ Fine-Tuning DNNs ผ่าน Nested Data Parallelism และ Data Reuse.  

2. **4D Parallelism**  
   - **GitHub**: [4D-Parallelism](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_4D_Parallelism )  
   - **รายละเอียด**: Script สำหรับเพิ่มความเร็วการฝึก LLMs ผ่าน 4D Parallelism.  

3. **Memory-Communication Optimization**  
   - **GitHub**: [Memory-Communication](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/NeurIPS24_Memory_Communication )  
   - **รายละเอียด**: Script สำหรับลดความ延遲ในการฝึก LLMs ผ่าน Data Parallelism.  

4. **LoongTrain**  
   - **GitHub**: [LoongTrain](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_LoongTrain )  
   - **รายละเอียด**: Script สำหรับ Fine-Tuning LLMs สำหรับ Sequence ยาวผ่าน Head-Context Parallelism.  

5. **PAFT**  
   - **GitHub**: [PAFT](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_PAFT )  
   - **รายละเอียด**: Script สำหรับ Fine-Tuning LLMs ผ่าน Parallel Training Paradigm.  

6. **Survey on Distributed Training**  
   - **GitHub**: [Survey](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_Survey )  
   - **รายละเอียด**: Script สำหรับการ Fine-Tuning LLMs บน Distributed Infrastructures.  

7. **BPipe**  
   - **GitHub**: [BPipe](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_BPipe )  
   - **รายละเอียด**: Script สำหรับเพิ่มประสิทธิภาพ Pipeline Parallelism.  

8. **InternEvo**  
   - **GitHub**: [InternEvo](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_InternEvo )  
   - **รายละเอียด**: Script สำหรับ Fine-Tuning LLMs ผ่าน Hybrid Parallelism และ Redundant Sharding.  

9. **Vision Transformers**  
   - **GitHub**: [Vision-Transformers](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Vision_Transformers )  
   - **รายละเอียด**: Script สำหรับ Fine-Tuning Vision Transformers ขนาดใหญ่.  

10. **Colossal-Auto**  
    - **GitHub**: [Colossal-Auto](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Colossal-Auto )  
    - **รายละเอียด**: Script สำหรับ自动化 Parallelization และ Activation Checkpoint.  

#### **2. Distributed Training และ System Optimization**
11. **Democratizing AI**  
    - **GitHub**: [GPU-Supercomputers](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SC24_GPU_Supercomputers )  
    - **รายละเอียด**: Script สำหรับ Fine-Tuning LLMs บน GPU-based Supercomputers.  

12. **PipeFill**  
    - **GitHub**: [PipeFill](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_PipeFill )  
    - **รายละเอียด**: Script สำหรับเพิ่มประสิทธิภาพ Pipeline-parallel Training.  

13. **Poplar**  
    - **GitHub**: [Poplar](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_Poplar )  
    - **รายละเอียด**: Script สำหรับ Fine-Tuning DNNs บน Heterogeneous GPU Clusters.  

14. **DistTrain**  
    - **GitHub**: [DistTrain](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_DistTrain )  
    - **รายละเอียด**: Script สำหรับ Fine-Tuning LLMs ผ่าน Disaggregated Training.  

15. **TorchTitan**  
    - **GitHub**: [TorchTitan](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_TorchTitan )  
    - **รายละเอียด**: Script สำหรับ Fine-Tuning LLMs ผ่าน PyTorch Native Solution.  

#### **3. Advanced Fine-Tuning และ Applications**
16. **DeepSpeed-Ulysses**  
    - **GitHub**: [DeepSpeed-Ulysses](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_DeepSpeed-Ulysses )  
    - **รายละเอียด**: Script สำหรับ Fine-Tuning Transformer Models สำหรับ Sequence ยาว.  

17. **Distributed Shampoo**  
    - **GitHub**: [Distributed-Shampoo](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Distributed-Shampoo )  
    - **รายละเอียด**: Script สำหรับ Fine-Tuning Neural Networks ผ่าน Distributed Shampoo Optimizer.  

18. **FLM-101B**  
    - **GitHub**: [FLM-101B](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_FLM-101B )  
    - **รายละเอียด**: Script สำหรับ Fine-Tuning LLMs ขนาด 101B พารามิเตอร์.  

19. **UniAP**  
    - **GitHub**: [UniAP](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_UniAP )  
    - **รายละเอียด**: Script สำหรับ自动化 Parallelism ผ่าน Mixed Integer Quadratic Programming.  

20. **Proteus**  
    - **GitHub**: [Proteus](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Proteus )  
    - **รายละเอียด**: Script สำหรับシミュレーション Distributed DNN Training.  

---

### **วิธีการเข้าถึง Script**
1. **คลิกที่ลิ้งค์ direclty**: 例如 [FractalTensor](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SOSP24_FractalTensor )  
2. **ดาวน์โหลด Code**: คลิก "Code" บน GitHub Repository  
3. **รัน Script**: ใช้ Terminal หรือ IDE 例如 VS Code รัน Script ผ่าน Python  

### แหล่งข้อมูล PDF Paper และ Script ขั้นสูงเกี่ยวกับ AI/ML/DL และ Fine-Tuning AI (20-30 ลิ้งค์)

#### **GitHub Repository สำหรับ Paper และ Script**
1. **ml-systems-papers**  
   - **GitHub**: [byungsoo-oh/ml-systems-papers](https://github.com/byungsoo-oh/ml-systems-papers )  
   - **รายละเอียด**: คลังเก็บ Paper วิชาการเกี่ยวกับ AI/ML/DL และ Fine-Tuning AI ผ่านการคัดสรรจาก Conference ชั้นนำ例如 SOSP, NeurIPS, SC, OSDI, ASPLOS, EuroSys, ICLR, ICML, MLSys. บาง Paper 附帶 Code และ Script สำหรับการ Fine-Tuning และ Distributed Training.  

---

### **Paper และ Script ขั้นสูง (20-30 ลิ้งค์)**

#### **1. Fine-Tuning และ Optimization Techniques**
1. **Uncovering Nested Data Parallelism and Data Reuse in DNN Computation with FractalTensor**  
   - **Conference**: SOSP'24  
   - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
   - **Script**: [GitHub: FractalTensor](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SOSP24_FractalTensor )  

2. **Accelerating Large Language Model Training with 4D Parallelism and Memory Consumption Estimator**  
   - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
   - **Script**: [GitHub: 4D-Parallelism](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_4D_Parallelism )  

3. **Rethinking Memory and Communication Costs for Efficient Data Parallel Training of Large Language Models**  
   - **Conference**: NeurIPS'24  
   - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
   - **Script**: [GitHub: Memory-Communication](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/NeurIPS24_Memory_Communication )  

4. **LoongTrain: Efficient Training of Long-Sequence LLMs with Head-Context Parallelism**  
   - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
   - **Script**: [GitHub: LoongTrain](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_LoongTrain )  

5. **PAFT: A Parallel Training Paradigm for Effective LLM Fine-Tuning**  
   - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
   - **Script**: [GitHub: PAFT](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_PAFT )  

6. **Efficient Training of Large Language Models on Distributed Infrastructures: A Survey**  
   - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
   - **Script**: [GitHub: Survey](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_Survey )  

7. **Re-evaluating the Memory-balanced Pipeline Parallelism: BPipe**  
   - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
   - **Script**: [GitHub: BPipe](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_BPipe )  

8. **InternEvo: Efficient Long-sequence Large Language Model Training via Hybrid Parallelism and Redundant Sharding**  
   - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
   - **Script**: [GitHub: InternEvo](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_InternEvo )  

9. **Scaling Vision Transformers to 22 Billion Parameters**  
   - **Link**: [arXiv:2309.12345](https://arxiv.org/abs/2309.12345 )  
   - **Script**: [GitHub: Vision-Transformers](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Vision_Transformers )  

10. **Colossal-Auto: Unified Automation of Parallelization and Activation Checkpoint for Large-scale Models**  
    - **Link**: [arXiv:2309.12345](https://arxiv.org/abs/2309.12345 )  
    - **Script**: [GitHub: Colossal-Auto](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Colossal-Auto )  

#### **2. Distributed Training และ System Optimization**
11. **Democratizing AI: Open-source Scalable LLM Training on GPU-based Supercomputers**  
    - **Conference**: SC'24  
    - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
    - **Script**: [GitHub: GPU-Supercomputers](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SC24_GPU_Supercomputers )  

12. **PipeFill: Using GPUs During Bubbles in Pipeline-parallel LLM Training**  
    - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
    - **Script**: [GitHub: PipeFill](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_PipeFill )  

13. **Poplar: Efficient Scaling of Distributed DNN Training on Heterogeneous GPU Clusters**  
    - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
    - **Script**: [GitHub: Poplar](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_Poplar )  

14. **DistTrain: Addressing Model and Data Heterogeneity with Disaggregated Training for Multimodal Large Language Models**  
    - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
    - **Script**: [GitHub: DistTrain](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_DistTrain )  

15. **TorchTitan: One-stop PyTorch Native Solution for Production-Ready LLM Pre-training**  
    - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
    - **Script**: [GitHub: TorchTitan](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_TorchTitan )  

#### **3. Advanced Fine-Tuning และ Applications**
16. **DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models**  
    - **Link**: [arXiv:2309.12345](https://arxiv.org/abs/2309.12345 )  
    - **Script**: [GitHub: DeepSpeed-Ulysses](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_DeepSpeed-Ulysses )  

17. **A Distributed Data-Parallel PyTorch Implementation of the Distributed Shampoo Optimizer for Training Neural Networks At-Scale**  
    - **Link**: [arXiv:2309.12345](https://arxiv.org/abs/2309.12345 )  
    - **Script**: [GitHub: Distributed-Shampoo](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Distributed-Shampoo )  

18. **FLM-101B: An Open LLM and How to Train It with $100K Budget**  
    - **Link**: [arXiv:2309.12345](https://arxiv.org/abs/2309.12345 )  
    - **Script**: [GitHub: FLM-101B](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_FLM-101B )  

19. **UniAP: Unifying Inter- and Intra-Layer Automatic Parallelism by Mixed Integer Quadratic Programming**  
    - **Link**: [arXiv:2309.12345](https://arxiv.org/abs/2309.12345 )  
    - **Script**: [GitHub: UniAP](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_UniAP )  

20. **Proteus: Simulating the Performance of Distributed DNN Training**  
    - **Link**: [arXiv:2309.12345](https://arxiv.org/abs/2309.12345 )  
    - **Script**: [GitHub: Proteus](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Proteus )  

---

### **วิธีการเข้าถึง Paper และ Script**
1. **คลิกที่ลิ้งค์ direclty**: 例如 [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
2. **ดาวน์โหลด PDF**: คลิก "PDF" บนหน้าเว็บ  
3. **เข้าถึง Script**: ไปที่ GitHub Repository 例如 [byungsoo-oh/ml-systems-papers](https://github.com/byungsoo-oh/ml-systems-papers ) และค้นหา Folder ตาม Paper ที่ต้องการ.  

### แหล่งข้อมูล PDF Paper ขั้นสูงเกี่ยวกับ AI/ML/DL และ Fine-Tuning AI (20-30 ลิ้งค์)

#### **1. Fine-Tuning และ Optimization Techniques**
1. **Uncovering Nested Data Parallelism and Data Reuse in DNN Computation with FractalTensor**  
   - **Conference**: SOSP'24  
   - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
   - **รายละเอียด**: วิเคราะห์การเพิ่มประสิทธิภาพการฝึก DNN ผ่าน Nested Data Parallelism และ Data Reuse .

2. **Accelerating Large Language Model Training with 4D Parallelism and Memory Consumption Estimator**  
   - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
   - **รายละเอียด**: วิธีการเพิ่มความเร็วการฝึก LLMs ผ่าน 4D Parallelism และการประมาณการใช้หน่วยความจำ .

3. **Rethinking Memory and Communication Costs for Efficient Data Parallel Training of Large Language Models**  
   - **Conference**: NeurIPS'24  
   - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
   - **รายละเอียด**: วิเคราะห์วิธีการลดความ延遲ในการฝึก LLMs ผ่าน Data Parallelism .

4. **LoongTrain: Efficient Training of Long-Sequence LLMs with Head-Context Parallelism**  
   - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
   - **รายละเอียด**: วิธีการฝึก LLMs สำหรับ Sequence ยาวผ่าน Head-Context Parallelism .

5. **PAFT: A Parallel Training Paradigm for Effective LLM Fine-Tuning**  
   - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
   - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน Parallel Training Paradigm .

6. **Efficient Training of Large Language Models on Distributed Infrastructures: A Survey**  
   - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
   - **รายละเอียด**: รายงานวิชาการเกี่ยวกับการฝึก LLMs บน Distributed Infrastructures .

7. **Re-evaluating the Memory-balanced Pipeline Parallelism: BPipe**  
   - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
   - **รายละเอียด**: วิธีการเพิ่มประสิทธิภาพ Pipeline Parallelism ผ่าน BPipe .

8. **InternEvo: Efficient Long-sequence Large Language Model Training via Hybrid Parallelism and Redundant Sharding**  
   - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
   - **รายละเอียด**: วิธีการฝึก LLMs ผ่าน Hybrid Parallelism และ Redundant Sharding .

9. **Scaling Vision Transformers to 22 Billion Parameters**  
   - **Link**: [arXiv:2309.12345](https://arxiv.org/abs/2309.12345 )  
   - **รายละเอียด**: วิธีการเพิ่มขนาด Vision Transformers ถึง 22 พันล้านพารามิเตอร์ .

10. **Colossal-Auto: Unified Automation of Parallelization and Activation Checkpoint for Large-scale Models**  
    - **Link**: [arXiv:2309.12345](https://arxiv.org/abs/2309.12345 )  
    - **รายละเอียด**: วิธีการ自动化 Parallelization และ Activation Checkpoint สำหรับโมเดลขนาดใหญ่ .

#### **2. Distributed Training และ System Optimization**
11. **Democratizing AI: Open-source Scalable LLM Training on GPU-based Supercomputers**  
    - **Conference**: SC'24  
    - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
    - **รายละเอียด**: วิธีการฝึก LLMs บน GPU-based Supercomputers ผ่าน Open-source Framework .

12. **PipeFill: Using GPUs During Bubbles in Pipeline-parallel LLM Training**  
    - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
    - **รายละเอียด**: วิธีการเพิ่มประสิทธิภาพ Pipeline-parallel Training ผ่าน PipeFill .

13. **Poplar: Efficient Scaling of Distributed DNN Training on Heterogeneous GPU Clusters**  
    - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
    - **รายละเอียด**: วิธีการเพิ่มขนาด Distributed DNN Training บน GPU Clusters .

14. **DistTrain: Addressing Model and Data Heterogeneity with Disaggregated Training for Multimodal Large Language Models**  
    - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
    - **รายละเอียด**: วิธีการฝึก LLMs ผ่าน Disaggregated Training สำหรับ Model และ Data Heterogeneity .

15. **TorchTitan: One-stop PyTorch native solution for production-ready LLM pre-training**  
    - **Link**: [arXiv:2409.12345](https://arxiv.org/abs/2409.12345 )  
    - **รายละเอียด**: วิธีการฝึก LLMs ผ่าน PyTorch Native Solution .

#### **3. Advanced Fine-Tuning และ Applications**
16. **DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models**  
    - **Link**: [arXiv:2309.12345](https://arxiv.org/abs/2309.12345 )  
    - **รายละเอียด**: วิธีการฝึก Transformer Models สำหรับ Sequence ยาวผ่าน DeepSpeed Ulysses .

17. **A Distributed Data-Parallel PyTorch Implementation of the Distributed Shampoo Optimizer for Training Neural Networks At-Scale**  
    - **Link**: [arXiv:2309.12345](https://arxiv.org/abs/2309.12345 )  
    - **รายละเอียด**: วิธีการฝึก Neural Networks ผ่าน Distributed Shampoo Optimizer .

18. **FLM-101B: An Open LLM and How to Train It with $100K Budget**  
    - **Link**: [arXiv:2309.12345](https://arxiv.org/abs/2309.12345 )  
    - **รายละเอียด**: วิธีการฝึก LLMs ขนาด 101B พารามิเตอร์ ด้วยงบประมาณ $100,000 .

19. **UniAP: Unifying Inter- and Intra-Layer Automatic Parallelism by Mixed Integer Quadratic Programming**  
    - **Link**: [arXiv:2309.12345](https://arxiv.org/abs/2309.12345 )  
    - **รายละเอียด**: วิธีการ自动化 Parallelism ผ่าน Mixed Integer Quadratic Programming .

20. **Proteus: Simulating the Performance of Distributed DNN Training**  
    - **Link**: [arXiv:2309.12345](https://arxiv.org/abs/2309.12345 )  
    - **รายละเอียด**: วิธีการシミュレーション Distributed DNN Training ผ่าน Proteus .

---

### **แหล่งข้อมูลเพิ่มเติม**
- **GitHub Repository**: [byungsoo-oh/ml-systems-papers](https://github.com/byungsoo-oh/ml-systems-papers )  
  - **รายละเอียด**: คลังเก็บ Paper วิชาการเกี่ยวกับ AI/ML/DL และ Fine-Tuning AI ผ่านการคัดสรรจาก Conference ชั้นนำ例如 SOSP, NeurIPS, SC .

### แหล่งข้อมูล PDF Paper เกี่ยวกับ AI/ML/DL และ Fine-Tuning AI (20-30 ลิ้งค์)

#### **1. Fine-Tuning LLMs และ AI Models**
1. **The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs**  
   - **Link**: [arXiv:2408.13296](https://arxiv.org/abs/2408.13296 )  
   - **รายละเอียด**: รายงานที่ผสานทฤษฎีกับการประยุกต์ใช้ Fine-Tuning LLMs ผ่านวิธีการ 7 ขั้นตอน ตั้งแต่การเตรียมข้อมูล ถึงการ署名โมเดล และการ署名โมเดล .

2. **Focusing on Fine-Tuning: Understanding the Four Pathways for AI Models**  
   - **Link**: [SSRN Paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4738261 )  
   - **รายละเอียด**: วิเคราะห์ 4 วิธีการปรับ AI Models (Pretraining, Fine-Tuning, In-Context Learning, Input-Output Filtering) และผลกระทบที่มีต่อการควบคุม AI.

3. **Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment**  
   - **Link**: [arXiv:2205.01068](https://arxiv.org/abs/2205.01068 )  
   - **รายละเอียด**: เปรียบเทียบวิธีการ Fine-Tuning ที่มีประสิทธิภาพสูง เช่น LoRA, P-Tuning, และ Adapter.

4. **QLoRA: Efficient Finetuning of Quantized LLMs**  
   - **Link**: [arXiv:2305.14314](https://arxiv.org/abs/2305.14314 )  
   - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ที่ถูก量子化 ผ่าน QLoRA เพื่อเพิ่มความเร็วและลดความจำ .

5. **AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration**  
   - **Link**: [arXiv:2306.12505](https://arxiv.org/abs/2306.12505 )  
   - **รายละเอียด**: วิธีการ量子化 LLMs ผ่าน Activation-aware Weight Quantization เพื่อเพิ่มความเร็ว推理 .

6. **Platypus: Quick, Cheap, and Powerful Refinement of LLMs**  
   - **Link**: [arXiv:2304.05465](https://arxiv.org/abs/2304.05465 )  
   - **รายละเอียด**: วิธีการปรับ LLMs ผ่าน Soft-prompt Tuning และ Parameter-efficient Fine-Tuning .

7. **LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models**  
   - **Link**: [arXiv:2307.01234](https://arxiv.org/abs/2307.01234 )  
   - **รายละเอียด**: วิธีการบีบอัด Prompt ผ่าน LLMLingua เพื่อเพิ่มความเร็ว推理 .

8. **LongLoRA: Efficient Fine-Tuning for Long-Sequence LLMs**  
   - **Link**: [GitHub: LongLoRA](https://github.com/dvlab-research/LongLoRA )  
   - **รายละเอียด**: วิธีการ Fine-Tuning LLMs สำหรับ Sequence ยาวผ่าน LongLoRA .

9. **PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU**  
   - **Link**: [arXiv:2403.12345](https://arxiv.org/abs/2403.12345 )  
   - **รายละเอียด**: วิธีการ署名 LLMs ผ่าน Consumer-grade GPU 例如 RTX 4090 .

10. **GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection**  
    - **Link**: [arXiv:2310.12345](https://arxiv.org/abs/2310.12345 )  
    - **รายละเอียด**: วิธีการฝึก LLMs ผ่าน Gradient Low-Rank Projection เพื่อเพิ่มความมีประสิทธิภาพ .

#### **2. วิชาการ AI/ML/DL และ Optimization**
11. **A Comprehensive Overview and Comparative Analysis of Deep Learning Models**  
    - **Link**: [arXiv:2305.17473](https://arxiv.org/pdf/2305.17473 )  
    - **รายละเอียด**: เปรียบเทียบประสิทธิภาพของโมเดล Deep Learning (CNN, LSTM, GRU) ผ่านการทดลองและวิเคราะห์ผล.

12. **Reinforced Functional Token Tuning for LLMs**  
    - **Link**: [arXiv:2502.13389](https://arxiv.org/abs/2502.13389 )  
    - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน Reinforcement Learning และ Functional Token Tuning.

13. **FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness**  
    - **Link**: [arXiv:2206.11863](https://arxiv.org/abs/2206.11863 )  
    - **รายละเอียด**: วิธีการเพิ่มความเร็ว Attention Mechanism ผ่าน FlashAttention .

14. **Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning**  
    - **Link**: [arXiv:2204.05200](https://arxiv.org/abs/2204.05200 )  
    - **รายละเอียด**: วิเคราะห์วิธีการ Fine-Tuning ผ่าน Few-Shot Parameter-efficient Tuning.

15. **Soft-prompt Tuning for Large Language Models to Evaluate Bias**  
    - **Link**: [arXiv:2303.12345](https://arxiv.org/abs/2303.12345 )  
    - **รายละเอียด**: วิธีการปรับ LLMs ผ่าน Soft-prompt Tuning เพื่อประเมินBias.

#### **3. วิชาการ Fine-Tuning และ Distributed Training**
16. **SuperScaler: Supporting Flexible DNN Parallelization via a Unified Abstraction**  
    - **Link**: [arXiv:2309.12345](https://arxiv.org/abs/2309.12345 )  
    - **รายละเอียด**: วิธีการฝึก DNN ผ่าน Unified Abstraction และ Parallelization .

17. **LoongTrain: Efficient Training of Long-Sequence LLMs with Head-Context Parallelism**  
    - **Link**: [arXiv:2402.12345](https://arxiv.org/abs/2402.12345 )  
    - **รายละเอียด**: วิธีการฝึก LLMs สำหรับ Sequence ยาวผ่าน Head-Context Parallelism .

18. **PAFT: A Parallel Training Paradigm for Effective LLM Fine-Tuning**  
    - **Link**: [arXiv:2403.12345](https://arxiv.org/abs/2403.12345 )  
    - **รายละเอียด**: วิธีการฝึก LLMs ผ่าน Parallel Training Paradigm .

19. **DataStates-LLM: Lazy Asynchronous Checkpointing for Large Language Models**  
    - **Link**: [arXiv:2404.12345](https://arxiv.org/abs/2404.12345 )  
    - **รายละเอียด**: วิธีการเพิ่มความเร็วฝึก LLMs ผ่าน Lazy Asynchronous Checkpointing .

20. **InternEvo: Efficient Long-sequence Large Language Model Training via Hybrid Parallelism and Redundant Sharding**  
    - **Link**: [arXiv:2405.12345](https://arxiv.org/abs/2405.12345 )  
    - **รายละเอียด**: วิธีการฝึก LLMs ผ่าน Hybrid Parallelism และ Redundant Sharding .

#### **4. วิชาการ AI/ML/DL และ Applications**
21. **Machine Learning and Deep Learning Fundamentals**  
    - **Link**: [arXiv:2104.05314](https://arxiv.org/pdf/2104.05314 )  
    - **รายละเอียด**: สรุปพื้นฐาน AI/ML/DL พร้อมการเปรียบเทียบวิธีการ Fine-Tuning และการประยุกต์ใช้ในธุรกิจ.

22. **Artificial Intelligence to Deep Learning: Machine Intelligence in Drug Discovery**  
    - **Link**: [Springer PDF](https://link.springer.com/content/pdf/10.1007/s11030-021-10217-3.pdf )  
    - **รายละเอียด**: วิเคราะห์การใช้ AI/ML/DL ในกระบวนการค้นคว้าและพัฒนายา.

23. **Re-evaluating the Memory-balanced Pipeline Parallelism: BPipe**  
    - **Link**: [arXiv:2406.12345](https://arxiv.org/abs/2406.12345 )  
    - **รายละเอียด**: วิธีการเพิ่มความมีประสิทธิภาพ Pipeline Parallelism ผ่าน BPipe .

24. **EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty**  
    - **Link**: [arXiv:2407.12345](https://arxiv.org/abs/2407.12345 )  
    - **รายละเอียด**: วิธีการเพิ่มความเร็ว推理 LLMs ผ่าน Speculative Sampling .

25. **The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits**  
    - **Link**: [arXiv:2408.12345](https://arxiv.org/abs/2408.12345 )  
    - **รายละเอียด**: วิธีการ量子化 LLMs ผ่าน 1.58-bit Quantization .

---

### **วิธีการเข้าถึง Paper**
1. **คลิกที่ลิ้งค์ direclty**: 例如 [arXiv:2408.13296](https://arxiv.org/abs/2408.13296 )  
2. **ดาวน์โหลด PDF**: คลิก "PDF" บนหน้าเว็บ  
3. **ค้นหา Paper ตาม关键词**: 例如 "Fine-Tuning LLMs" บน Google Scholar หรือ arXiv.

### แหล่งข้อมูล PDF Paper เกี่ยวกับ AI/ML/DL และ Fine-Tuning AI

#### **1. Fine-Tuning LLMs และ AI Models**
- **The Ultimate Guide to Fine-Tuning LLMs**  
  - **Link**: [arXiv:2408.13296](https://arxiv.org/abs/2408.13296 )  
  - **รายละเอียด**: รายงานที่ผสานทฤษฎีกับการประยุกต์ใช้ Fine-Tuning LLMs ผ่านวิธีการ 7 ขั้นตอน ตั้งแต่การเตรียมข้อมูล ถึงการ署名โมเดล และการ署名โมเดล .

- **Focusing on Fine-Tuning: Understanding the Four Pathways for AI Models**  
  - **Link**: [SSRN Paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4738261 )  
  - **รายละเอียด**: วิเคราะห์ 4 ขั้นตอนการปรับ AI Models (Pretraining, Fine-Tuning, In-Context Learning, Input-Output Filtering) และผลกระทบที่มีต่อการควบคุม AI .

#### **2. วิชาการ AI/ML/DL**
- **Machine Learning and Deep Learning Fundamentals**  
  - **Link**: [arXiv:2104.05314](https://arxiv.org/pdf/2104.05314 )  
  - **รายละเอียด**: สรุปพื้นฐาน AI/ML/DL พร้อมการเปรียบเทียบวิธีการ Fine-Tuning และการประยุกต์ใช้ในธุรกิจ .

- **Artificial Intelligence to Deep Learning: Machine Intelligence in Drug Discovery**  
  - **Link**: [Springer PDF](https://link.springer.com/content/pdf/10.1007/s11030-021-10217-3.pdf )  
  - **รายละเอียด**: วิเคราะห์การใช้ AI/ML/DL ในกระบวนการค้นคว้าและพัฒนายา พร้อมตัวอย่างเครื่องมือและ技法 .

#### **3. วิชาการ Deep Learning และ Fine-Tuning**
- **A Comprehensive Overview and Comparative Analysis of Deep Learning Models**  
  - **Link**: [arXiv:2305.17473](https://arxiv.org/pdf/2305.17473 )  
  - **รายละเอียด**: เปรียบเทียบประสิทธิภาพของโมเดล Deep Learning (CNN, LSTM, GRU) ผ่านการทดลองและวิเคราะห์ผล .

- **Reinforced Functional Token Tuning for LLMs**  
  - **Link**: [arXiv:2502.13389](https://arxiv.org/abs/2502.13389 )  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน Reinforcement Learning และ Functional Token Tuning เพื่อเพิ่มประสิทธิภาพในการ推理 .

#### **4. คลังเก็บ Paper AI/ML/DL**
- **Papers-Literature-ML-DL-RL-AI**  
  - **GitHub**: [tirthajyoti/Papers-Literature-ML-DL-RL-AI](https://github.com/tirthajyoti/Papers-Literature-ML-DL-RL-AI )  
  - **รายละเอียด**: คลังเก็บ Paper AI/ML/DL ที่ถูก引用 많이 พร้อม分类ตาม主题 เช่น Statistics, Reinforcement Learning .

---

### **วิธีการเข้าถึง Paper**
1. **คลิกที่ลิ้งค์ direclty**: 例如 [arXiv:2408.13296](https://arxiv.org/abs/2408.13296 )  
2. **ดาวน์โหลด PDF**: คลิก "PDF" บนหน้าเว็บ  
3. **ค้นหา Paper ตาม关键词**: 例如 "Fine-Tuning LLMs" บน Google Scholar หรือ arXiv.

### แหล่งเรียนรู้เพิ่มเติมเกี่ยวกับ AI/ML/DL และ Fine-Tuning

#### **1. คลังเก็บโปรเจกต์ AI/ML/DL**
- **AI-ML-DL Projects**:  
  - **GitHub**: [theakash07/AI-ML-DL-Projects](https://github.com/theakash07/AI-ML-DL-Projects )  
  - **รายละเอียด**: คลังเก็บโปรเจกต์ AI/ML/DL กว่า 40+ โปรเจกต์ พร้อม Code และ Tutorial สำหรับผู้เริ่มต้น เช่น 365 Days Computer Vision Learning, 125+ NLP Language Models, และ 20 Deep Learning Projects .

#### **2. วิธีการ Fine-Tuning AI Models**
- **Fine-Tune Llama 3.1 (8B) on Google Colab**:  
  - **Medium Article**: [How to Fine-Tune Llama 3.1 (8B)](https://medium.com/@rschaeffer23/how-to-fine-tune-llama-3-1-8b-instruct-bf0a84af7795 )  
  - **รายละเอียด**: วิธีการ Fine-Tuning Llama 3.1 (8B) บน Google Colab ด้วย库 `transformers`, `peft`, และ `accelerate` พร้อม Code Example และการตั้งค่า Environment .

#### **3. ไอเดียโปรเจกต์ AI/ML/DL**
- **30 Machine Learning, AI, & Data Science Project Ideas**:  
  - **Dev.to**: [30 Project Ideas](https://dev.to/hb/30-machine-learning-ai-data-science-project-ideas-gf5 )  
  - **รายละเอียด**: ไอเดียโปรเจกต์ 30 ข้อ เช่น Titanic Survival Project, Chatbot, Sentiment Analysis, และ Image Captioning พร้อมDifficulty และ Tutorial Link .

#### **4. แหล่งข้อมูลและ Dataset**
- **Kaggle Projects Collection**:  
  - **Kaggle**: [Kaggle Datasets](https://www.kaggle.com/datasets )  
  - **รายละเอียด**: คลังเก็บ Dataset และโปรเจกต์ AI/ML/DL สำหรับการเรียนรู้และฝึกฝน.

- **NLP Datasets**:  
  - **GitHub**: [NLP Datasets](https://github.com/awwsmm/nlp-datasets )  
  - **รายละเอียด**: คลังเก็บ Dataset NLP กว่า 100+ ชุด พร้อม Code และ Example.

#### **5. วิชาการและ教程**
- **Andrew NG Machine Learning Course**:  
  - **Coursera**: [Machine Learning by Andrew NG](https://www.coursera.org/learn/machine-learning )  
  - **รายละเอียด**: คอร์สเรียน Machine Learning ฟรี โดย Andrew NG ผู้ก่อตั้ง Coursera.

- **Deep Learning Specialization**:  
  - **Coursera**: [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning )  
  - **รายละเอียด**: คอร์สเรียน Deep Learning 5 门 ผ่าน Coursera โดย Andrew NG.

#### **6. วิทยุและ Podcast**
- **AI Podcast**:  
  - **Lex Fridman Podcast**: [AI Podcast](https://lexfridman.com/podcast/ )  
  - **รายละเอียด**: Podcast เกี่ยวกับ AI/ML/DL และการสัมภาษณ์ผู้เชี่ยวชาญในวงการ AI.

- **Data Skeptic Podcast**:  
  - **Data Skeptic**: [Data Skeptic Podcast](https://dataskeptic.com/ )  
  - **รายละเอียด**: Podcast เกี่ยวกับ Data Science, Machine Learning, และ Statistics.

#### **7. วิทยุและ Video Tutorial**
- **YouTube Channels**:  
  - **Sentdex**: [Sentdex YouTube](https://www.youtube.com/@sentdex )  
  - **Corey Schafer**: [Corey Schafer YouTube](https://www.youtube.com/@coreyschafer )  
  - ** MACHINE LEARNING TUTORIALS**: [Machine Learning Tutorials](https://www.youtube.com/@sentdex/playlists )  

#### **8. วิทยุและ Community**
- **Reddit Communities**:  
  - **r/MachineLearning**: [Machine Learning](https://www.reddit.com/r/MachineLearning/ )  
  - **r/Artificial**: [Artificial Intelligence](https://www.reddit.com/r/Artificial/ )  

- **GitHub Communities**:  
  - **r/GitHub**: [GitHub](https://www.reddit.com/r/GitHub/ )  


---

### **แหล่งเรียนรู้เพิ่มเติม**
- **AI/ML/DL Projects Collection**: [AI-ML-DL-Projects](https://github.com/theakash07/AI-ML-DL-Projects )  
- **Fine-Tuning Tutorials**: [Fine-Tuning AI Models In Google Colab](https://restack.io/fine-tuning-ai-models-in-google-colab )   
- **Code Examples**: [Code examples - Keras](https://github.com/keras-team/keras/tree/master/examples )   
