# Top AI/LLM learning resource in 2025

Jan 24, 2025

The Blog is organized into three main segments:

1. **LLM Fundamentals** (optional) ‚Äì Covers essential topics such as mathematics, Python, and neural networks.
2. **The LLM Scientist** ‚Äì Concentrates on creating the best-performing LLMs using state-of-the-art techniques.
3. **The LLM Engineer** ‚Äì Focuses on building applications based on LLMs and deploying them.

* * *

### üìù Notebooks

Below is a collection of notebooks and articles dedicated to LLMs.

### Tools
| Notebook Name | Description | Notebook |
|---|---|---|
| **üßê LLM AutoEval** | Evaluate your LLMs automatically using RunPod | [Notebook](https://colab.research.google.com/drive/1Igs3WZuXAIv9X0vwqiE90QlEPys8e8Oa?usp=sharing) |
| **ü•± LazyMergekit** | Merge models effortlessly using MergeKit with a single click | [Notebook](https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing) |
| **ü¶é LazyAxolotl** | Fine-tune models in the cloud with Axolotl in just one click | [Notebook](https://colab.research.google.com/drive/1TsDKNo2riwVmU55gjuBgB1AXVtRRfRHW?usp=sharing) |
| **‚ö° AutoQuant** | Quantize LLMs into GGUF, GPTQ, EXL2, AWQ, and HQQ formats in one click | [Notebook](https://colab.research.google.com/drive/1b6nqC7UZVt8bx4MksX7s656GXPM-eWw4?usp=sharing) |
| **üå≥ Model Family Tree** | Visualize the lineage of merged models | [Notebook](https://colab.research.google.com/drive/1s2eQlolcI1VGgDhqWIANfkfKvcKrMyNr?usp=sharing) |
| **üöÄ ZeroSpace** | Instantly create a Gradio chat interface using a free ZeroGPU | [Notebook](https://colab.research.google.com/drive/1LcVUW5wsJTO2NGmozjji5CkC--646LgC) |


### Fine-tuning
| Notebook Name | Description | Article | Notebook |
|---|---|---|---|
| **Fine-tune Llama 3.1 with Unsloth** | Perform ultra-efficient supervised fine-tuning in Google Colab | [Article](https://originshq.com/blog/fine-tune-llama-3-1-ultra-efficiently-with-unsloth/) | [Notebook](https://colab.research.google.com/drive/164cg_O7SV7G8kZr_JXqLd6VC7pd86-1Z?usp=sharing) |
| **Fine-tune Llama 3 with ORPO** | Achieve cheaper and faster fine-tuning in a single stage with ORPO | [Article](https://originshq.com/blog/fine-tune-llama-3-with-orpo/) | [Notebook](https://colab.research.google.com/drive/1eHNWg9gnaXErdAa8_mcvjMupbSS6rDvi) |
| **Fine-tune Mistral-7b with DPO** | Enhance the performance of supervised fine-tuned models using DPO | [Article](https://originshq.com/blog/boost-the-performance-of-supervised-fine-tuned-models-with-dpo/) | [Notebook](https://colab.research.google.com/drive/15iFBr1xWgztXvhrj5I9fBv20c7CFOPBE?usp=sharing) |
| **Fine-tune Mistral-7b with QLoRA** | Supervised fine-tuning of Mistral-7b in a free-tier Google Colab using TRL |  | [Notebook](https://colab.research.google.com/drive/1o_w0KastmEJNVwT5GoqMCciH-18ca5WS?usp=sharing) |
| **Fine-tune CodeLlama using Axolotl** | A comprehensive guide to fine-tune with the state-of-the-art Axolotl tool | [Article](https://originshq.com/blog/end-to-end-guide-to-the-state-of-the-art-tool-for-fine-tuning/) | [Notebook](https://colab.research.google.com/drive/1Xu0BrCB7IShwSWKVcfAfhehwjDrDMH5m?usp=sharing) |
| **Fine-tune Llama 2 with QLoRA** | A step-by-step guide to supervised fine-tuning of Llama 2 in Google Colab | [Article](https://originshq.com/blog/step-by-step-guide-to-supervised-fine-tune-llama-2-in-google-colab/) | [Notebook](https://colab.research.google.com/drive/1PEQyJO1-f6j0S_XJ8DV50NkpzasXkrzd?usp=sharing) |


### Quantization
| Notebook Name | Description | Article | Notebook |
|---|---|---|---|
| **Introduction to Quantization** | An overview of optimizing large language models using 8-bit quantization | [Article](https://originshq.com/blog/introduction-to-weight-quantization/) | [Notebook](https://colab.research.google.com/drive/1DPr4mUQ92Cc-xf4GgAaB6dFcFnWIvqYi?usp=sharing) |
| **4-bit Quantization using GPTQ** | Learn to quantize your open-source LLMs for consumer hardware using GPTQ | [Article](https://originshq.com/blog/4-bit-llm-quantization-with-gptq/) | [Notebook](https://colab.research.google.com/drive/1lSvVDaRgqQp_mWK_jC9gydz6_-y6Aq4A?usp=sharing) |
| **Quantization with GGUF and llama.cpp** | Quantize Llama 2 models with llama.cpp and upload their GGUF versions to the HF Hub | [Article](https://originshq.com/blog/quantize-llama-models-with-gguf-and-llama-cpp/) | [Notebook](https://colab.research.google.com/drive/1pL8k7m04mgE5jo2NrjGi8atB0j_37aDD?usp=sharing) |
| **ExLlamaV2: The Fastest Library to Run LLMs** | Quantize and run EXL2 models, then upload them to the HF Hub | [Article](https://originshq.com/blog/exllamav2-the-fastest-library-to-run-llms/) | [Notebook](https://colab.research.google.com/drive/1yrq4XBlxiA0fALtMoT2dwiACVc77PHou?usp=sharing) |


### Other
| Notebook Name | Description | Article | Notebook |
|---|---|---|---|
| **Merge LLMs with MergeKit** | Easily create your own models without needing a GPU | [Article](https://originshq.com/blog/merge-large-language-models-with-mergekit/) | [Notebook](https://colab.research.google.com/drive/1_JS7JKJAQozD48-LhYdegcuuZ2ddgXfr?usp=sharing) |
| **Create MoEs with MergeKit** | Combine multiple experts into a single frankenMoE | [Article](https://originshq.com/blog/create-mixtures-of-experts-with-mergekit/) | [Notebook](https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing) |
| **Uncensor any LLM with abliteration** | Fine-tuning strategies without retraining the model | [Article](https://originshq.com/blog/uncensor-any-llm-with-abliteration/) | [Notebook](https://colab.research.google.com/drive/1VYm3hOcvCpbGiqKZb141gJwjdmmCcVpR?usp=sharing) |
| **Improve ChatGPT with Knowledge Graphs** | Augment ChatGPT's responses using knowledge graphs | [Article](https://originshq.com/blog/improve-chatgpt-with-knowledge-graphs/) | [Notebook](https://colab.research.google.com/drive/1mwhOSw9Y9bgEaIFKT4CLi0n18pXRM4cj?usp=sharing) |
| **Decoding Strategies in Large Language Models** | A comprehensive guide covering text generation methods from beam search to nucleus sampling | [Article](https://originshq.com/blog/decoding-strategies-in-large-language-models/) | [Notebook](https://colab.research.google.com/drive/19CJlOS5lI29g-B3dziNn93Enez1yiHk2?usp=sharing) |

* * *
