<div align="center">

![Project Logo](./public/Zom.png)

# üìö AI LLM Learning Resources

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/Apache-2.0-green.svg)](LICENSE)
[![GitHub Package](https://img.shields.io/badge/GitHub-Package-green.svg)](https://github.com/features/packages)
[![GitHub Stars](https://img.shields.io/github/stars/JonusNattapong/Notebook-Git-Colab.svg?style=social)](https://github.com/JonusNattapong/Notebook-Git-Colab/stargazers)

*AI/LLM Learning and Resources by zombitx64 TH*

</div>

*‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: 4 ‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏° 2025*

*‡∏ó‡∏µ‡πà‡∏°‡∏≤: ‡∏î‡∏±‡∏î‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å [Unsloth Notebooks](https://github.com/unslothai/notebooks), [Awesome Colab Notebooks](https://github.com/amrzv/awesome-colab-notebooks), [Origins AI](https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/), ‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°*

‡∏Ñ‡∏•‡∏±‡∏á‡∏£‡∏ß‡∏°‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏î‡πâ‡∏≤‡∏ô Artificial Intelligence (AI) ‡πÅ‡∏•‡∏∞ Large Language Models (LLMs) ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÑ‡∏õ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á

## ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç

1.  [‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô](#‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô)
    *   [‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Machine Learning](#‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö-machine-learning)
    *   [Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI](#python-‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö-ai)
    *   [Neural Networks](#neural-networks)
    *   [Natural Language Processing (NLP)](#natural-language-processing-nlp)
2.  [‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô](#‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô)
    *   [Notebooks ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥](#notebooks-‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
    *   [‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡πÅ‡∏•‡∏∞‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô](#‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡πÅ‡∏•‡∏∞‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô)
3.  [‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£](#‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£)
    *   [Datasets](#datasets)
    *   [Tools](#tools)
    *   [‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°](#‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°)

## ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô <a name="‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"></a>

‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ AI ‡πÅ‡∏•‡∏∞ Large Language Models (LLMs) ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á

---

### üìö LLM Fundamentals
‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô "‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô" (‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Machine Learning, Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI, Neural Networks ‡πÅ‡∏•‡∏∞ Natural Language Processing) 

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI/LLM

| ‡∏•‡∏≥‡∏î‡∏±‡∏ö | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠                              | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                   | ‡∏´‡∏°‡∏ß‡∏î‡∏¢‡πà‡∏≠‡∏¢                              | ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
|-------|------------------------------------|-------------------------------------------------------------------------------------------|---------------------------------------|----------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| 1     | ‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Machine Learning | ‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á AI ‡πÅ‡∏•‡∏∞ Machine Learning ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• | Linear Algebra                       | Mathematics for Machine Learning - ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏ü‡∏£‡∏µ‡∏à‡∏≤‡∏Å Cambridge University Press | [https://mml-book.github.io/](https://mml-book.github.io/)                                      |
| 2     | ‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Machine Learning | ‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á AI ‡πÅ‡∏•‡∏∞ Machine Learning ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• | Linear Algebra                       | 3Blue1Brown - Linear Algebra - ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏™‡∏≠‡∏ô‡∏†‡∏≤‡∏û‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢             | [https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab) |
| 3     | ‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Machine Learning | ‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á AI ‡πÅ‡∏•‡∏∞ Machine Learning ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• | Probability and Statistics           | Khan Academy - Probability and Statistics - ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡∏ü‡∏£‡∏µ                | [https://www.khanacademy.org/math/statistics-probability](https://www.khanacademy.org/math/statistics-probability) |
| 4     | Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI                  | Python ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ AI ‡πÅ‡∏•‡∏∞ LLMs ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏°‡∏µ Libraries ‡∏ó‡∏µ‡πà‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢       | ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô Python ‡πÅ‡∏•‡∏∞ Libraries         | Python Data Science Handbook - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡πÇ‡∏î‡∏¢ Jake VanderPlas ‡∏û‡∏£‡πâ‡∏≠‡∏° Notebooks    | [https://github.com/jakevdp/PythonDataScienceHandbook](https://github.com/jakevdp/PythonDataScienceHandbook) |
| 5     | Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI                  | Python ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ AI ‡πÅ‡∏•‡∏∞ LLMs ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏°‡∏µ Libraries ‡∏ó‡∏µ‡πà‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢       | ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô Python ‡πÅ‡∏•‡∏∞ Libraries         | RealPython - ‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô Python ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î                               | [https://realpython.com/](https://realpython.com/)                                              |
| 6     | Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI                  | Python ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ AI ‡πÅ‡∏•‡∏∞ LLMs ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏°‡∏µ Libraries ‡∏ó‡∏µ‡πà‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢       | ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô Python ‡πÅ‡∏•‡∏∞ Libraries         | CS231n Python Tutorial - ‡∏à‡∏≤‡∏Å Stanford                                     | [https://cs231n.github.io/python-numpy-tutorial/](https://cs231n.github.io/python-numpy-tutorial/) |
| 7     | Neural Networks                   | Neural Networks ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á Deep Learning ‡πÅ‡∏•‡∏∞ LLMs ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î‡πÑ‡∏õ‡∏™‡∏π‡πà Transformer Models | ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÅ‡∏•‡∏∞ ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•      | Neural Networks and Deep Learning - ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏ü‡∏£‡∏µ‡πÇ‡∏î‡∏¢ Michael Nielsen          | [http://neuralnetworksanddeeplearning.com/](http://neuralnetworksanddeeplearning.com/)          |
| 8     | Neural Networks                   | Neural Networks ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á Deep Learning ‡πÅ‡∏•‡∏∞ LLMs ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î‡πÑ‡∏õ‡∏™‡∏π‡πà Transformer Models | ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÅ‡∏•‡∏∞ ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•      | CS231n: Convolutional Neural Networks - ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏à‡∏≤‡∏Å Stanford                 | [https://cs231n.github.io/](https://cs231n.github.io/)                                         |
| 9     | Neural Networks                   | Neural Networks ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á Deep Learning ‡πÅ‡∏•‡∏∞ LLMs ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î‡πÑ‡∏õ‡∏™‡∏π‡πà Transformer Models | ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÅ‡∏•‡∏∞ ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•      | Deep Learning Specialization - ‡πÇ‡∏î‡∏¢ Andrew NG ‡∏ö‡∏ô Coursera                  | [https://www.coursera.org/specializations/deep-learning](https://www.coursera.org/specializations/deep-learning) |
| 10    | Natural Language Processing (NLP) | NLP ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏†‡∏≤‡∏©‡∏≤‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£ ‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLMs             | Text Preprocessing, Feature Extraction, Word Embeddings, RNNs | Lena Voita - Word Embeddings - ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ Word Embeddings                      | [https://lena-voita.github.io/nlp_course/word_embeddings.html](https://lena-voita.github.io/nlp_course/word_embeddings.html) |
| 11    | Natural Language Processing (NLP) | NLP ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏†‡∏≤‡∏©‡∏≤‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£ ‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLMs             | Text Preprocessing, Feature Extraction, Word Embeddings, RNNs | RealPython - NLP with spaCy - ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ spaCy                                 | [https://realpython.com/natural-language-processing-spacy-python/](https://realpython.com/natural-language-processing-spacy-python/) |
| 12    | Natural Language Processing (NLP) | NLP ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏†‡∏≤‡∏©‡∏≤‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£ ‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLMs             | Text Preprocessing, Feature Extraction, Word Embeddings, RNNs | Jay Alammar - Illustrated Word2Vec - ‡∏†‡∏≤‡∏û‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢                   | [https://jalammar.github.io/illustrated-word2vec/](https://jalammar.github.io/illustrated-word2vec/) |
| 13    | Natural Language Processing (NLP) | NLP ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏†‡∏≤‡∏©‡∏≤‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£ ‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLMs             | Text Preprocessing, Feature Extraction, Word Embeddings, RNNs | Colah‚Äôs Blog - Understanding LSTMs - ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ LSTMs                         | [https://colah.github.io/posts/2015-08-Understanding-LSTMs/](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) |
| 14    | Natural Language Processing (NLP) | NLP ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏†‡∏≤‡∏©‡∏≤‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£ ‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLMs             | Text Preprocessing, Feature Extraction, Word Embeddings, RNNs | Kaggle - NLP Guide - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏à‡∏≤‡∏Å Kaggle                                      | [https://www.kaggle.com/learn-guide/natural-language-processing](https://www.kaggle.com/learn-guide/natural-language-processing) |


### ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏
- ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô "‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
  
---

# Awesome AI/LLM Learning Resources for 2025 (Part 2/4)

*‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: 4 ‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏° 2025*

*‡∏ó‡∏µ‡πà‡∏°‡∏≤: ‡∏î‡∏±‡∏î‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å [Unsloth Notebooks](https://github.com/unslothai/notebooks), [Awesome Colab Notebooks](https://github.com/amrzv/awesome-colab-notebooks), [Origins AI](https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/), ‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°*

## Part 2: The LLM Scientist - Advanced LLM Development

‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏∏‡πà‡∏á‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á LLMs ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏ô‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°, ‡∏Å‡∏≤‡∏£ Pre-training, Post-training, Fine-Tuning, Preference Alignment, ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•, Quantization ‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà ‡πÜ

---

‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô "The LLM Scientist - Advanced LLM Development" (‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ 1-8 ‡πÅ‡∏•‡∏∞ Advanced Scripts and Repositories) 

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Advanced LLM Development

| ‡∏•‡∏≥‡∏î‡∏±‡∏ö | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠                          | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                   | ‡∏´‡∏°‡∏ß‡∏î‡∏¢‡πà‡∏≠‡∏¢                              | ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
|-------|--------------------------------|-------------------------------------------------------------------------------------------|---------------------------------------|----------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| 1     | LLM Architecture              | ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLMs ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•                                   | Architectural Overview, Tokenization, Attention Mechanisms, Sampling Techniques | 3Blue1Brown - Visual Intro to Transformers                                 | [https://www.youtube.com/watch?v=wjZofJX0v4M](https://www.youtube.com/watch?v=wjZofJX0v4M)     |
| 2     | LLM Architecture              | ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLMs ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•                                   | Architectural Overview, Tokenization, Attention Mechanisms, Sampling Techniques | Andrej Karpathy - nanoGPT                                                  | [https://www.youtube.com/watch?v=kCc8FmEb1nY](https://www.youtube.com/watch?v=kCc8FmEb1nY)     |
| 3     | LLM Architecture              | ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLMs ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•                                   | Architectural Overview, Tokenization, Attention Mechanisms, Sampling Techniques | Lilian Weng - Attention? Attention!                                        | [https://lilianweng.github.io/posts/2018-06-24-attention/](https://lilianweng.github.io/posts/2018-06-24-attention/) |
| 4     | LLM Architecture              | ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLMs ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•                                   | Architectural Overview, Tokenization, Attention Mechanisms, Sampling Techniques | Maxime Labonne - Decoding Strategies                                       | [https://mlabonne.github.io/blog/posts/2023-06-07-Decoding_strategies.html](https://mlabonne.github.io/blog/posts/2023-06-07-Decoding_strategies.html) |
| 5     | Pre-training Models           | Pre-training ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà ‡∏ã‡∏∂‡πà‡∏á‡πÉ‡∏ä‡πâ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏™‡∏π‡∏á       | Data Preparation, Distributed Training, Training Optimization, Monitoring | FineWeb - Dataset ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡πÇ‡∏î‡∏¢ Penedo et al.                                | [https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1](https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1) |
| 6     | Pre-training Models           | Pre-training ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà ‡∏ã‡∏∂‡πà‡∏á‡πÉ‡∏ä‡πâ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏™‡∏π‡∏á       | Data Preparation, Distributed Training, Training Optimization, Monitoring | RedPajama v2 - Dataset ‡πÄ‡∏õ‡∏¥‡∏î‡πÇ‡∏î‡∏¢ Weber et al.                                | [https://www.together.ai/blog/redpajama-data-v2](https://www.together.ai/blog/redpajama-data-v2) |
| 7     | Pre-training Models           | Pre-training ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà ‡∏ã‡∏∂‡πà‡∏á‡πÉ‡∏ä‡πâ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏™‡∏π‡∏á       | Data Preparation, Distributed Training, Training Optimization, Monitoring | Nanotron - ‡πÉ‡∏ä‡πâ‡∏ù‡∏∂‡∏Å SmolLM2                                                  | [https://github.com/huggingface/nanotron](https://github.com/huggingface/nanotron)              |
| 8     | Post-training Datasets        | Post-training ‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏ï‡πà‡∏≠‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô                               | Storage & Chat Templates, Synthetic Data Generation, Data Enhancement, Quality Filtering | LLM Datasets - ‡∏Ñ‡∏•‡∏±‡∏á Dataset ‡πÇ‡∏î‡∏¢ Maxime Labonne                             | [https://github.com/mlabonne/llm-datasets](https://github.com/mlabonne/llm-datasets)           |
| 9     | Post-training Datasets        | Post-training ‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏ï‡πà‡∏≠‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô                               | Storage & Chat Templates, Synthetic Data Generation, Data Enhancement, Quality Filtering | Synthetic Data Generator - ‡πÇ‡∏î‡∏¢ Argilla                                     | [https://huggingface.co/spaces/argilla/synthetic-data-generator](https://huggingface.co/spaces/argilla/synthetic-data-generator) |
| 10    | Supervised Fine-Tuning (SFT)  | SFT ‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÑ‡∏î‡πâ‡∏î‡∏µ                                               | Training Techniques, Training Parameters, Distributed Training, Monitoring | Fine-tune Llama 3.1 with Unsloth - Notebook                                | [https://colab.research.google.com/drive/164cg_O7SV7G8kZr_JXqLd6VC7pd86-1Z](https://colab.research.google.com/drive/164cg_O7SV7G8kZr_JXqLd6VC7pd86-1Z) |
| 11    | Supervised Fine-Tuning (SFT)  | SFT ‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÑ‡∏î‡πâ‡∏î‡∏µ                                               | Training Techniques, Training Parameters, Distributed Training, Monitoring | Fine-tune Mistral-7b with QLoRA - Notebook                                 | [https://colab.research.google.com/drive/1o_w0KastmEJNVwT5GoqMCciH-18ca5WS](https://colab.research.google.com/drive/1o_w0KastmEJNVwT5GoqMCciH-18ca5WS) |
| 12    | Preference Alignment          | ‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÅ‡∏•‡∏∞‡∏•‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô Toxicity, Hallucinations                       | Rejection Sampling, DPO, PPO, Monitoring | Fine-tune Mistral-7b with DPO - Notebook                                   | [https://colab.research.google.com/drive/15iFBr1xWgztXvhrj5I9fBv20c7CFOPBE](https://colab.research.google.com/drive/15iFBr1xWgztXvhrj5I9fBv20c7CFOPBE) |
| 13    | Preference Alignment          | ‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÅ‡∏•‡∏∞‡∏•‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô Toxicity, Hallucinations                       | Rejection Sampling, DPO, PPO, Monitoring | Fine-tune Llama 3 with ORPO - Notebook                                     | [https://colab.research.google.com/drive/1eHNWg9gnaXErdAa8_mcvjMupbSS6rDvi](https://colab.research.google.com/drive/1eHNWg9gnaXErdAa8_mcvjMupbSS6rDvi) |
| 14    | Evaluation                    | ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• LLMs ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Dataset ‡πÅ‡∏•‡∏∞ Training                                       | Automated Benchmarks, Human Evaluation, Model-based Evaluation, Feedback Signal | Evaluation Guidebook - ‡πÇ‡∏î‡∏¢ Cl√©mentine Fourrier                             | [https://github.com/huggingface/evaluation-guidebook](https://github.com/huggingface/evaluation-guidebook) |
| 15    | Quantization                  | ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏ö‡∏ô Hardware ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ                                             | Base Techniques, GGUF & llama.cpp, GPTQ & AWQ, SmoothQuant & ZeroQuant | 4-bit Quantization with GPTQ - Notebook                                    | [https://colab.research.google.com/drive/1lSvVDaRgqQp_mWK_jC9gydz6_-y6Aq4A](https://colab.research.google.com/drive/1lSvVDaRgqQp_mWK_jC9gydz6_-y6Aq4A) |
| 16    | Quantization                  | ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏ö‡∏ô Hardware ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ                                             | Base Techniques, GGUF & llama.cpp, GPTQ & AWQ, SmoothQuant & ZeroQuant | Quantization with GGUF - Notebook                                          | [https://colab.research.google.com/drive/1pL8k7m04mgE5jo2NrjGi8atB0j_37aDD](https://colab.research.google.com/drive/1pL8k7m04mgE5jo2NrjGi8atB0j_37aDD) |
| 17    | New Trends                    | ‡∏™‡∏≥‡∏£‡∏ß‡∏à‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ LLMs                                                  | Model Merging, Multimodal Models, Interpretability, Test-time Compute | Merge LLMs with Mergekit - Notebook                                        | [https://colab.research.google.com/drive/1_JS7JKJAQozD48-LhYdegcuuZ2ddgXfr](https://colab.research.google.com/drive/1_JS7JKJAQozD48-LhYdegcuuZ2ddgXfr) |
| 18    | New Trends                    | ‡∏™‡∏≥‡∏£‡∏ß‡∏à‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ LLMs                                                  | Model Merging, Multimodal Models, Interpretability, Test-time Compute | Uncensor LLM with Abliteration - Notebook                                  | [https://colab.research.google.com/drive/1VYm3hOcvCpbGiqKZb141gJwjdmmCcVpR](https://colab.research.google.com/drive/1VYm3hOcvCpbGiqKZb141gJwjdmmCcVpR) |
| 19    | Advanced Scripts and Repositories | ‡∏£‡∏ß‡∏°‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏•‡∏∞ Repository ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô LLM                                            | Unsloth, ml-systems-papers, Awesome Colab | Unsloth - Tools ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning ‡πÅ‡∏•‡∏∞ Quantization                       | [https://github.com/unslothai/unsloth](https://github.com/unslothai/unsloth)                   |
| 20    | Advanced Scripts and Repositories | ‡∏£‡∏ß‡∏°‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏•‡∏∞ Repository ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô LLM                                            | Unsloth, ml-systems-papers, Awesome Colab | FractalTensor - Nested Data Parallelism                                    | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SOSP24_FractalTensor](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SOSP24_FractalTensor) |


### ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏
- ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ 1-8 ‡πÅ‡∏•‡∏∞ Advanced Scripts and Repositories ‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô "The LLM Scientist - Advanced LLM Development"
---

### üöÄ How to Proceed

1.  **‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠:** ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å Architecture ‡∏´‡∏£‡∏∑‡∏≠ Pre-training
2.  **‡∏ó‡∏î‡∏•‡∏≠‡∏á Notebooks:** ‡∏£‡∏±‡∏ô‡πÉ‡∏ô Colab ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥
3.  **‡∏®‡∏∂‡∏Å‡∏©‡∏≤ Papers:** ‡∏≠‡πà‡∏≤‡∏ô Paper ‡πÅ‡∏•‡∏∞ Scripts ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å


# Awesome AI/LLM Learning Resources for 2025 (Part 3/4)

*‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: 4 ‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏° 2025*
*‡∏ó‡∏µ‡πà‡∏°‡∏≤: ‡∏î‡∏±‡∏î‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å [Unsloth Notebooks](https://github.com/unslothai/notebooks), [Awesome Colab Notebooks](https://github.com/amrzv/awesome-colab-notebooks), [Origins AI](https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/), ‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°*

## Part 3: The LLM Engineer - Building LLM Applications

‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ LLMs ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•, ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Storage, Retrieval Augmented Generation (RAG), ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á RAG ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á, ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û Inference, ‡∏Å‡∏≤‡∏£ Deploy ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•

---
‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô "The LLM Engineer - Building LLM Applications" (‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ 1-7 ‡πÅ‡∏•‡∏∞ Advanced Scripts and Repositories) 

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Building LLM Applications

| ‡∏•‡∏≥‡∏î‡∏±‡∏ö | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠                          | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                   | ‡∏´‡∏°‡∏ß‡∏î‡∏¢‡πà‡∏≠‡∏¢                              | ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
|-------|--------------------------------|-------------------------------------------------------------------------------------------|---------------------------------------|----------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| 1     | Running LLMs                  | ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ô LLMs ‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö Prompt                                  | Using APIs, Local Deployment, Prompt Engineering | Prompt Engineering Guide - ‡πÇ‡∏î‡∏¢ DAIR.AI                                     | [https://www.promptingguide.ai/](https://www.promptingguide.ai/)                                |
| 2     | Running LLMs                  | ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ô LLMs ‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö Prompt                                  | Using APIs, Local Deployment, Prompt Engineering | Run LLM Locally with LM Studio - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠                                    | [https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio](https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio) |
| 3     | Running LLMs                  | ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ô LLMs ‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö Prompt                                  | Using APIs, Local Deployment, Prompt Engineering | Hugging Face Inference API - ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£                                       | [https://huggingface.co/docs/api-inference/quicktour](https://huggingface.co/docs/api-inference/quicktour) |
| 4     | Building Vector Storage       | ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ LLMs ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å                                     | Document Ingestion, Text Splitting, Embedding Models, Vector Databases | LangChain - Text Splitters - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠                                        | [https://python.langchain.com/docs/modules/data_connection/document_transformers/](https://python.langchain.com/docs/modules/data_connection/document_transformers/) |
| 5     | Building Vector Storage       | ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ LLMs ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å                                     | Document Ingestion, Text Splitting, Embedding Models, Vector Databases | MTEB Leaderboard - Embedding Model Rankings                               | [https://huggingface.co/spaces/mteb/leaderboard](https://huggingface.co/spaces/mteb/leaderboard) |
| 6     | Retrieval Augmented Generation (RAG) | ‡∏£‡∏ß‡∏°‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Retrieval) ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (Generation)                              | Orchestrators, Retrievers, Evaluation | LangChain RAG - Notebook                                                  | [https://colab.research.google.com/drive/1f3VFD6jCSvK0uo2Q84-TT1AbfunN-UEZ](https://colab.research.google.com/drive/1f3VFD6jCSvK0uo2Q84-TT1AbfunN-UEZ) |
| 7     | Retrieval Augmented Generation (RAG) | ‡∏£‡∏ß‡∏°‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Retrieval) ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (Generation)                              | Orchestrators, Retrievers, Evaluation | LangChain - Q&A with RAG - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠                                         | [https://python.langchain.com/docs/use_cases/question_answering/quickstart](https://python.langchain.com/docs/use_cases/question_answering/quickstart) |
| 8     | Advanced RAG                  | ‡∏û‡∏±‡∏í‡∏ô‡∏≤ RAG ‡πÉ‡∏´‡πâ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô                                                | Query Construction, Agents, Post-Processing, Evaluation | Build Agentic RAG with LlamaIndex - Notebook                              | [https://colab.research.google.com/drive/1qW7uNR3S3h1l_9h2xS2KX9rvzX-VVvMang](https://colab.research.google.com/drive/1qW7uNR3S3h1l_9h2xS2KX9rvzX-VVvMang) |
| 9     | Advanced RAG                  | ‡∏û‡∏±‡∏í‡∏ô‡∏≤ RAG ‡πÉ‡∏´‡πâ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô                                                | Query Construction, Agents, Post-Processing, Evaluation | LangChain - SQL with RAG - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠                                         | [https://python.langchain.com/docs/use_cases/qa_structured/sql](https://python.langchain.com/docs/use_cases/qa_structured/sql) |
| 10    | Inference Optimization        | ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô LLMs ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î Latency ‡πÅ‡∏•‡∏∞‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥                                  | Flash Attention, Key-Value Cache Optimization, Speculative Decoding, Dynamic Batching, Hardware Acceleration | Hugging Face - GPU Inference - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠                                     | [https://huggingface.co/docs/transformers/main/en/perf_infer_gpu_one](https://huggingface.co/docs/transformers/main/en/perf_infer_gpu_one) |
| 11    | Inference Optimization        | ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô LLMs ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î Latency ‡πÅ‡∏•‡∏∞‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥                                  | Flash Attention, Key-Value Cache Optimization, Speculative Decoding, Dynamic Batching, Hardware Acceleration | Databricks - LLM Inference - Best Practices                              | [https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices](https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices) |
| 12    | Deploying LLMs                | ‡∏ô‡∏≥ LLMs ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô Production                                                         | Local Deployment, Demo Applications, Server Deployment, Cloud Options | Deploy LLM with Gradio - Notebook                                         | [https://colab.research.google.com/drive/1xXw0qlv-GZzovmWv2sTjMcgrKkN6gR4S](https://colab.research.google.com/drive/1xXw0qlv-GZzovmWv2sTjMcgrKkN6gR4S) |
| 13    | Deploying LLMs                | ‡∏ô‡∏≥ LLMs ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô Production                                                         | Local Deployment, Demo Applications, Server Deployment, Cloud Options | Streamlit - LLM App - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠                                              | [https://docs.streamlit.io/knowledge-base/tutorials/build-conversational-apps](https://docs.streamlit.io/knowledge-base/tutorials/build-conversational-apps) |
| 14    | Securing LLMs                 | ‡∏õ‡∏Å‡∏õ‡πâ‡∏≠‡∏á LLMs ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°                                            | Prompt Hacking, Defensive Measures, Monitoring | OWASP LLM Top 10 - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á                                              | [https://owasp.org/www-project-top-10-for-large-language-model-applications/](https://owasp.org/www-project-top-10-for-large-language-model-applications/) |
| 15    | Securing LLMs                 | ‡∏õ‡∏Å‡∏õ‡πâ‡∏≠‡∏á LLMs ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°                                            | Prompt Hacking, Defensive Measures, Monitoring | LLM Security - ‡πÇ‡∏î‡∏¢ Lakera                                                | [https://llmsecurity.net/](https://llmsecurity.net/)                                            |
| 16    | Advanced Scripts and Repositories | ‡∏£‡∏ß‡∏°‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏•‡∏∞ Repository ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô LLM                                            | LangChain, LlamaIndex, Unsloth, Awesome Colab | LangChain - RAG ‡πÅ‡∏•‡∏∞ Agents                                                | [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)          |
| 17    | Advanced Scripts and Repositories | ‡∏£‡∏ß‡∏°‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏•‡∏∞ Repository ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô LLM                                            | LangChain, LlamaIndex, Unsloth, Awesome Colab | LlamaIndex - Data Ingestion ‡πÅ‡∏•‡∏∞ Query                                     | [https://github.com/run-llama/llama_index](https://github.com/run-llama/llama_index)            |
| 18    | Advanced Scripts and Repositories | ‡∏£‡∏ß‡∏°‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏•‡∏∞ Repository ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô LLM                                            | LangChain, LlamaIndex, Unsloth, Awesome Colab | Unsloth: Qwen 2 VL (7B) - Vision - Multimodal                            | [https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2_VL_(7B)-Vision.ipynb](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2_VL_(7B)-Vision.ipynb) |
| 19    | Advanced Scripts and Repositories | ‡∏£‡∏ß‡∏°‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏•‡∏∞ Repository ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô LLM                                            | LangChain, LlamaIndex, Unsloth, Awesome Colab | Awesome Colab: Text Generation WebUI - Local Deployment                  | [https://colab.research.google.com/github/oobabooga/text-generation-webui/blob/main/notebooks/colab.ipynb](https://colab.research.google.com/github/oobabooga/text-generation-webui/blob/main/notebooks/colab.ipynb) |


### ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏
- ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ 1-7 ‡πÅ‡∏•‡∏∞ Advanced Scripts and Repositories ‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô "The LLM Engineer - Building LLM Applications"
---

### üöÄ How to Proceed

1.  **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô:** ‡∏£‡∏±‡∏ô LLM ‡∏î‡πâ‡∏ß‡∏¢ API ‡∏´‡∏£‡∏∑‡∏≠ Local
2.  **‡∏™‡∏£‡πâ‡∏≤‡∏á RAG:** ‡πÉ‡∏ä‡πâ LangChain/LlamaIndex
3.  **‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á:** ‡πÄ‡∏û‡∏¥‡πà‡∏° Agents ‡∏´‡∏£‡∏∑‡∏≠ Optimize Inference
4.  **Deploy:** ‡∏•‡∏≠‡∏á Gradio ‡∏´‡∏£‡∏∑‡∏≠ TGI


# Awesome AI/LLM Learning Resources for 2025 (Part 4/4)

*‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: 4 ‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏° 2025*
*‡∏ó‡∏µ‡πà‡∏°‡∏≤: ‡∏î‡∏±‡∏î‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å [Unsloth Notebooks](https://github.com/unslothai/notebooks), [Awesome Colab Notebooks](https://github.com/amrzv/awesome-colab-notebooks), [Origins AI](https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/), ‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°*

## Part 4: GitHub Repositories and Advanced Scripts

‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö GitHub ‡πÅ‡∏•‡∏∞ Scripts ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô AI, Machine Learning (ML), Deep Learning (DL) ‡πÅ‡∏•‡∏∞ Large Language Models (LLMs) ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏π‡∏á ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á Fine-Tuning, Distributed Training ‡πÅ‡∏•‡∏∞ Advanced Applications ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

---

### üìÇ GitHub Repositories
‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô "GitHub Repositories and Advanced Scripts" (‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ 1-5 ‡πÅ‡∏•‡∏∞ Advanced Scripts ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á Research Papers) ‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡πÇ‡∏î‡∏¢‡∏à‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå "‡∏•‡∏≥‡∏î‡∏±‡∏ö", "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠", "‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢", "‡∏´‡∏°‡∏ß‡∏î‡∏¢‡πà‡∏≠‡∏¢/‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á", "‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", ‡πÅ‡∏•‡∏∞ "‡∏•‡∏¥‡∏á‡∏Å‡πå" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏π‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á GitHub Repositories and Advanced Scripts

| ‡∏•‡∏≥‡∏î‡∏±‡∏ö | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠                          | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                   | ‡∏´‡∏°‡∏ß‡∏î‡∏¢‡πà‡∏≠‡∏¢/‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á                     | ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
|-------|--------------------------------|-------------------------------------------------------------------------------------------|---------------------------------------|----------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| 1     | Unsloth Notebooks             | ‡∏Ñ‡∏•‡∏±‡∏á Notebooks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning ‡πÅ‡∏•‡∏∞ Inference LLMs ‡∏ö‡∏ô Google Colab ‡πÅ‡∏•‡∏∞ Kaggle              | GRPO Notebooks                       | Phi 4 (14B) - GRPO - Fine-Tuning ‡∏î‡πâ‡∏ß‡∏¢ GRPO                                 | [https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4_(14B)-GRPO.ipynb](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4_(14B)-GRPO.ipynb) |
| 2     | Unsloth Notebooks             | ‡∏Ñ‡∏•‡∏±‡∏á Notebooks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning ‡πÅ‡∏•‡∏∞ Inference LLMs ‡∏ö‡∏ô Google Colab ‡πÅ‡∏•‡∏∞ Kaggle              | Llama Notebooks                      | Llama 3.2 (1B and 3B) - Conversational                                    | [https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb) |
| 3     | Unsloth Notebooks             | ‡∏Ñ‡∏•‡∏±‡∏á Notebooks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning ‡πÅ‡∏•‡∏∞ Inference LLMs ‡∏ö‡∏ô Google Colab ‡πÅ‡∏•‡∏∞ Kaggle              | Mistral Notebooks                    | Mistral Small (22B) - Alpaca                                              | [https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_Small_(22B)-Alpaca.ipynb](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_Small_(22B)-Alpaca.ipynb) |
| 4     | Awesome Colab Notebooks       | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Notebooks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ML Experiments ‡πÅ‡∏•‡∏∞ Research                                      | Courses                              | ARENA - ML Engineering ‡πÇ‡∏î‡∏¢ Callum McDougall                               | [https://colab.research.google.com/drive/1vuQOB2Gd7OcfzH2y9djXm9OdZA_DcxYz](https://colab.research.google.com/drive/1vuQOB2Gd7OcfzH2y9djXm9OdZA_DcxYz) |
| 5     | Awesome Colab Notebooks       | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Notebooks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ML Experiments ‡πÅ‡∏•‡∏∞ Research                                      | Research                             | AlphaFold - Protein Structure Prediction                                  | [https://colab.research.google.com/github/deepmind/alphafold/blob/master/notebooks/AlphaFold.ipynb](https://colab.research.google.com/github/deepmind/alphafold/blob/master/notebooks/AlphaFold.ipynb) |
| 6     | AI-ML-DL Projects             | 40+ ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå AI/ML/DL ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÇ‡∏Ñ‡πâ‡∏î‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                | Examples                             | 365 Days Computer Vision - ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå CV ‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô                             | [https://github.com/theakash07/AI-ML-DL-Projects/tree/main/365-Days-Computer-Vision-Learning](https://github.com/theakash07/AI-ML-DL-Projects/tree/main/365-Days-Computer-Vision-Learning) |
| 7     | AI-ML-DL Projects             | 40+ ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå AI/ML/DL ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÇ‡∏Ñ‡πâ‡∏î‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                | Examples                             | 125+ NLP Language Models - ‡∏£‡∏ß‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏• NLP                                  | [https://github.com/theakash07/AI-ML-DL-Projects/tree/main/125-NLP-Language-Models](https://github.com/theakash07/AI-ML-DL-Projects/tree/main/125-NLP-Language-Models) |
| 8     | ml-systems-papers             | ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏° Paper ‡πÅ‡∏•‡∏∞ Scripts ‡∏à‡∏≤‡∏Å‡∏á‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏ä‡∏±‡πâ‡∏ô‡∏ô‡∏≥ (SOSP, NeurIPS, SC)                           | Examples                             | FractalTensor - Nested Data Parallelism                                   | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SOSP24_FractalTensor](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SOSP24_FractalTensor) |
| 9     | Additional Repositories       | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô NLP, RAG ‡πÅ‡∏•‡∏∞ Data Ingestion                                      | Hugging Face Transformers            | Library ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NLP ‡πÅ‡∏•‡∏∞ LLMs                                               | [https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)       |
| 10    | Additional Repositories       | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô NLP, RAG ‡πÅ‡∏•‡∏∞ Data Ingestion                                      | LangChain                            | RAG ‡πÅ‡∏•‡∏∞ Agents                                                            | [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)          |
| 11    | Advanced Scripts - Fine-Tuning & Optimization | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning ‡πÅ‡∏•‡∏∞ Optimization                                         | FractalTensor                        | Nested Data Parallelism ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Training LLMs                              | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SOSP24_FractalTensor](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SOSP24_FractalTensor) |
| 12    | Advanced Scripts - Fine-Tuning & Optimization | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning ‡πÅ‡∏•‡∏∞ Optimization                                         | QLoRA Fine-Tuning                    | Fine-Tuning LLMs ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏î‡πâ‡∏ß‡∏¢ 4-bit Quantization                | [https://github.com/georgesung/llm_qlora/blob/main/train.py](https://github.com/georgesung/llm_qlora/blob/main/train.py) |
| 13    | Advanced Scripts - Distributed Training | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Distributed Training                                                | Democratizing AI                     | ‡∏ù‡∏∂‡∏Å LLMs ‡∏ö‡∏ô GPU Supercomputers                                            | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SC24_GPU_Supercomputers](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SC24_GPU_Supercomputers) |
| 14    | Advanced Scripts - Distributed Training | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Distributed Training                                                | TorchTitan                           | PyTorch Native Solution ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Distributed Training                      | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_TorchTitan](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_TorchTitan) |
| 15    | Advanced Scripts - Advanced Applications | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Advanced Applications                                              | DeepSpeed-Ulysses                    | Long-Sequence Transformers ‡∏î‡πâ‡∏ß‡∏¢ DeepSpeed                                | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_DeepSpeed-Ulysses](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_DeepSpeed-Ulysses) |
| 16    | Research Papers - Fine-Tuning | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö Fine-Tuning                                                  | QLoRA                                | Quantized LoRA                                                            | [https://arxiv.org/abs/2305.14314](https://arxiv.org/abs/2305.14314)                           |
| 17    | Research Papers - Fine-Tuning | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö Fine-Tuning                                                  | LongLoRA                             | Long-Context Fine-Tuning                                                  | [https://arxiv.org/abs/2309.12307](https://arxiv.org/abs/2309.12307)                           |
| 18    | Research Papers - Distributed Training | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö Distributed Training                                        | Democratizing AI                     | GPU Supercomputers                                                        | [https://arxiv.org/abs/2409.12345](https://arxiv.org/abs/2409.12345)                           |
| 19    | Research Papers - Advanced Techniques | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á                                                | Flash Attention                      | Optimized Attention                                                       | [https://arxiv.org/abs/2205.14135](https://arxiv.org/abs/2205.14135)                           |
| 20    | Research Papers - Advanced Techniques | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á                                                | Speculative Decoding                 | Faster Inference                                                          | [https://arxiv.org/abs/2211.17192](https://arxiv.org/abs/2211.17192)                           |


### ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏
- ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ 1-5 (Repositories), Advanced Scripts (Fine-Tuning & Optimization, Distributed Training, Advanced Applications) ‡πÅ‡∏•‡∏∞ Research Papers 
---

### üöÄ How to Proceed

1.  **Explore Repositories:** ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Repository ‡∏ó‡∏µ‡πà‡∏™‡∏ô‡πÉ‡∏à (‡πÄ‡∏ä‡πà‡∏ô Unsloth, Awesome Colab)
2.  **Review Scripts:** ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ Advanced Scripts ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏´‡∏°‡πà ‡πÜ
3.  **Read Papers:** ‡∏≠‡πà‡∏≤‡∏ô Research Papers ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å‡∏ñ‡∏∂‡∏á‡∏ó‡∏§‡∏©‡∏é‡∏µ
4. **Test**: Try a notebook from each section.
5. **Create**: Start building your project.

---

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á DeepSeek AI GitHub Repositories (Part 5)

| ‡∏•‡∏≥‡∏î‡∏±‡∏ö | ‡∏ä‡∏∑‡πà‡∏≠                        | URL                                                                                   | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                                   | ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô                                                                                             |
|-------|-----------------------------|---------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|
| 1     | DeepEP                     | [https://github.com/deepseek-ai/DeepEP](https://github.com/deepseek-ai/DeepEP)         | ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡πÅ‡∏ö‡∏ö Expert-Parallel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á ‡∏ä‡πà‡∏ß‡∏¢‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å AI ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà | ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏Ñ‡πâ‡∏î, ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies (‡πÄ‡∏ä‡πà‡∏ô PyTorch), ‡∏£‡∏ß‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö Pipeline ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÇ‡∏î‡∏¢‡∏Å‡∏≥‡∏´‡∏ô‡∏î Expert Modules ‡πÉ‡∏ô Config |
| 2     | 3FS                        | [https://github.com/deepseek-ai/3FS](https://github.com/deepseek-ai/3FS)               | ‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞ Inference AI ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞               | ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ú‡πà‡∏≤‡∏ô Docker ‡∏´‡∏£‡∏∑‡∏≠ Source Code, ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Cluster Configuration, ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ö Framework ‡πÄ‡∏ä‡πà‡∏ô TensorFlow ‡∏´‡∏£‡∏∑‡∏≠ PyTorch |
| 3     | DeepGEMM                   | [https://github.com/deepseek-ai/DeepGEMM](https://github.com/deepseek-ai/DeepGEMM)     | Kernel GEMM ‡πÅ‡∏ö‡∏ö FP8 ‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î (Fine-grained Scaling) | ‡∏£‡∏ß‡∏° Kernel ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• Deep Learning, ‡∏Ñ‡∏≠‡∏°‡πÑ‡∏û‡∏•‡πå‡∏î‡πâ‡∏ß‡∏¢ CUDA, ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Layer ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ GEMM                |
| 4     | open-infra-index           | [https://github.com/deepseek-ai/open-infra-index](https://github.com/deepseek-ai/open-infra-index) | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô AI ‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô Production ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏û‡∏±‡∏í‡∏ô‡∏≤ AGI ‡πÅ‡∏•‡∏∞‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°‡∏ä‡∏∏‡∏°‡∏ä‡∏ô     | ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏à‡∏≤‡∏Å Index, ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≤‡∏°‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÉ‡∏ô README, ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Workflow ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì                           |
| 5     | profile-data               | [https://github.com/deepseek-ai/profile-data](https://github.com/deepseek-ai/profile-data) | ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡πÉ‡∏ô DeepSeek-V3/R1                              | ‡∏£‡∏±‡∏ô Script ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏±‡∏ö Log ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å, ‡πÉ‡∏ä‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏õ‡∏£‡∏±‡∏ö Hyperparameters ‡∏´‡∏£‡∏∑‡∏≠ Pipeline                      |
| 6     | awesome-deepseek-integration | [https://github.com/deepseek-ai/awesome-deepseek-integration](https://github.com/deepseek-ai/awesome-deepseek-integration) | ‡∏£‡∏ß‡∏°‡∏ß‡∏¥‡∏ò‡∏µ‡∏ú‡∏™‡∏≤‡∏ô DeepSeek API ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏° ‡πÄ‡∏ä‡πà‡∏ô IDEs ‡πÅ‡∏•‡∏∞‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏≠‡∏∑‡πà‡∏ô ‡πÜ              | ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ (‡πÄ‡∏ä‡πà‡∏ô VS Code), ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡πÇ‡∏Ñ‡πâ‡∏î‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á, ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏î‡πâ‡∏ß‡∏¢ API Key                    |
| 7     | smallpond                  | [https://github.com/deepseek-ai/smallpond](https://github.com/deepseek-ai/smallpond)   | ‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Å‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏ö‡∏≤ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ô DuckDB ‡πÅ‡∏•‡∏∞ 3FS                                     | ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á DuckDB ‡πÅ‡∏•‡∏∞ 3FS, ‡∏£‡∏±‡∏ô Script ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô README, ‡∏õ‡πâ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•                         |

---

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Fine-Tuning AI Models (Part 6 ‡πÅ‡∏•‡∏∞ Uncensored AI Models)

| ‡∏•‡∏≥‡∏î‡∏±‡∏ö | ‡∏ä‡∏∑‡πà‡∏≠                                              | GitHub/Hugging Face                                                                                  | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                                   | Script ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á                                                                                             |
|-------|--------------------------------------------------|-----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|
|  |                                                                                                     |                                                                                              |                                                                                              |                                                                                                            |
| 1     | QLoRA Fine-Tuning Pipeline                      | [WeixuanJiang/Qlora-Fine-Tuning-Pipeline](https://github.com/WeixuanJiang/Qlora-Fine-Tuning-Pipeline) | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô QLoRA ‡∏û‡∏£‡πâ‡∏≠‡∏° Script ‡πÅ‡∏•‡∏∞ Configuration Files                     | [Train Script](https://github.com/WeixuanJiang/Qlora-Fine-Tuning-Pipeline/blob/main/scripts/run_training.bat), [Merge Script](https://github.com/WeixuanJiang/Qlora-Fine-Tuning-Pipeline/blob/main/scripts/run_merge_multiple_loras.bat) |
| 2     | LLM Fine-Tuning for Programming Queries         | [Avani1297/LLM-Fine-Tuning-Project-for-Programming-Queries](https://github.com/Avani1297/LLM-Fine-Tuning-Project-for-Programming-Queries) | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏ö‡∏ô Stack Overflow datasets ‡∏ú‡πà‡∏≤‡∏ô Hugging Face ‡πÅ‡∏•‡∏∞ Vast.ai            | [Fine-Tuning Script](https://github.com/Avani1297/LLM-Fine-Tuning-Project-for-Programming-Queries/blob/main/train.py) |
| 3     | FLUX.1 Fine-Tuning                              | [black-forest-labs/FLUX.1-dev](https://huggingface.co/black-forest-labs/FLUX.1-dev/discussions/196) | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning FLUX.1 ‡∏ú‡πà‡∏≤‡∏ô AI Toolkit                                                   | [Train Script](https://github.com/ostris/ai-toolkit/blob/main/train_lora_flux_24gb.py)                     |
| 4     | Llama-2 Fine-Tuning with QLoRA                  | [mert-delibalta/llama2-fine-tune-qlora](https://github.com/mert-delibalta/llama2-fine-tune-qlora)   | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning Llama-2 ‡∏ú‡πà‡∏≤‡∏ô QLoRA ‡∏û‡∏£‡πâ‡∏≠‡∏° Script ‡πÅ‡∏•‡∏∞ Configuration Files                  | [Fine-Tuning Script](https://github.com/mert-delibalta/llama2-fine-tune-qlora/blob/main/train.py)          |
| 5     | BERT Fine-Tuning with NVIDIA NGC                | [Fine-Tune and Optimize BERT](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/bert_workshop)  | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning BERT ‡∏ú‡πà‡∏≤‡∏ô NVIDIA NGC                                                     | [Training Notebook](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/bert_workshop)                   |
| 6     | Llama2 Fine-Tuning with QLoRA (torchtune)       | [Fine-Tuning Llama2 with QLoRA](https://pytorch.org/torchtune/stable/tutorials/qlora_finetune.html) | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning Llama2 ‡∏ú‡πà‡∏≤‡∏ô QLoRA ‡∏û‡∏£‡πâ‡∏≠‡∏° Script ‡πÅ‡∏•‡∏∞ Configuration Files                   | [Fine-Tuning Command](https://pytorch.org/torchtune/stable/tutorials/qlora_finetune.html)                  |
| **Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning Uncensored AI Models** |                                                                                                     |                                                                                              |                                                                                              |                                                                                                            |
| 7     | Fine-Tuning LLMs using QLoRA                    | [georgesung/llm_qlora](https://github.com/georgesung/llm_qlora)                                     | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô QLoRA ‡∏û‡∏£‡πâ‡∏≠‡∏° Script ‡πÅ‡∏•‡∏∞ Configuration Files                     | [Train Script](https://github.com/georgesung/llm_qlora/blob/main/train.py), [Config File](https://github.com/georgesung/llm_qlora/blob/main/configs/llama3_8b_chat_uncensored.yaml) |
| 8     | Fine-Tuning LLMs with Kiln AI                   | [Kiln-AI/kiln](https://github.com/Kiln-AI/kiln)                                                     | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô Kiln AI ‡∏û‡∏£‡πâ‡∏≠‡∏° UI ‡πÅ‡∏•‡∏∞ Synthetic Data Generation                 | [Fine-Tuning Guide](https://github.com/Kiln-AI/kiln/blob/main/guides/Fine%20Tuning%20LLM%20Models%20Guide.md) |
| 9     | Fine-Tuning LLMs with Hugging Face              | [Acerkhan/generative-ai-with-MS](https://github.com/Acerkhan/generative-ai-with-MS/blob/main/18-fine-tuning/README.md) | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô Hugging Face Transformers ‡∏û‡∏£‡πâ‡∏≠‡∏° Step-by-Step Tutorial         | [Fine-Tuning Script](https://github.com/Acerkhan/generative-ai-with-MS/blob/main/18-fine-tuning/README.md) |
| 10    | Fine-Tuning LLMs with Node-RED Flow             | [rozek/node-red-flow-gpt4all-unfiltered](https://github.com/rozek/node-red-flow-gpt4all-unfiltered) | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning GPT4All ‡∏ú‡πà‡∏≤‡∏ô Node-RED Flow ‡∏û‡∏£‡πâ‡∏≠‡∏° Function Node                           | [Function Node](https://github.com/rozek/node-red-flow-gpt4all-unfiltered/blob/main/GPT4All-unfiltered-Function.json) |
| 11    | Fine-Tuning LLMs with OpenAI                    | [OpenAI Fine-Tuning](https://github.com/openai/openai-python/blob/main/examples/fine_tuning.py)     | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô OpenAI API ‡∏û‡∏£‡πâ‡∏≠‡∏° Script ‡πÅ‡∏•‡∏∞ Example                            | [Fine-Tuning Script](https://github.com/openai/openai-python/blob/main/examples/fine_tuning.py)            |
| 12    | Fine-Tuning LLMs with Azure OpenAI              | [Azure OpenAI Fine-Tuning](https://github.com/Azure/azure-ai-openai/blob/main/samples/fine_tuning.ipynb) | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô Azure OpenAI Service ‡∏û‡∏£‡πâ‡∏≠‡∏° Notebook ‡πÅ‡∏•‡∏∞ Example               | [Fine-Tuning Notebook](https://github.com/Azure/azure-ai-openai/blob/main/samples/fine_tuning.ipynb)       |
| 13    | Fine-Tuning LLMs with AWS SageMaker             | [AWS SageMaker Fine-Tuning](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/transformers/transformers_fine_tuning.ipynb) | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô AWS SageMaker ‡∏û‡∏£‡πâ‡∏≠‡∏° Notebook ‡πÅ‡∏•‡∏∞ Example                     | [Fine-Tuning Notebook](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/transformers/transformers_fine_tuning.ipynb) |
| 14    | Fine-Tuning LLMs with Google AI                 | [Google AI Fine-Tuning](https://github.com/googleapis/python-aiplatform/blob/main/samples/v1beta1/fine_tune_model_sample.py) | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô Google AI Platform ‡∏û‡∏£‡πâ‡∏≠‡∏° Script ‡πÅ‡∏•‡∏∞ Example                   | [Fine-Tuning Script](https://github.com/googleapis/python-aiplatform/blob/main/samples/v1beta1/fine_tune_model_sample.py) |
| 15    | Fine-Tuning LLMs with Microsoft DeepSpeed       | [Microsoft DeepSpeed](https://github.com/microsoft/DeepSpeed/blob/main/examples/fine_tune.py)       | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô Microsoft DeepSpeed ‡∏û‡∏£‡πâ‡∏≠‡∏° Script ‡πÅ‡∏•‡∏∞ Example                   | [Fine-Tuning Script](https://github.com/microsoft/DeepSpeed/blob/main/examples/fine_tune.py)               |
| 16    | Fine-Tuning LLMs with NVIDIA Triton             | [NVIDIA Triton](https://github.com/NVIDIA/triton-inference-server/blob/main/docs/Training.md)       | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô NVIDIA Triton ‡∏û‡∏£‡πâ‡∏≠‡∏° Documentation ‡πÅ‡∏•‡∏∞ Example                  | [Fine-Tuning Documentation](https://github.com/NVIDIA/triton-inference-server/blob/main/docs/Training.md)  |

---

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Fine-Tuning AI Models ‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏û‡∏¥‡πÄ‡∏®‡∏©

| ‡∏•‡∏≥‡∏î‡∏±‡∏ö | ‡∏ä‡∏∑‡πà‡∏≠                                              | GitHub                                                                                  | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                                   | Script ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á                                                                                             |
|-------|--------------------------------------------------|-----------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|
| 1     | Azure OpenAI Service                            | [Azure OpenAI Fine-Tuning](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning) | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô Azure OpenAI Service ‡∏û‡∏£‡πâ‡∏≠‡∏° Code Example ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Environment | [Fine-Tuning Code](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning#create-a-custom-model), [Upload Training Data](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning#upload-your-training-data) |
| 2     | AWS SageMaker                                   | [AWS SageMaker Fine-Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/fine-tuning.html) | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô AWS SageMaker ‡∏û‡∏£‡πâ‡∏≠‡∏° Code Example ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Environment | [Fine-Tuning Code](https://docs.aws.amazon.com/sagemaker/latest/dg/fine-tuning.html#create-a-fine-tuning-job) |
| 3     | Hugging Face Transformers                       | [huggingface/transformers](https://github.com/huggingface/transformers)                 | Library ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning AI Models ‡πÄ‡∏ä‡πà‡∏ô BERT, GPT, ‡πÅ‡∏•‡∏∞ Llama ‡∏ú‡πà‡∏≤‡∏ô PyTorch/TensorFlow         | [Fine-Tuning Code](https://huggingface.co/docs/transformers/main/en/training)                              |
| 4     | Microsoft Phi Models                            | [microsoft/Phi-3](https://github.com/microsoft/Phi-3)                                   | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning Phi Models ‡∏ú‡πà‡∏≤‡∏ô Azure AI Foundry ‡∏´‡∏£‡∏∑‡∏≠ ONNX Runtime                       | [Fine-Tuning Code](https://github.com/microsoft/Phi-3/blob/main/README.md#fine-tuning)                     |
| 5     | Llama Factory                                   | [Llama Factory](https://github.com/ai-forever/Llama-Factory)                            | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning Llama Models ‡∏ú‡πà‡∏≤‡∏ô LoRA ‡πÅ‡∏•‡∏∞ P-Tuning                                      | [Fine-Tuning Code](https://github.com/ai-forever/Llama-Factory/blob/main/README.md#fine-tuning)            |
| 6     | FastAI                                          | [fastai/fastai](https://github.com/fastai/fastai)                                       | Framework ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô PyTorch                                         | [Fine-Tuning Code](https://github.com/fastai/fastai/blob/main/tutorial/fine_tuning.ipynb)                  |
| 7     | PyTorch Lightning                               | [pytorch-lightning/pytorch-lightning](https://github.com/pytorch-lightning/pytorch-lightning) | Framework ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô PyTorch Lightning                              | [Fine-Tuning Code](https://github.com/pytorch-lightning/pytorch-lightning/blob/main/examples/domain_templates/fine_tuning.ipynb) |
| 8     | TensorFlow                                      | [tensorflow/models](https://github.com/tensorflow/models)                               | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô TensorFlow                                | [Fine-Tuning Code](https://github.com/tensorflow/models/tree/main/official/vision)                         |
| 9     | Keras                                           | [keras-team/keras](https://github.com/keras-team/keras)                                 | Library ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô Keras                                             | [Fine-Tuning Code](https://keras.io/examples/vision/image_classification_efficientnet/)                    |
| 10    | ONNX Runtime                                    | [onnx/onnx](https://github.com/onnx/onnx)                                               | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô ONNX Runtime                                              | [Fine-Tuning Code](https://github.com/onnx/onnx/blob/main/docs/Training.md)                                |
| 11    | OpenVINO Toolkit                                | [intel/openvino](https://github.com/intel/openvino)                                     | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô OpenVINO Toolkit                                          | [Fine-Tuning Code](https://github.com/intel/openvino/blob/main/docs/Training.md)                           |
| 12    | TPU                                             | [tensorflow/tpu](https://github.com/tensorflow/tpu)                                     | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô TPU                                                       | [Fine-Tuning Code](https://github.com/tensorflow/tpu/blob/main/models/official/vision/image_classification/fine_tune.py) |
| 13    | AWS Neuron                                      | [aws-neuron/aws-neuron-sdk](https://github.com/aws-neuron/aws-neuron-sdk)               | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô AWS Neuron                                                | [Fine-Tuning Code](https://github.com/aws-neuron/aws-neuron-sdk/blob/main/docs/Training.md)                |
| 14    | Azure ML                                        | [Azure/azure-ml-samples](https://github.com/Azure/azure-ml-samples)                     | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô Azure ML                                                  | [Fine-Tuning Code](https://github.com/Azure/azure-ml-samples/blob/main/notebooks/python/finetune_model.ipynb) |
| 15    | AWS SageMaker Neo                               | [aws-samples/sagemaker-neo](https://github.com/aws-samples/sagemaker-neo)               | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô AWS SageMaker Neo                                         | [Fine-Tuning Code](https://github.com/aws-samples/sagemaker-neo/blob/main/docs/Training.md)                |
| 16    | Microsoft DeepSpeed                             | [microsoft/DeepSpeed](https://github.com/microsoft/DeepSpeed)                           | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô DeepSpeed                                                 | [Fine-Tuning Code](https://github.com/microsoft/DeepSpeed/blob/main/examples/fine_tune.py)                 |
| 17    | NVIDIA Triton                                   | [NVIDIA/triton-inference-server](https://github.com/NVIDIA/triton-inference-server)     | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô NVIDIA Triton                                            | [Fine-Tuning Code](https://github.com/NVIDIA/triton-inference-server/blob/main/docs/Training.md)           |
| 18    | Intel Optimization for Transformers             | [intel/transformers](https://github.com/intel/transformers)                             | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô Intel Optimization                                        | [Fine-Tuning Code](https://github.com/intel/transformers/blob/main/examples/fine_tune.py)                  |
| 19    | AWS Inferentia                                  | [aws-samples/inferentia-training](https://github.com/aws-samples/inferentia-training)   | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô AWS Inferentia                                            | [Fine-Tuning Code](https://github.com/aws-samples/inferentia-training/blob/main/docs/Training.md)          |
| 20    | Microsoft ONNX Runtime                          | [microsoft/onnxruntime](https://github.com/microsoft/onnxruntime)                       | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning AI Models ‡∏ú‡πà‡∏≤‡∏ô ONNX Runtime                                              | [Fine-Tuning Code](https://github.com/microsoft/onnxruntime/blob/main/docs/Training.md)                    |

---
‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å "Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning AI ‡∏ö‡∏ô Google Cloud ‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏û‡∏¥‡πÄ‡∏®‡∏©" ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡πÇ‡∏î‡∏¢‡∏à‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå "‡∏•‡∏≥‡∏î‡∏±‡∏ö", "‡∏ä‡∏∑‡πà‡∏≠", "GitHub/Link", "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î", ‡πÅ‡∏•‡∏∞ "Script ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏π‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Fine-Tuning AI Models ‡∏ö‡∏ô Google Cloud ‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏û‡∏¥‡πÄ‡∏®‡∏©

| ‡∏•‡∏≥‡∏î‡∏±‡∏ö | ‡∏ä‡∏∑‡πà‡∏≠                                              | GitHub/Link                                                                                  | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                                   | Script ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á                                                                                             |
|-------|--------------------------------------------------|---------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|
| 1     | Vertex AI LLM Fine-Tuning Examples              | [arunpshankar/VAI-FineTuning-LLMs](https://github.com/arunpshankar/VAI-FineTuning-LLMs)     | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning LLMs ‡∏ö‡∏ô Vertex AI ‡πÄ‡∏ä‡πà‡∏ô Gemini 1.5 Pro, Llama 3.1, ‡πÅ‡∏•‡∏∞ Gemma 2 | [Gemini 1.5 Pro Fine-Tuning](https://github.com/arunpshankar/VAI-FineTuning-LLMs/tree/main/src/models/gemini_1_5), [Llama 3.1 Fine-Tuning](https://github.com/arunpshankar/VAI-FineTuning-LLMs/tree/main/src/models/llama_3_1) |
| 2     | Fine-Tuning Large Language Models with Vertex AI (Codelab) | [llm-finetuning-supervised](https://github.com/leodeveloper/fine-tune-with-google-cloud)    | Tutorial ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning LLMs ‡∏ö‡∏ô Google Cloud ‡∏ú‡πà‡∏≤‡∏ô Vertex AI SDK                          | [Fine-Tuning Code](https://github.com/leodeveloper/fine-tune-with-google-cloud/blob/main/fine_tune_vertex_ai.ipynb) |
| 3     | Fine-Tuning Large Language Models: How Vertex AI Takes LLMs to the Next Level | [Medium Article](https://medium.com/google-cloud/fine-tuning-large-language-models-how-vertex-ai-takes-llms-to-the-next-level-3c113f4007da) | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô Vertex AI SDK ‡∏û‡∏£‡πâ‡∏≠‡∏° Code Example                              | [Fine-Tuning Code](https://medium.com/google-cloud/fine-tuning-large-language-models-how-vertex-ai-takes-llms-to-the-next-level-3c113f4007da) |
| 4     | Keras AI/ML/DL Script Examples                  | [keras/examples](https://keras.io/examples/)                                                | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI/ML/DL ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏ä‡πà‡∏ô Image Classification, NLP, ‡πÅ‡∏•‡∏∞ Generative AI | [Image Classification with EfficientNet](https://keras.io/examples/vision/image_classification_efficientnet/), [Text Classification with Transformer](https://keras.io/examples/nlp/text_classification_with_transformer/) |
| 5     | Fine-Tuning AI Models on Google Cloud (Advanced Scripts) | [google-cloud-aiplatform](https://github.com/googleapis/python-aiplatform)                 | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Vertex AI SDK ‡πÄ‡∏ä‡πà‡∏ô Fine-Tuning, Hyperparameter Tuning, ‡πÅ‡∏•‡∏∞ Model Deployment | [Fine-Tuning Script](https://github.com/googleapis/python-aiplatform/blob/main/samples/v1beta1/fine_tune_model_sample.py) |
| 6     | Fine-Tuning AI Models with Google Cloud Vertex AI (Tutorial) | [vertex-ai-samples](https://github.com/GoogleCloudPlatform/vertex-ai-samples)             | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Script ‡πÅ‡∏•‡∏∞ Tutorial ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Vertex AI ‡πÄ‡∏ä‡πà‡∏ô Fine-Tuning ‡πÅ‡∏•‡∏∞ Model Deployment  | [Fine-Tuning LLMs](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/llm_fine_tuning.ipynb) |
| 7     | Fine-Tuning AI Models with Google Cloud AI Platform (Legacy) | [google-cloud-aiplatform](https://github.com/googleapis/python-aiplatform)                 | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Google Cloud AI Platform ‡πÄ‡∏ä‡πà‡∏ô Fine-Tuning ‡πÅ‡∏•‡∏∞ Model Training  | [Fine-Tuning Script](https://github.com/googleapis/python-aiplatform/blob/main/samples/v1beta1/fine_tune_model_sample.py) |
| 8     | Fine-Tuning AI Models with Google Cloud AutoML  | [automl-samples](https://github.com/GoogleCloudPlatform/automl-samples)                     | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Script ‡πÅ‡∏•‡∏∞ Tutorial ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô AutoML ‡πÄ‡∏ä‡πà‡∏ô Fine-Tuning ‡πÅ‡∏•‡∏∞ Model Deployment     | [Fine-Tuning Script](https://github.com/GoogleCloudPlatform/automl-samples/blob/main/vision/image_classification/fine_tune_model.py) |
| 9     | Fine-Tuning AI Models with Google Cloud TPU     | [tpu-examples](https://github.com/tensorflow/tpu)                                           | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô TPU ‡πÄ‡∏ä‡πà‡∏ô Fine-Tuning ‡πÅ‡∏•‡∏∞ Model Training                      | [Fine-Tuning Script](https://github.com/tensorflow/tpu/blob/main/models/official/vision/image_classification/fine_tune.py) |
| 10    | Fine-Tuning AI Models with Google Cloud AI Platform Pipelines | [ai-platform-pipelines](https://github.com/GoogleCloudPlatform/ai-platform-pipelines)       | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Script ‡πÅ‡∏•‡∏∞ Tutorial ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô AI Platform Pipelines ‡πÄ‡∏ä‡πà‡∏ô Fine-Tuning ‡πÅ‡∏•‡∏∞ Model Deployment | [Fine-Tuning Script](https://github.com/GoogleCloudPlatform/ai-platform-pipelines/blob/main/samples/fine_tune_model.py) |

---

### Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning AI

#### **GitHub Repository ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Script**
‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡∏≠‡∏á GitHub Repositories ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏´‡πâ‡∏°‡∏≤ ("AI-ML-DL Projects" ‡πÅ‡∏•‡∏∞ "ml-systems-papers") ‡πÇ‡∏î‡∏¢‡∏à‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå "‡∏•‡∏≥‡∏î‡∏±‡∏ö", "‡∏ä‡∏∑‡πà‡∏≠", "GitHub", "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î", ‡πÅ‡∏•‡∏∞ "Script ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏π‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á GitHub Repositories

| ‡∏•‡∏≥‡∏î‡∏±‡∏ö | ‡∏ä‡∏∑‡πà‡∏≠                 | GitHub                                                                                  | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                                   | Script ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á                                                                                             |
|-------|----------------------|-----------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|
| 1     | AI-ML-DL Projects   | [theakash07/AI-ML-DL-Projects](https://github.com/theakash07/AI-ML-DL-Projects)         | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå AI/ML/DL ‡∏Å‡∏ß‡πà‡∏≤ 40+ ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå ‡∏û‡∏£‡πâ‡∏≠‡∏° Code ‡πÅ‡∏•‡∏∞ Tutorial ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô         | [365 Days Computer Vision Learning](https://github.com/theakash07/AI-ML-DL-Projects/tree/main/365-Days-Computer-Vision-Learning) |
| 1.1   | AI-ML-DL Projects   | [theakash07/AI-ML-DL-Projects](https://github.com/theakash07/AI-ML-DL-Projects)         | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå AI/ML/DL ‡∏Å‡∏ß‡πà‡∏≤ 40+ ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå ‡∏û‡∏£‡πâ‡∏≠‡∏° Code ‡πÅ‡∏•‡∏∞ Tutorial ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô         | [125+ NLP Language Models](https://github.com/theakash07/AI-ML-DL-Projects/tree/main/125-NLP-Language-Models) |
| 1.2   | AI-ML-DL Projects   | [theakash07/AI-ML-DL-Projects](https://github.com/theakash07/AI-ML-DL-Projects)         | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå AI/ML/DL ‡∏Å‡∏ß‡πà‡∏≤ 40+ ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå ‡∏û‡∏£‡πâ‡∏≠‡∏° Code ‡πÅ‡∏•‡∏∞ Tutorial ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô         | [20 Deep Learning Projects](https://github.com/theakash07/AI-ML-DL-Projects/tree/main/20-Deep-Learning-Projects) |
| 2     | ml-systems-papers   | [byungsoo-oh/ml-systems-papers](https://github.com/byungsoo-oh/ml-systems-papers)       | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Paper ‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning AI ‡∏û‡∏£‡πâ‡∏≠‡∏° Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Fine-Tuning ‡πÅ‡∏•‡∏∞ Distributed Training | [FractalTensor](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SOSP24_FractalTensor)             |
| 2.1   | ml-systems-papers   | [byungsoo-oh/ml-systems-papers](https://github.com/byungsoo-oh/ml-systems-papers)       | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Paper ‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning AI ‡∏û‡∏£‡πâ‡∏≠‡∏° Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Fine-Tuning ‡πÅ‡∏•‡∏∞ Distributed Training | [LoongTrain](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_LoongTrain)                 |
| 2.2   | ml-systems-papers   | [byungsoo-oh/ml-systems-papers](https://github.com/byungsoo-oh/ml-systems-papers)       | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Paper ‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning AI ‡∏û‡∏£‡πâ‡∏≠‡∏° Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Fine-Tuning ‡πÅ‡∏•‡∏∞ Distributed Training | [PAFT](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_PAFT)                             |


### ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏
- ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≠‡∏á Repositories ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡πÇ‡∏î‡∏¢‡πÅ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡πà‡∏≠‡∏¢‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô

---

### **Script ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning AI**
‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô "Script ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning AI" (‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ Fine-Tuning ‡πÅ‡∏•‡∏∞ Optimization Techniques, Distributed Training ‡πÅ‡∏•‡∏∞ System Optimization, Advanced Fine-Tuning ‡πÅ‡∏•‡∏∞ Applications) ‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡πÇ‡∏î‡∏¢‡∏à‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå "‡∏•‡∏≥‡∏î‡∏±‡∏ö", "‡∏ä‡∏∑‡πà‡∏≠", "GitHub", "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î", ‡πÅ‡∏•‡∏∞ "‡∏•‡∏¥‡∏á‡∏Å‡πå" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏π‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Script ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning AI

| ‡∏•‡∏≥‡∏î‡∏±‡∏ö | ‡∏ä‡∏∑‡πà‡∏≠                       | GitHub                                                                                         | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                                   | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
|-------|----------------------------|------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| **Fine-Tuning ‡πÅ‡∏•‡∏∞ Optimization Techniques** |                                                                                                |                                                                                              |                                                                                              |                                                                                                  |
| 1     | FractalTensor             | [FractalTensor](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SOSP24_FractalTensor) | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning DNNs ‡∏ú‡πà‡∏≤‡∏ô Nested Data Parallelism ‡πÅ‡∏•‡∏∞ Data Reuse                   | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SOSP24_FractalTensor](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SOSP24_FractalTensor) |
| 2     | 4D Parallelism            | [4D-Parallelism](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_4D_Parallelism) | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å LLMs ‡∏ú‡πà‡∏≤‡∏ô 4D Parallelism                                     | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_4D_Parallelism](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_4D_Parallelism) |
| 3     | Memory-Communication Optimization | [Memory-Communication](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/NeurIPS24_Memory_Communication) | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å LLMs ‡∏ú‡πà‡∏≤‡∏ô Data Parallelism                                  | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/NeurIPS24_Memory_Communication](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/NeurIPS24_Memory_Communication) |
| 4     | LoongTrain                | [LoongTrain](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_LoongTrain)     | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning LLMs ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Sequence ‡∏¢‡∏≤‡∏ß‡∏ú‡πà‡∏≤‡∏ô Head-Context Parallelism              | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_LoongTrain](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_LoongTrain)     |
| 5     | PAFT                      | [PAFT](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_PAFT)                 | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô Parallel Training Paradigm                               | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_PAFT](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_PAFT)                 |
| 6     | Survey on Distributed Training | [Survey](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_Survey)             | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏ö‡∏ô Distributed Infrastructures                             | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_Survey](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_Survey)             |
| 7     | BPipe                     | [BPipe](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_BPipe)               | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û Pipeline Parallelism                                           | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_BPipe](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_BPipe)               |
| 8     | InternEvo                 | [InternEvo](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_InternEvo)       | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô Hybrid Parallelism ‡πÅ‡∏•‡∏∞ Redundant Sharding                | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_InternEvo](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_InternEvo)       |
| 9     | Vision Transformers       | [Vision-Transformers](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Vision_Transformers) | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning Vision Transformers ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà                                       | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Vision_Transformers](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Vision_Transformers) |
| 10    | Colossal-Auto             | [Colossal-Auto](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Colossal-Auto) | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ Parallelization ‡πÅ‡∏•‡∏∞ Activation Checkpoint                     | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Colossal-Auto](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Colossal-Auto) |
| **Distributed Training ‡πÅ‡∏•‡∏∞ System Optimization** |                                                                                                |                                                                                              |                                                                                              |                                                                                                  |
| 11    | Democratizing AI          | [GPU-Supercomputers](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SC24_GPU_Supercomputers) | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning LLMs ‡∏ö‡∏ô GPU-based Supercomputers                                   | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SC24_GPU_Supercomputers](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SC24_GPU_Supercomputers) |
| 12    | PipeFill                  | [PipeFill](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_PipeFill)         | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û Pipeline-parallel Training                                     | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_PipeFill](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_PipeFill)         |
| 13    | Poplar                    | [Poplar](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_Poplar)             | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning DNNs ‡∏ö‡∏ô Heterogeneous GPU Clusters                                 | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_Poplar](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_Poplar)             |
| 14    | DistTrain                 | [DistTrain](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_DistTrain)       | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô Disaggregated Training                                   | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_DistTrain](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_DistTrain)       |
| 15    | TorchTitan                | [TorchTitan](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_TorchTitan)     | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô PyTorch Native Solution                                  | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_TorchTitan](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_TorchTitan)     |
| **Advanced Fine-Tuning ‡πÅ‡∏•‡∏∞ Applications** |                                                                                                |                                                                                              |                                                                                              |                                                                                                  |
| 16    | DeepSpeed-Ulysses         | [DeepSpeed-Ulysses](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_DeepSpeed-Ulysses) | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning Transformer Models ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Sequence ‡∏¢‡∏≤‡∏ß                             | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_DeepSpeed-Ulysses](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_DeepSpeed-Ulysses) |
| 17    | Distributed Shampoo       | [Distributed-Shampoo](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Distributed-Shampoo) | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning Neural Networks ‡∏ú‡πà‡∏≤‡∏ô Distributed Shampoo Optimizer                 | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Distributed-Shampoo](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Distributed-Shampoo) |
| 18    | FLM-101B                  | [FLM-101B](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_FLM-101B)         | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning LLMs ‡∏Ç‡∏ô‡∏≤‡∏î 101B ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå                                         | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_FLM-101B](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_FLM-101B)         |
| 19    | UniAP                     | [UniAP](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_UniAP)               | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ Parallelism ‡∏ú‡πà‡∏≤‡∏ô Mixed Integer Quadratic Programming          | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_UniAP](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_UniAP)               |
| 20    | Proteus                   | [Proteus](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Proteus)           | Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á Distributed DNN Training                                                | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Proteus](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Proteus)           |


### ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏
- ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà (Fine-Tuning ‡πÅ‡∏•‡∏∞ Optimization Techniques, Distributed Training ‡πÅ‡∏•‡∏∞ System Optimization, Advanced Fine-Tuning ‡πÅ‡∏•‡∏∞ Applications) ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
- ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡πà‡∏ß‡∏á" ‡πÉ‡∏ô "Memory-Communication Optimization" ‡∏ñ‡∏π‡∏Å‡πÅ‡∏õ‡∏•‡πÄ‡∏õ‡πá‡∏ô "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡πà‡∏ß‡∏á" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢

---

### ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PDF Paper ‡πÅ‡∏•‡∏∞ Script ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning AI 

#### **GitHub Repository ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Paper ‡πÅ‡∏•‡∏∞ Script**
1. **ml-systems-papers**  
   - **GitHub**: [byungsoo-oh/ml-systems-papers](https://github.com/byungsoo-oh/ml-systems-papers )  
   - **‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î**: ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Paper ‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning AI ‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡∏™‡∏£‡∏£‡∏à‡∏≤‡∏Å Conference ‡∏ä‡∏±‡πâ‡∏ô‡∏ô‡∏≥‰æãÂ¶Ç SOSP, NeurIPS, SC, OSDI, ASPLOS, EuroSys, ICLR, ICML, MLSys. ‡∏ö‡∏≤‡∏á Paper ÈôÑÂ∏∂ Code ‡πÅ‡∏•‡∏∞ Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Fine-Tuning ‡πÅ‡∏•‡∏∞ Distributed Training.  

---

### **Paper ‡πÅ‡∏•‡∏∞ Script ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á**

‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ‡∏â‡∏±‡∏ô‡∏à‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà ‡πÇ‡∏î‡∏¢‡∏´‡∏≤‡∏Å‡∏•‡∏¥‡∏á‡∏Å‡πå arXiv ‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ ".12345" (‡πÄ‡∏ä‡πà‡∏ô `arXiv:2409.12345` ‡∏´‡∏£‡∏∑‡∏≠ `arXiv:2309.12345`) ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ô‡∏±‡πâ‡∏ô‡∏•‡∏á‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡∏Ç‡∏∂‡πâ‡∏ô ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡πâ‡∏ß:

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Paper ‡πÅ‡∏•‡∏∞ Script ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning AI (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á)

| ‡∏•‡∏≥‡∏î‡∏±‡∏ö | ‡∏ä‡∏∑‡πà‡∏≠                                                                                   | Conference   | Link (arXiv)                          | Script                                      | GitHub                                                                                             |
|-------|----------------------------------------------------------------------------------------|--------------|---------------------------------------|---------------------------------------------|--------------------------------------------------------------------------------------------------|
| **Fine-Tuning ‡πÅ‡∏•‡∏∞ Optimization Techniques** |                                                                                       |              |                                       |                                             |                                                                                                  |
| 1     | Uncovering Nested Data Parallelism and Data Reuse in DNN Computation with FractalTensor | SOSP'24      | -                                     | FractalTensor                              | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SOSP24_FractalTensor](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SOSP24_FractalTensor) |
| 2     | Accelerating Large Language Model Training with 4D Parallelism and Memory Consumption Estimator | -            | -                                     | 4D-Parallelism                             | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_4D_Parallelism](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_4D_Parallelism) |
| 3     | Rethinking Memory and Communication Costs for Efficient Data Parallel Training of Large Language Models | NeurIPS'24 | -                                     | Memory-Communication                       | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/NeurIPS24_Memory_Communication](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/NeurIPS24_Memory_Communication) |
| 4     | LoongTrain: Efficient Training of Long-Sequence LLMs with Head-Context Parallelism     | -            | -                                     | LoongTrain                                 | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_LoongTrain](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_LoongTrain)     |
| 5     | PAFT: A Parallel Training Paradigm for Effective LLM Fine-Tuning                      | -            | -                                     | PAFT                                       | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_PAFT](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_PAFT)                 |
| 6     | Efficient Training of Large Language Models on Distributed Infrastructures: A Survey   | -            | -                                     | Survey                                     | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_Survey](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_Survey)             |
| 7     | Re-evaluating the Memory-balanced Pipeline Parallelism: BPipe                         | -            | -                                     | BPipe                                      | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_BPipe](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_BPipe)               |
| 8     | InternEvo: Efficient Long-sequence Large Language Model Training via Hybrid Parallelism and Redundant Sharding | -            | -                                     | InternEvo                                  | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_InternEvo](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_InternEvo)       |
| 9     | Scaling Vision Transformers to 22 Billion Parameters                                   | -            | -                                     | Vision-Transformers                        | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Vision_Transformers](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Vision_Transformers) |
| 10    | Colossal-Auto: Unified Automation of Parallelization and Activation Checkpoint for Large-scale Models | -            | -                                     | Colossal-Auto                              | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Colossal-Auto](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Colossal-Auto) |
| **Distributed Training ‡πÅ‡∏•‡∏∞ System Optimization** |                                                                                       |              |                                       |                                             |                                                                                                  |
| 11    | Democratizing AI: Open-source Scalable LLM Training on GPU-based Supercomputers       | SC'24        | -                                     | GPU-Supercomputers                         | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SC24_GPU_Supercomputers](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/SC24_GPU_Supercomputers) |
| 12    | PipeFill: Using GPUs During Bubbles in Pipeline-parallel LLM Training                 | -            | -                                     | PipeFill                                   | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_PipeFill](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_PipeFill)         |
| 13    | Poplar: Efficient Scaling of Distributed DNN Training on Heterogeneous GPU Clusters   | -            | -                                     | Poplar                                     | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_Poplar](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_Poplar)             |
| 14    | DistTrain: Addressing Model and Data Heterogeneity with Disaggregated Training for Multimodal Large Language Models | -            | -                                     | DistTrain                                  | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_DistTrain](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_DistTrain)       |
| 15    | TorchTitan: One-stop PyTorch Native Solution for Production-Ready LLM Pre-training    | -            | -                                     | TorchTitan                                 | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_TorchTitan](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv24_TorchTitan)     |
| **Advanced Fine-Tuning ‡πÅ‡∏•‡∏∞ Applications** |                                                                                       |              |                                       |                                             |                                                                                                  |
| 16    | DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models | -            | -                                     | DeepSpeed-Ulysses                          | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_DeepSpeed-Ulysses](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_DeepSpeed-Ulysses) |
| 17    | A Distributed Data-Parallel PyTorch Implementation of the Distributed Shampoo Optimizer for Training Neural Networks At-Scale | -            | -                                     | Distributed-Shampoo                        | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Distributed-Shampoo](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Distributed-Shampoo) |
| 18    | FLM-101B: An Open LLM and How to Train It with $100K Budget                           | -            | -                                     | FLM-101B                                   | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_FLM-101B](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_FLM-101B)         |
| 19    | UniAP: Unifying Inter- and Intra-Layer Automatic Parallelism by Mixed Integer Quadratic Programming | -            | -                                     | UniAP                                      | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_UniAP](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_UniAP)               |
| 20    | Proteus: Simulating the Performance of Distributed DNN Training                       | -            | -                                     | Proteus                                    | [https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Proteus](https://github.com/byungsoo-oh/ml-systems-papers/tree/main/arXiv23_Proteus)           |


### ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏
- ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà (Fine-Tuning ‡πÅ‡∏•‡∏∞ Optimization Techniques, Distributed Training ‡πÅ‡∏•‡∏∞ System Optimization, Advanced Fine-Tuning ‡πÅ‡∏•‡∏∞ Applications)

---

---

### ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PDF Paper ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning AI
‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô "Paper ‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PDF ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning AI" (‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ Fine-Tuning LLMs ‡πÅ‡∏•‡∏∞ AI Models, ‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£ AI/ML/DL ‡πÅ‡∏•‡∏∞ Optimization, ‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£ Fine-Tuning ‡πÅ‡∏•‡∏∞ Distributed Training, ‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£ AI/ML/DL ‡πÅ‡∏•‡∏∞ Applications ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PDF) ‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡πÇ‡∏î‡∏¢‡∏à‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå "‡∏•‡∏≥‡∏î‡∏±‡∏ö", "‡∏ä‡∏∑‡πà‡∏≠", "Link", ‡πÅ‡∏•‡∏∞ "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏π‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Paper ‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PDF ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning AI

| ‡∏•‡∏≥‡∏î‡∏±‡∏ö | ‡∏ä‡∏∑‡πà‡∏≠                                                                                   | Link                                                                                  | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                                   |
|-------|----------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------|
| **Fine-Tuning LLMs ‡πÅ‡∏•‡∏∞ AI Models** |                                                                                       |                                                                                       |                                                                                              |
| 1     | The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs                   | [arXiv:2408.13296](https://arxiv.org/abs/2408.13296)                                  | ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡∏™‡∏≤‡∏ô‡∏ó‡∏§‡∏©‡∏é‡∏µ‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ 7 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• |
| 2     | Focusing on Fine-Tuning: Understanding the Four Pathways for AI Models                | [SSRN Paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4738261)             | ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå 4 ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö AI Models (Pretraining, Fine-Tuning, In-Context Learning, Input-Output Filtering) ‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° AI |
| 3     | Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment | [arXiv:2205.01068](https://arxiv.org/abs/2205.01068)                                  | ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á ‡πÄ‡∏ä‡πà‡∏ô LoRA, P-Tuning, ‡πÅ‡∏•‡∏∞ Adapter           |
| 4     | QLoRA: Efficient Finetuning of Quantized LLMs                                         | [arXiv:2305.14314](https://arxiv.org/abs/2305.14314)                                  | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Ñ‡∏ß‡∏≠‡∏ô‡πÑ‡∏ó‡∏ã‡πå ‡∏ú‡πà‡∏≤‡∏ô QLoRA ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥                |
| 5     | AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration        | [arXiv:2306.12505](https://arxiv.org/abs/2306.12505)                                  | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≠‡∏ô‡πÑ‡∏ó‡∏ã‡πå LLMs ‡∏ú‡πà‡∏≤‡∏ô Activation-aware Weight Quantization ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏≤‡∏ô     |
| 6     | Platypus: Quick, Cheap, and Powerful Refinement of LLMs                               | [arXiv:2304.05465](https://arxiv.org/abs/2304.05465)                                  | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö LLMs ‡∏ú‡πà‡∏≤‡∏ô Soft-prompt Tuning ‡πÅ‡∏•‡∏∞ Parameter-efficient Fine-Tuning                  |
| 7     | LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models     | [arXiv:2307.01234](https://arxiv.org/abs/2307.01234)                                  | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î Prompt ‡∏ú‡πà‡∏≤‡∏ô LLMLingua ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏≤‡∏ô                                |
| 8     | LongLoRA: Efficient Fine-Tuning for Long-Sequence LLMs                                | [GitHub: LongLoRA](https://github.com/dvlab-research/LongLoRA)                        | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Sequence ‡∏¢‡∏≤‡∏ß‡∏ú‡πà‡∏≤‡∏ô LongLoRA                                    |
| 9     | PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU              | -                                                                             | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô LLMs ‡∏ú‡πà‡∏≤‡∏ô Consumer-grade GPU ‡πÄ‡∏ä‡πà‡∏ô RTX 4090                                     |
| 10    | GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection                 | -                                                                             | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å LLMs ‡∏ú‡πà‡∏≤‡∏ô Gradient Low-Rank Projection ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û                       |
| **‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£ AI/ML/DL ‡πÅ‡∏•‡∏∞ Optimization** |                                                                                       |                                                                                       |                                                                                              |
| 11    | A Comprehensive Overview and Comparative Analysis of Deep Learning Models            | [arXiv:2305.17473](https://arxiv.org/pdf/2305.17473)                                  | ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Deep Learning (CNN, LSTM, GRU) ‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•     |
| 12    | Reinforced Functional Token Tuning for LLMs                                           | [arXiv:2502.13389](https://arxiv.org/abs/2502.13389)                                  | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô Reinforcement Learning ‡πÅ‡∏•‡∏∞ Functional Token Tuning              |
| 13    | FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness           | [arXiv:2206.11863](https://arxiv.org/abs/2206.11863)                                  | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß Attention Mechanism ‡∏ú‡πà‡∏≤‡∏ô FlashAttention                                  |
| 14    | Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning | [arXiv:2204.05200](https://arxiv.org/abs/2204.05200)                                  | ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning ‡∏ú‡πà‡∏≤‡∏ô Few-Shot Parameter-efficient Tuning                       |
| 15    | Soft-prompt Tuning for Large Language Models to Evaluate Bias                         | -                                                                             | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö LLMs ‡∏ú‡πà‡∏≤‡∏ô Soft-prompt Tuning ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô Bias                                    |
| **‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£ Fine-Tuning ‡πÅ‡∏•‡∏∞ Distributed Training** |                                                                                       |                                                                                       |                                                                                              |
| 16    | SuperScaler: Supporting Flexible DNN Parallelization via a Unified Abstraction        | -                                                                             | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å DNN ‡∏ú‡πà‡∏≤‡∏ô Unified Abstraction ‡πÅ‡∏•‡∏∞ Parallelization                                  |
| 17    | LoongTrain: Efficient Training of Long-Sequence LLMs with Head-Context Parallelism    | -                                                                             | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å LLMs ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Sequence ‡∏¢‡∏≤‡∏ß‡∏ú‡πà‡∏≤‡∏ô Head-Context Parallelism                             |
| 18    | PAFT: A Parallel Training Paradigm for Effective LLM Fine-Tuning                     | -                                                                             | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å LLMs ‡∏ú‡πà‡∏≤‡∏ô Parallel Training Paradigm                                              |
| 19    | DataStates-LLM: Lazy Asynchronous Checkpointing for Large Language Models            | -                                                                             | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏ù‡∏∂‡∏Å LLMs ‡∏ú‡πà‡∏≤‡∏ô Lazy Asynchronous Checkpointing                            |
| 20    | InternEvo: Efficient Long-sequence Large Language Model Training via Hybrid Parallelism and Redundant Sharding | -                                                                             | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å LLMs ‡∏ú‡πà‡∏≤‡∏ô Hybrid Parallelism ‡πÅ‡∏•‡∏∞ Redundant Sharding                               |
| **‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£ AI/ML/DL ‡πÅ‡∏•‡∏∞ Applications** |                                                                                       |                                                                                       |                                                                                              |
| 21    | Machine Learning and Deep Learning Fundamentals                                       | [arXiv:2104.05314](https://arxiv.org/pdf/2104.05314)                                  | ‡∏™‡∏£‡∏∏‡∏õ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô AI/ML/DL ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à          |
| 22    | Artificial Intelligence to Deep Learning: Machine Intelligence in Drug Discovery      | [Springer PDF](https://link.springer.com/content/pdf/10.1007/s11030-021-10217-3.pdf)   | ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ AI/ML/DL ‡πÉ‡∏ô‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏Ñ‡∏ß‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏¢‡∏≤                                       |
| 23    | Re-evaluating the Memory-balanced Pipeline Parallelism: BPipe                         | -                                                                             | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û Pipeline Parallelism ‡∏ú‡πà‡∏≤‡∏ô BPipe                                      |
| 24    | EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty                   | -                                                                             | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏≤‡∏ô LLMs ‡∏ú‡πà‡∏≤‡∏ô Speculative Sampling                                  |
| 25    | The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits                    | -                                                                             | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≠‡∏ô‡πÑ‡∏ó‡∏ã‡πå LLMs ‡∏ú‡πà‡∏≤‡∏ô 1.58-bit Quantization                                             |
| **‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PDF Paper ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning AI** |                                                                                       |                                                                                       |                                                                                              |
| 26    | The Ultimate Guide to Fine-Tuning LLMs                                                | [arXiv:2408.13296](https://arxiv.org/abs/2408.13296)                                  | ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡∏™‡∏≤‡∏ô‡∏ó‡∏§‡∏©‡∏é‡∏µ‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ 7 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• |
| 27    | Focusing on Fine-Tuning: Understanding the Four Pathways for AI Models                | [SSRN Paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4738261)             | ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå 4 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö AI Models (Pretraining, Fine-Tuning, In-Context Learning, Input-Output Filtering) ‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° AI |
| 28    | Machine Learning and Deep Learning Fundamentals                                       | [arXiv:2104.05314](https://arxiv.org/pdf/2104.05314)                                  | ‡∏™‡∏£‡∏∏‡∏õ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô AI/ML/DL ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à          |
| 29    | Artificial Intelligence to Deep Learning: Machine Intelligence in Drug Discovery      | [Springer PDF](https://link.springer.com/content/pdf/10.1007/s11030-021-10217-3.pdf)   | ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ AI/ML/DL ‡πÉ‡∏ô‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏Ñ‡∏ß‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏¢‡∏≤ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ         |
| 30    | A Comprehensive Overview and Comparative Analysis of Deep Learning Models            | [arXiv:2305.17473](https://arxiv.org/pdf/2305.17473)                                  | ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Deep Learning (CNN, LSTM, GRU) ‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•     |
| 31    | Reinforced Functional Token Tuning for LLMs                                           | [arXiv:2502.13389](https://arxiv.org/abs/2502.13389)                                  | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning LLMs ‡∏ú‡πà‡∏≤‡∏ô Reinforcement Learning ‡πÅ‡∏•‡∏∞ Functional Token Tuning ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏≤‡∏ô |
| 32    | Papers-Literature-ML-DL-RL-AI                                                         | [GitHub: tirthajyoti/Papers-Literature-ML-DL-RL-AI](https://github.com/tirthajyoti/Papers-Literature-ML-DL-RL-AI) | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Paper AI/ML/DL ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏°‡∏≤‡∏Å ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ ‡πÄ‡∏ä‡πà‡∏ô Statistics, Reinforcement Learning |

### ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
- **‡∏•‡∏≥‡∏î‡∏±‡∏ö**: ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏∏‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Paper ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
- **‡∏ä‡∏∑‡πà‡∏≠**: ‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á Paper ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏ä‡πà‡∏ô The Ultimate Guide to Fine-Tuning LLMs, Machine Learning and Deep Learning Fundamentals)
- **Link**: ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏ô arXiv, SSRN, Springer ‡∏´‡∏£‡∏∑‡∏≠ GitHub (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏õ‡πá‡∏ô "-")
- **‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î**: ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡∏≠‡∏á Paper ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

### ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏
- ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏µ‡πà‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏´‡∏•‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PDF Pap

---

### ‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning

‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô "‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning AI" (‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ 1-8) ‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡πÇ‡∏î‡∏¢‡∏à‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå "‡∏•‡∏≥‡∏î‡∏±‡∏ö", "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠", "‡∏ä‡∏∑‡πà‡∏≠", "Link", ‡πÅ‡∏•‡∏∞ "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏π‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞ Fine-Tuning AI

| ‡∏•‡∏≥‡∏î‡∏±‡∏ö | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠                          | ‡∏ä‡∏∑‡πà‡∏≠                                                                                   | Link                                                                                  | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                                   |
|-------|--------------------------------|----------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------|
| 1     | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå AI/ML/DL      | AI-ML-DL Projects                                                                      | [https://github.com/theakash07/AI-ML-DL-Projects](https://github.com/theakash07/AI-ML-DL-Projects) | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå AI/ML/DL ‡∏Å‡∏ß‡πà‡∏≤ 40+ ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå ‡∏û‡∏£‡πâ‡∏≠‡∏° Code ‡πÅ‡∏•‡∏∞ Tutorial ‡πÄ‡∏ä‡πà‡∏ô 365 Days Computer Vision Learning, 125+ NLP Language Models, ‡πÅ‡∏•‡∏∞ 20 Deep Learning Projects |
| 2     | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning AI Models  | Fine-Tune Llama 3.1 (8B) on Google Colab                                              | [https://medium.com/@rschaeffer23/how-to-fine-tune-llama-3-1-8b-instruct-bf0a84af7795](https://medium.com/@rschaeffer23/how-to-fine-tune-llama-3-1-8b-instruct-bf0a84af7795) | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Fine-Tuning Llama 3.1 (8B) ‡∏ö‡∏ô Google Colab ‡∏î‡πâ‡∏ß‡∏¢‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ `transformers`, `peft`, ‡πÅ‡∏•‡∏∞ `accelerate` ‡∏û‡∏£‡πâ‡∏≠‡∏° Code Example ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Environment |
| 3     | ‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå AI/ML/DL       | 30 Machine Learning, AI, & Data Science Project Ideas                                  | [https://dev.to/hb/30-machine-learning-ai-data-science-project-ideas-gf5](https://dev.to/hb/30-machine-learning-ai-data-science-project-ideas-gf5) | ‡πÑ‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå 30 ‡∏Ç‡πâ‡∏≠ ‡πÄ‡∏ä‡πà‡∏ô Titanic Survival Project, Chatbot, Sentiment Analysis, ‡πÅ‡∏•‡∏∞ Image Captioning ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å‡πÅ‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå Tutorial |
| 4     | ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ Dataset         | Kaggle Projects Collection                                                             | [https://www.kaggle.com/datasets](https://www.kaggle.com/datasets)                    | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Dataset ‡πÅ‡∏•‡∏∞‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå AI/ML/DL ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡∏ù‡∏ô                                |
| 4.1   | ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ Dataset         | NLP Datasets                                                                           | [https://github.com/awwsmm/nlp-datasets](https://github.com/awwsmm/nlp-datasets)      | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Dataset NLP ‡∏Å‡∏ß‡πà‡∏≤ 100+ ‡∏ä‡∏∏‡∏î ‡∏û‡∏£‡πâ‡∏≠‡∏° Code ‡πÅ‡∏•‡∏∞ Example                                     |
| 5     | ‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞ÊïôÁ®ã                 | Andrew NG Machine Learning Course                                                      | [https://www.coursera.org/learn/machine-learning](https://www.coursera.org/learn/machine-learning) | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡πÄ‡∏£‡∏µ‡∏¢‡∏ô Machine Learning ‡∏ü‡∏£‡∏µ ‡πÇ‡∏î‡∏¢ Andrew NG ‡∏ú‡∏π‡πâ‡∏Å‡πà‡∏≠‡∏ï‡∏±‡πâ‡∏á Coursera                            |
| 5.1   | ‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞ÊïôÁ®ã                 | Deep Learning Specialization                                                           | [https://www.coursera.org/specializations/deep-learning](https://www.coursera.org/specializations/deep-learning) | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡πÄ‡∏£‡∏µ‡∏¢‡∏ô Deep Learning 5 ‡∏Ñ‡∏≠‡∏£‡πå‡∏™ ‡∏ú‡πà‡∏≤‡∏ô Coursera ‡πÇ‡∏î‡∏¢ Andrew NG                                |
| 6     | ‡∏ß‡∏¥‡∏ó‡∏¢‡∏∏‡πÅ‡∏•‡∏∞ Podcast               | AI Podcast                                                                             | [https://lexfridman.com/podcast/](https://lexfridman.com/podcast/)                    | Podcast ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ AI                                |
| 6.1   | ‡∏ß‡∏¥‡∏ó‡∏¢‡∏∏‡πÅ‡∏•‡∏∞ Podcast               | Data Skeptic Podcast                                                                   | [https://dataskeptic.com/](https://dataskeptic.com/)                                  | Podcast ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Data Science, Machine Learning, ‡πÅ‡∏•‡∏∞ Statistics                              |
| 7     | ‡∏ß‡∏¥‡∏ó‡∏¢‡∏∏‡πÅ‡∏•‡∏∞ Video Tutorial        | Sentdex                                                                                | [https://www.youtube.com/@sentdex](https://www.youtube.com/@sentdex)                  | ‡∏ä‡πà‡∏≠‡∏á YouTube ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô AI/ML/DL ‡πÅ‡∏•‡∏∞‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏°‡∏¥‡πà‡∏á                                         |
| 7.1   | ‡∏ß‡∏¥‡∏ó‡∏¢‡∏∏‡πÅ‡∏•‡∏∞ Video Tutorial        | Corey Schafer                                                                          | [https://www.youtube.com/@coreyschafer](https://www.youtube.com/@coreyschafer)        | ‡∏ä‡πà‡∏≠‡∏á YouTube ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏°‡∏¥‡πà‡∏á ‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î                                |
| 7.2   | ‡∏ß‡∏¥‡∏ó‡∏¢‡∏∏‡πÅ‡∏•‡∏∞ Video Tutorial        | MACHINE LEARNING TUTORIALS                                                            | [https://www.youtube.com/@sentdex/playlists](https://www.youtube.com/@sentdex/playlists) | ‡πÄ‡∏û‡∏•‡∏¢‡πå‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô Machine Learning ‡∏à‡∏≤‡∏Å Sentdex                                                |
| 8     | ‡∏ß‡∏¥‡∏ó‡∏¢‡∏∏‡πÅ‡∏•‡∏∞ Community             | Reddit Communities: r/MachineLearning                                                  | [https://www.reddit.com/r/MachineLearning/](https://www.reddit.com/r/MachineLearning/) | ‡∏ä‡∏∏‡∏°‡∏ä‡∏ô Reddit ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Machine Learning                                                     |
| 8.1   | ‡∏ß‡∏¥‡∏ó‡∏¢‡∏∏‡πÅ‡∏•‡∏∞ Community             | Reddit Communities: r/Artificial                                                       | [https://www.reddit.com/r/Artificial/](https://www.reddit.com/r/Artificial/)          | ‡∏ä‡∏∏‡∏°‡∏ä‡∏ô Reddit ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Artificial Intelligence                                              |
| 8.2   | ‡∏ß‡∏¥‡∏ó‡∏¢‡∏∏‡πÅ‡∏•‡∏∞ Community             | Reddit Communities: r/GitHub                                                           | [https://www.reddit.com/r/GitHub/](https://www.reddit.com/r/GitHub/)                  | ‡∏ä‡∏∏‡∏°‡∏ä‡∏ô Reddit ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö GitHub                                                               |
| 8.3   | ‡∏ß‡∏¥‡∏ó‡∏¢‡∏∏‡πÅ‡∏•‡∏∞ Community             | AI/ML/DL Projects Collection                                                          | [https://github.com/theakash07/AI-ML-DL-Projects](https://github.com/theakash07/AI-ML-DL-Projects) | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå AI/ML/DL ‡∏à‡∏≤‡∏Å GitHub                                                         |
| 8.4   | ‡∏ß‡∏¥‡∏ó‡∏¢‡∏∏‡πÅ‡∏•‡∏∞ Community             | Fine-Tuning Tutorials                                                                  | [https://restack.io/fine-tuning-ai-models-in-google-colab](https://restack.io/fine-tuning-ai-models-in-google-colab) | ‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏≤‡∏£ Fine-Tuning AI Models ‡∏ö‡∏ô Google Colab                                             |
| 8.5   | ‡∏ß‡∏¥‡∏ó‡∏¢‡∏∏‡πÅ‡∏•‡∏∞ Community             | Code Examples                                                                          | [https://github.com/keras-team/keras/tree/master/examples](https://github.com/keras-team/keras/tree/master/examples) | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡∏à‡∏≤‡∏Å Keras ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô AI/ML/DL                                                    |


---



### üìù Introductory Notebooks
Notebooks ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ù‡∏∂‡∏Å‡∏ù‡∏ô‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏à‡∏£‡∏¥‡∏á‡∏ö‡∏ô‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏° ‡πÄ‡∏ä‡πà‡∏ô Google Colab ‡πÅ‡∏•‡∏∞ Kaggle
‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô "Introductory Notebooks, Online Courses, Datasets, Tools, ‡πÅ‡∏•‡∏∞ Additional Learning Resources" ‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡πÇ‡∏î‡∏¢‡∏à‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå "‡∏•‡∏≥‡∏î‡∏±‡∏ö", "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠", "‡∏ä‡∏∑‡πà‡∏≠", "Link", ‡πÅ‡∏•‡∏∞ "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏π‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Introductory Notebooks, Online Courses, Datasets, Tools, ‡πÅ‡∏•‡∏∞ Additional Learning Resources

| ‡∏•‡∏≥‡∏î‡∏±‡∏ö | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠                          | ‡∏ä‡∏∑‡πà‡∏≠                                                                                   | Link                                                                                  | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                                   |
|-------|--------------------------------|----------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------|
| **Introductory Notebooks** |                                                                                       |                                                                                       |                                                                                       |                                                                                              |
| 1     | Unsloth Notebooks             | Unsloth Notebooks                                                                      | [https://github.com/unslothai/notebooks](https://github.com/unslothai/notebooks)      | ‡∏£‡∏ß‡∏° Notebooks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning ‡πÅ‡∏•‡∏∞ Inference ‡πÇ‡∏°‡πÄ‡∏î‡∏• LLMs ‡∏ö‡∏ô Google Colab ‡πÅ‡∏•‡∏∞ Kaggle          |
| 1.1   | Unsloth Notebooks             | Phi 4 (14B) - GRPO                                                                     | [https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4_(14B)-GRPO.ipynb](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4_(14B)-GRPO.ipynb) | Notebook ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning Phi 4 (14B) ‡∏î‡πâ‡∏ß‡∏¢ GRPO                                            |
| 1.2   | Unsloth Notebooks             | Llama 3.2 (1B and 3B) - Conversational                                                | [https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb) | Notebook ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning Llama 3.2 (1B ‡πÅ‡∏•‡∏∞ 3B) ‡πÅ‡∏ö‡∏ö Conversational                        |
| 2     | Origins AI Notebooks          | Origins AI Notebooks                                                                   | [https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/](https://originshq.com/blog/top-ai-llm-learning-resource-in-2025/) | Notebooks ‡πÅ‡∏•‡∏∞‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ LLMs                                            |
| 2.1   | Origins AI Notebooks          | LLM AutoEval                                                                           | [https://colab.research.google.com/drive/1Igs3WZuXAIv9X0vwqiE90QlEPys8e8Oa](https://colab.research.google.com/drive/1Igs3WZuXAIv9X0vwqiE90QlEPys8e8Oa) | Notebook ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô LLMs ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏î‡πâ‡∏ß‡∏¢ RunPod                                              |
| 2.2   | Origins AI Notebooks          | Fine-tune Llama 3.1 with Unsloth                                                       | [https://colab.research.google.com/drive/164cg_O7SV7G8kZr_JXqLd6VC7pd86-1Z](https://colab.research.google.com/drive/164cg_O7SV7G8kZr_JXqLd6VC7pd86-1Z) | Notebook ‡πÅ‡∏•‡∏∞‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning Llama 3.1 ‡∏î‡πâ‡∏ß‡∏¢ Unsloth                                  |
| 3     | Awesome Colab Notebooks       | Awesome Colab Notebooks                                                                | [https://github.com/amrzv/awesome-colab-notebooks](https://github.com/amrzv/awesome-colab-notebooks) | ‡∏Ñ‡∏•‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö Notebooks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ML Experiments                                                     |
| 3.1   | Awesome Colab Notebooks       | ARENA                                                                                  | [https://colab.research.google.com/drive/1vuQOB2Gd7OcfzH2y9djXm9OdZA_DcxYz](https://colab.research.google.com/drive/1vuQOB2Gd7OcfzH2y9djXm9OdZA_DcxYz) | Notebook ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ML Engineering ‡πÇ‡∏î‡∏¢ Callum McDougall                                         |
| 3.2   | Awesome Colab Notebooks       | AlphaFold                                                                              | [https://colab.research.google.com/github/deepmind/alphafold/blob/master/notebooks/AlphaFold.ipynb](https://colab.research.google.com/github/deepmind/alphafold/blob/master/notebooks/AlphaFold.ipynb) | Notebook ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Protein Structure Prediction                                                |
| **Online Courses and Tutorials** |                                                                                       |                                                                                       |                                                                                       |                                                                                              |
| 4     | Online Courses and Tutorials  | Andrew NG Machine Learning Course                                                      | [https://www.coursera.org/learn/machine-learning](https://www.coursera.org/learn/machine-learning) | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô Machine Learning ‡πÇ‡∏î‡∏¢ Andrew NG                                          |
| 4.1   | Online Courses and Tutorials  | Deep Learning Specialization                                                           | [https://www.coursera.org/specializations/deep-learning](https://www.coursera.org/specializations/deep-learning) | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå Deep Learning 5 ‡∏Ñ‡∏≠‡∏£‡πå‡∏™ ‡πÇ‡∏î‡∏¢ Andrew NG                                            |
| 4.2   | Online Courses and Tutorials  | NYU-DLSP20                                                                             | [https://github.com/Atcold/NYU-DLSP20](https://github.com/Atcold/NYU-DLSP20)          | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™ Deep Learning ‡πÇ‡∏î‡∏¢ Yann LeCun                                                          |
| 4.3   | Online Courses and Tutorials  | mlcourse.ai                                                                            | [https://github.com/Yorko/mlcourse.ai](https://github.com/Yorko/mlcourse.ai)          | Open ML Course ‡πÇ‡∏î‡∏¢ Yury Kashnitsky                                                          |
| **Datasets and Tools** |                                                                                       |                                                                                       |                                                                                       |                                                                                              |
| 5     | Datasets and Tools            | Kaggle Datasets                                                                        | [https://www.kaggle.com/datasets](https://www.kaggle.com/datasets)                    | ‡∏Ñ‡∏•‡∏±‡∏á Dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡∏ù‡∏ô‡∏á‡∏≤‡∏ô AI/ML/DL                                                         |
| 5.1   | Datasets and Tools            | NLP Datasets                                                                           | [https://github.com/awwsmm/nlp-datasets](https://github.com/awwsmm/nlp-datasets)      | ‡∏Ñ‡∏•‡∏±‡∏á Dataset NLP ‡∏Å‡∏ß‡πà‡∏≤ 100+ ‡∏ä‡∏∏‡∏î ‡∏û‡∏£‡πâ‡∏≠‡∏° Code ‡πÅ‡∏•‡∏∞ Example                                        |
| 5.2   | Datasets and Tools            | Hugging Face Transformers                                                              | [https://github.com/huggingface/transformers](https://github.com/huggingface/transformers) | Library ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fine-Tuning ‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏ä‡πà‡∏ô BERT, GPT                                              |
| **Additional Learning Resources** |                                                                                       |                                                                                       |                                                                                       |                                                                                              |
| 6     | Podcasts                      | Lex Fridman Podcast                                                                    | [https://lexfridman.com/podcast/](https://lexfridman.com/podcast/)                    | Podcast ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI/ML/DL ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ AI                                |
| 6.1   | Podcasts                      | Data Skeptic                                                                           | [https://dataskeptic.com/](https://dataskeptic.com/)                                  | Podcast ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Data Science, Machine Learning, ‡πÅ‡∏•‡∏∞ Statistics                              |
| 7     | YouTube Channels              | Sentdex                                                                                | [https://www.youtube.com/@sentdex](https://www.youtube.com/@sentdex)                  | ‡∏ä‡πà‡∏≠‡∏á YouTube ‡∏™‡∏≠‡∏ô ML ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î                                                          |
| 7.1   | YouTube Channels              | Corey Schafer                                                                          | [https://www.youtube.com/@coreyschafer](https://www.youtube.com/@coreyschafer)        | ‡∏ä‡πà‡∏≠‡∏á YouTube ‡∏™‡∏≠‡∏ô Python ‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î                                                |
| 8     | Communities                   | r/MachineLearning                                                                      | [https://www.reddit.com/r/MachineLearning/](https://www.reddit.com/r/MachineLearning/) | ‡∏ä‡∏∏‡∏°‡∏ä‡∏ô Reddit ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Machine Learning                                                     |
| 8.1   | Communities                   | Discord - Unsloth                                                                      | [https://discord.gg/unsloth](https://discord.gg/unsloth)                              | ‡∏ä‡∏∏‡∏°‡∏ä‡∏ô Discord ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Unsloth ‡πÅ‡∏•‡∏∞ LLMs                                        |



### ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏
- ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° Introductory Notebooks (Unsloth, Origins AI, Awesome Colab), Online Courses and Tutorials, Datasets and Tools, ‡πÅ‡∏•‡∏∞ Additional Learning Resources (Podcasts, YouTube, Communities) 

---
## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ LLM ‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï (Applying LLMs in Real-World and Future Trends)

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ LLM ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏à‡∏£‡∏¥‡∏á ‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏• ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà‡πÜ ‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï*

### 5.1 ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ LLM (Real-World LLM Projects)

| ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå                                      | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                       | ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ                              | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
| :------------------------------------------- | :----------------------------------------------------------------------------------------------- | :------------------------------------------ | :--------------------- | :----------------------------------------------------------------------------------------------- |
| Chatbot for Customer Support                 | ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô                              | LangChain, Llama 3, Gradio                  | `[Intermediate]`       | [Example Repo](https://github.com/langchain-ai/langchain/tree/master/templates)                  |
| Document Summarization Tool                  | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏¢‡∏≤‡∏ß ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£                                          | Hugging Face Transformers, Mistral 7B       | `[Intermediate/Advanced]` | [Hugging Face Tutorial](https://huggingface.co/docs/transformers/tasks/summarization)           |
| Code Generation Assistant                    | ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Python ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ bug                                      | OpenAI API, GitHub Copilot Clone, Streamlit | `[Intermediate/Advanced]` | [Copilot Clone Tutorial](https://www.youtube.com/watch?v=M-D2_UrjR-E)                          |
| Multilingual Translator                      | ‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡πÑ‡∏ó‡∏¢-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©-‡∏à‡∏µ‡∏ô ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• open-source                              | OpenThaiGPT, mBART                          | `[Advanced]`           | [mBART Docs](https://huggingface.co/docs/transformers/model_doc/mbart)                         |

### 5.2 ‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á LLM (Evaluation and Improvement)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                    | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                           | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                           | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
| :------------------------------------------- | :-------------------------------------------------------------------------------------------------- | :---------------------------------------------- | :--------------------- | :----------------------------------------------------------------------------------------------- |
| Hugging Face Evaluate                        | ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ (accuracy) ‡∏´‡∏£‡∏∑‡∏≠ BLEU score ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤                   | Metrics, evaluation datasets, benchmarking      | `[Intermediate]`       | [Evaluate Docs](https://huggingface.co/docs/evaluate/index)                                      |
| EleutherAI LM Evaluation Harness             | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û LLM ‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô MMLU ‡∏´‡∏£‡∏∑‡∏≠ TruthfulQA                       | Task-specific evaluation, zero-shot testing     | `[Advanced]`           | [LM Eval (GitHub)](https://github.com/EleutherAI/lm-evaluation-harness)                         |
| HumanEval: Evaluating Large Language Models  | Paper ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ HumanEval ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á LLM                             | Code generation metrics, functional correctness | `[Advanced]`           | [HumanEval (Arxiv)](https://arxiv.org/abs/2107.03374)                                           |
| MT-Bench: A Multi-turn Benchmark            | Paper ‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠ MT-Bench ‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á LLM                                | Multi-turn dialogue, human-like responses       | `[Advanced]`           | [MT-Bench (Arxiv)](https://arxiv.org/abs/2306.05685)                                            |

### 5.3 ‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÅ‡∏•‡∏∞‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ LLM (Emerging Trends and Innovations)

| ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠                                         | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                           | ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á                        | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
| :------------------------------------------- | :-------------------------------------------------------------------------------------------------- | :--------------------------------------------- | :----------------------------------------------------------------------------------------------- |
| Multimodal LLMs                              | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÄ‡∏ä‡πà‡∏ô CLIP-ViT ‡∏´‡∏£‡∏∑‡∏≠ DALL-E 3                                | Paper: "Flamingo" (Arxiv)                      | [Flamingo (Arxiv)](https://arxiv.org/abs/2204.14198)                                            |
| Smaller, Efficient Models                    | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡πÅ‡∏ï‡πà‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á ‡πÄ‡∏ä‡πà‡∏ô Phi-3 (Microsoft) ‡∏´‡∏£‡∏∑‡∏≠ TinyLlama ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£       | Phi-3 Blog (Microsoft)                         | [Phi-3 Blog](https://azure.microsoft.com/en-us/blog/introducing-phi-3/)                         |
| AI Agents and Tool Integration               | ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ AI agents ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ LLM ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ ‡πÄ‡∏ä‡πà‡∏ô AutoGen ‡∏´‡∏£‡∏∑‡∏≠ AgentGPT                          | AutoGen (GitHub)                               | [AutoGen (GitHub)](https://github.com/microsoft/autogen)                                        |
| Ethical AI and Regulation                    | ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏é‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏•‡∏î bias ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏î‡∏¢ LLM                 | AI Ethics Guidelines (UNESCO)                  | [UNESCO AI Ethics](https://unesdoc.unesco.org/ark:/48223/pf0000381137)                          |

### 5.4 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (How to Proceed)

1. **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏á‡πà‡∏≤‡∏¢‡πÜ:** ‡∏•‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ LangChain ‡∏´‡∏£‡∏∑‡∏≠ Hugging Face `[Intermediate]`
2. **‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•:** ‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏¢‡πà‡∏≤‡∏á Hugging Face Evaluate ‡∏´‡∏£‡∏∑‡∏≠ LM Evaluation Harness ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤ `[Intermediate/Advanced]`
3. **‡∏™‡∏≥‡∏£‡∏ß‡∏à‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà:** ‡∏≠‡πà‡∏≤‡∏ô paper ‡πÄ‡∏ä‡πà‡∏ô Flamingo ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏à‡∏≤‡∏Å Microsoft ‡πÅ‡∏•‡∏∞ xAI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ ‡πÄ‡∏ä‡πà‡∏ô multimodal LLMs `[Advanced]`
4. **‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á:** ‡∏•‡∏≠‡∏á‡∏£‡∏ß‡∏° LLM ‡∏Å‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏∑‡πà‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏£‡πâ‡∏≤‡∏á AI agent ‡∏î‡πâ‡∏ß‡∏¢ AutoGen ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö edge devices `[Advanced]`
5. **‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏°:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö bias ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô UNESCO AI Ethics `[All Levels]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ LLM ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô ‡∏ö‡∏ô‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡πâ‡∏≠‡∏á‡∏ñ‡∏¥‡πà‡∏ô
- ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏ä‡∏∏‡∏°‡∏ä‡∏ô ‡πÄ‡∏ä‡πà‡∏ô Arxiv ‡∏´‡∏£‡∏∑‡∏≠ X (Twitter) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏û‡∏•‡∏≤‡∏î‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö‡∏ï‡πà‡∏≠‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ç‡∏≠‡∏á LLM ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏¥‡πà‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 6: ‡∏®‡∏±‡∏û‡∏ó‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ LLM (Key Terminology in the LLM Field)

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ Large Language Models (LLM) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ï‡πà‡∏≤‡∏á‡πÜ*

### 6.1 ‡∏®‡∏±‡∏û‡∏ó‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (Basic Terminology)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå                   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢                                                                                       |
| :----------------------- | :--------------------------------------------------------------------------------------------- |
| LLM (Large Language Model) | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å ‡πÉ‡∏ä‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô GPT ‡∏´‡∏£‡∏∑‡∏≠ LLaMA |
| Transformer              | ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLM ‡πÉ‡∏ä‡πâ‡∏Å‡∏•‡πÑ‡∏Å attention ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ö‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö                       |
| Attention                | ‡∏Å‡∏•‡πÑ‡∏Å‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ                       |
| Pre-training             | ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏Å‡πà‡∏≠‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏ñ‡∏±‡∏î‡πÑ‡∏õ                |
| Fine-tuning             | ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà pre-trained ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á              |
| Token                    | ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏¢‡πà‡∏≠‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥ ‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•                            |
| Embedding                | ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡∏´‡∏£‡∏∑‡∏≠ token ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå              |

### 6.2 ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ (Techniques and Methods)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå                   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢                                                                                       |
| :----------------------- | :--------------------------------------------------------------------------------------------- |
| Self-Attention           | ‡∏Å‡∏•‡πÑ‡∏Å attention ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏∏‡∏Å token ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô                           |
| Multi-Head Attention     | ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ attention ‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏±‡πâ‡∏ô‡πÉ‡∏ô Transformer ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢                      |
| Masked Language Model (MLM) | ‡∏ß‡∏¥‡∏ò‡∏µ pre-training ‡∏ó‡∏µ‡πà‡∏ã‡πà‡∏≠‡∏ô‡∏ö‡∏≤‡∏á‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô BERT                        |
| Autoregressive Model     | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô GPT                                   |
| LoRA (Low-Rank Adaptation) | ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ fine-tuning ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£                      |
| QLoRA                    | ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏° quantization ‡∏Å‡∏±‡∏ö LoRA ‡πÄ‡∏û‡∏∑‡πà‡∏≠ fine-tuning ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡πâ‡∏≠‡∏¢‡∏•‡∏á                       |
| Quantization             | ‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏à‡∏≤‡∏Å FP32 ‡πÄ‡∏õ‡πá‡∏ô INT8 ‡∏´‡∏£‡∏∑‡∏≠ 4-bit ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô           |
| Prompt Engineering       | ‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡πâ LLM ‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô prompt                   |
| RLHF (Reinforcement Learning from Human Feedback) | ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ feedback ‡∏à‡∏≤‡∏Å‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£                     |

### 6.3 ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Performance and Deployment)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå                   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢                                                                                       |
| :----------------------- | :--------------------------------------------------------------------------------------------- |
| Inference                | ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏• ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°                            |
| Latency                  | ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö                                                  |
| Throughput               | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏ß‡∏•‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏≥‡∏ï‡πà‡∏≠‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ                                |
| Model Parallelism        | ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏õ‡∏£‡∏±‡∏ô‡∏ö‡∏ô GPU ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà                                  |
| Data Parallelism         | ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏ù‡∏∂‡∏Å‡∏ö‡∏ô GPU ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡πà‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•                                    |
| PagedAttention           | ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÉ‡∏ô inference ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏ç‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û              |
| FlashAttention           | ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ attention ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô pre-training ‡πÅ‡∏•‡∏∞ inference             |

### 6.4 ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏° (Safety and Ethics)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå                   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢                                                                                       |
| :----------------------- | :--------------------------------------------------------------------------------------------- |
| Bias                     | ‡∏≠‡∏Ñ‡∏ï‡∏¥‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏•‡∏≥‡πÄ‡∏≠‡∏µ‡∏¢‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏û‡∏®‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏ä‡∏≤‡∏ï‡∏¥                    |
| Prompt Injection         | ‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡πÇ‡∏î‡∏¢‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢‡πÉ‡∏ô prompt ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏≠‡∏Å‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£                       |
| Jailbreaking             | ‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏ö‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏´‡πâ‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢               |
| Data Poisoning           | ‡∏Å‡∏≤‡∏£‡∏õ‡∏ô‡πÄ‡∏õ‡∏∑‡πâ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î                      |
| Explainability           | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£                                 |

### 6.5 ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Evaluation and Datasets)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå                   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢                                                                                       |
| :----------------------- | :--------------------------------------------------------------------------------------------- |
| BLEU Score               | ‡∏ï‡∏±‡∏ß‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤ ‡πÇ‡∏î‡∏¢‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏õ‡∏•‡∏à‡∏≤‡∏Å‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå                            |
| Perplexity               | ‡∏ï‡∏±‡∏ß‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏à‡∏≠‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏ñ‡∏±‡∏î‡πÑ‡∏õ ‡∏Ñ‡πà‡∏≤‡∏¢‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≥‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ                                |
| MMLU (Massive Multitask Language Understanding) | ‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Ç‡∏≠‡∏á LLM ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏´‡∏•‡∏≤‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå                |
| TruthfulQA               | ‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å LLM                                 |
| HumanEval                | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á LLM ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÇ‡∏à‡∏ó‡∏¢‡πå‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°                    |

### 6.6 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏®‡∏±‡∏û‡∏ó‡πå (How to Proceed)

1. **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:** ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô LLM, Transformer, ‡πÅ‡∏•‡∏∞ Token ‡∏Å‡πà‡∏≠‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô `[Beginner]`
2. **‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏®‡∏±‡∏û‡∏ó‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á LoRA ‡∏´‡∏£‡∏∑‡∏≠ Quantization ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô paper ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ `[Intermediate]`
3. **‡∏ù‡∏∂‡∏Å‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á:** ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå ‡πÄ‡∏ä‡πà‡∏ô ‡∏ß‡∏±‡∏î latency ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥ prompt engineering ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏´‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô `[Intermediate/Advanced]`
4. **‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢:** ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ bias ‡πÅ‡∏•‡∏∞ prompt injection ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡πâ‡∏≤‡∏ó‡∏≤‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏° `[All Levels]`
5. **‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡πÉ‡∏´‡∏°‡πà:** ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏´‡∏£‡∏∑‡∏≠ paper ‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≤‡∏Å Hugging Face ‡∏´‡∏£‡∏∑‡∏≠ Arxiv ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î `[Advanced]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ LLM ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏Ñ‡∏≥‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡∏≤‡∏°‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤
- ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏®‡∏±‡∏û‡∏ó‡πå‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
- ‡∏•‡∏≠‡∏á‡∏à‡∏î‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠‡∏ö‡πà‡∏≠‡∏¢‡πÅ‡∏•‡∏∞‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∏‡πâ‡∏ô‡πÄ‡∏Ñ‡∏¢

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=JonusNattapong/Notebook-Git-Colab&type=Date)](https://star-history.com/#JonusNattapong/Notebook-Git-Colab&Date)<div align="center">

![Project Logo](./public/Zom.png)

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/Apache-2.0-green.svg)](LICENSE)
[![GitHub Package](https://img.shields.io/badge/GitHub-Package-green.svg)](https://github.com/features/packages)
[![GitHub Stars](https://img.shields.io/github/stars/JonusNattapong/Notebook-Git-Colab.svg?style=social)](https://github.com/JonusNattapong/Notebook-Git-Colab/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/JonusNattapong/Notebook-Git-Colab.svg?style=social)](https://github.com/JonusNattapong/Notebook-Git-Colab/network/members)
[![GitHub Followers](https://img.shields.io/github/followers/JonusNattapong.svg?style=social)](https://github.com/JonusNattapong/followers)

</div>

# Notebook-Git-Colab

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏±‡πà‡∏ô‡∏Ñ‡∏á‡πÉ‡∏ô‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå, Python, ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏° ‡πÅ‡∏•‡∏∞ NLP ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á*

### 1.1 ‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Machine Learning

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                    | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                   | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                    | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)     | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                              |
| :------------------------------------------- | :------------------------------------------------------------------------------------------------------------ | :----------------------------------------------------------------------------------------- | :---------------- | :-------------------------------------------------------------------------------------------------------------------------------- |
| 3Blue1Brown - Linear Algebra                 | ‡∏ä‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏™‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏û‡∏µ‡∏ä‡∏Ñ‡∏ì‡∏¥‡∏ï‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏´‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ã‡∏õ‡∏ï‡πå‡∏¢‡∏≤‡∏Å‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏°‡∏ó‡∏£‡∏¥‡∏Å‡∏ã‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô PCA | ‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå, ‡πÄ‡∏°‡∏ó‡∏£‡∏¥‡∏Å‡∏ã‡πå, ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á (transformations), ‡∏Ñ‡πà‡∏≤‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á (eigenvalues - ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô PCA), ‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á (eigenvectors - ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô SVD) | `[Beginner]`      | [YouTube Playlist](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)                                     |
| Khan Academy - Probability and Statistics    | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡∏ü‡∏£‡∏µ ‡∏™‡∏≠‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ML ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô, ‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á (distributions), ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö‡πÄ‡∏ö‡∏¢‡πå (Bayesian inference)      | `[Beginner/Intermediate]` | [Khan Academy Course](https://www.khanacademy.org/math/statistics-probability)                                                     |
| Mathematics for Machine Learning (MML)       | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ü‡∏£‡∏µ‡∏à‡∏≤‡∏Å Cambridge ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô ML ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö gradient descent | ‡∏û‡∏µ‡∏ä‡∏Ñ‡∏ì‡∏¥‡∏ï‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô, ‡πÅ‡∏Ñ‡∏•‡∏Ñ‡∏π‡∏•‡∏±‡∏™, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô, ‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (optimization)                        | `[Intermediate/Advanced]` | [MML Book](https://mml-book.github.io/)                                                                                       |
| All of Statistics (Wasserman)                | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏ô‡∏∏‡∏Å‡∏£‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô ML ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ñ‡∏î‡∏ñ‡∏≠‡∏¢‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á | ‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏≤‡∏ô‡∏ó‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ (statistical inference), ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡∏ñ‡∏î‡∏ñ‡∏≠‡∏¢ (regression), ‡∏≠‡∏ô‡∏∏‡∏Å‡∏£‡∏°‡πÄ‡∏ß‡∏•‡∏≤ (time series) | `[Advanced]`      | [All of Statistics Book](https://www.stat.cmu.edu/~larry/all-of-statistics/) ‡∏´‡∏£‡∏∑‡∏≠ [Springer Link](https://link.springer.com/book/10.1007/978-0-387-21736-9) |

### 1.2 ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Python

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                  | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                          | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                       | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)        | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                |
| :------------------------------------------- | :-------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------- | :------------------- | :-------------------------------------------------------------------------------------------------- |
| Python Official Documentation              | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á Python ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢‡πÉ‡∏ô ML ‡πÄ‡∏ä‡πà‡∏ô `random` ‡∏´‡∏£‡∏∑‡∏≠ `math` | ‡πÑ‡∏ß‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå (syntax), ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡πÇ‡∏°‡∏î‡∏π‡∏• (modules), ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô (standard library)               | `[All Levels]`   | [Python Docs](https://docs.python.org/3/)                                                               |
| Google's Python Class                      | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏ü‡∏£‡∏µ‡∏à‡∏≤‡∏Å Google ‡∏™‡∏≠‡∏ô Python ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏ù‡∏∂‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå | ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô, ‡∏™‡∏ï‡∏£‡∏¥‡∏á (strings), ‡∏•‡∏¥‡∏™‡∏ï‡πå (lists), ‡∏î‡∏¥‡∏Å‡∏ä‡∏±‡∏ô‡∏ô‡∏≤‡∏£‡∏µ (dictionaries), ‡πÑ‡∏ü‡∏•‡πå, regular expressions      | `[Beginner]`       | [Google's Python Class](https://developers.google.com/edu/python/)                                      |
| Corey Schafer - Python Tutorials           | ‡∏ä‡πà‡∏≠‡∏á YouTube ‡∏™‡∏≠‡∏ô Python ‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ OOP ‡πÅ‡∏•‡∏∞‡∏á‡∏≤‡∏ô data science ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ pandas | ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏ä‡∏¥‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ (OOP), ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏ß‡πá‡∏ö, ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (data science)            | `[Beginner/Intermediate]` | [Corey Schafer YouTube](https://www.youtube.com/c/Coreymschafer)                                        |
| Sentdex - Python Programming Tutorials     | ‡∏ä‡πà‡∏≠‡∏á YouTube ‡∏™‡∏≠‡∏ô Python ‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ML ‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ NumPy          | Machine Learning, ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏ß‡πá‡∏ö, ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏Å‡∏°                                 | `[Intermediate]`    | [Sentdex YouTube](https://www.youtube.com/c/sentdex)                                                 |
| Python for Data Analysis (Wes McKinney)    | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏™‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Python (‡πÄ‡∏ô‡πâ‡∏ô pandas) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô ML ‡πÅ‡∏•‡∏∞ data science   | pandas, NumPy, ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (data visualization)     | `[Intermediate/Advanced]` | [Python for Data Analysis](https://wesmckinney.com/book/)                                               |
| Automate the Boring Stuff with Python      | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏ü‡∏£‡∏µ ‡∏™‡∏≠‡∏ô Python ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏á‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô   | ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå, ‡∏Å‡∏≤‡∏£ scraping ‡πÄ‡∏ß‡πá‡∏ö, ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö Excel                                 | `[Beginner]`        | [Automate the Boring Stuff](https://automatetheboringstuff.com/)                                       |

### 1.3 ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏° (Neural Networks)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                    | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                                   | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                   |
| :------------------------------------------- | :--------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------- | :--------------------- | :--------------------------------------------------------------------------------------------------------------------- |
| DeepLearning.AI - Deep Learning Specialization | ‡∏ä‡∏∏‡∏î‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡∏ö‡∏ô Coursera ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô Deep Learning ‡πÄ‡∏ä‡πà‡∏ô backpropagation ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏°     | ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏°, backpropagation, convolutional neural networks (CNNs), recurrent neural networks (RNNs) | `[Beginner/Intermediate]` | [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning)                                  |
| 3Blue1Brown - Neural Networks                | ‡∏ä‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏° ‡πÄ‡∏ä‡πà‡∏ô gradient descent ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏≠‡∏£‡πå‡πÄ‡∏ã‡∏õ‡∏ï‡∏£‡∏≠‡∏ô       | ‡πÄ‡∏û‡∏≠‡∏£‡πå‡πÄ‡∏ã‡∏õ‡∏ï‡∏£‡∏≠‡∏ô (perceptrons), ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô (activation functions), backpropagation, gradient descent   | `[Beginner]`          | [Neural Networks Playlist](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)                  |
| fast.ai - Practical Deep Learning for Coders | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡πÄ‡∏ô‡πâ‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ ‡∏™‡∏≠‡∏ô Deep Learning ‡∏î‡πâ‡∏ß‡∏¢ fastai (‡∏ö‡∏ô PyTorch) ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏£‡∏¥‡∏á          | ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ Deep Learning, PyTorch, ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ fastai                                                  | `[Intermediate]`       | [fast.ai Course](https://course.fast.ai/)                                                                            |
| Stanford CS231n - Convolutional Neural Networks | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏à‡∏≤‡∏Å Stanford ‡πÄ‡∏ô‡πâ‡∏ô CNNs ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô Computer Vision ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° CNN ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î   | Convolutional layers, pooling layers, ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° CNN ‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°                                       | `[Intermediate/Advanced]` | [CS231n Course](http://cs231n.stanford.edu/)                                                                         |
| Transformers Explained (Hugging Face)        | ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡∏à‡∏≤‡∏Å Hugging Face ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô Transformers ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLM ‡πÄ‡∏ä‡πà‡∏ô attention mechanism     | Attention mechanism, self-attention, Transformer architecture                                  | `[Beginner/Intermediate]` | [Transformers Explained](https://huggingface.co/docs/transformers/quicktour)                                         |

### 1.4 ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ (NLP)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                                                       | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                  | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                                                | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                   |
| :------------------------------------------------------------------------------ | :----------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------- | :--------------------- | :--------------------------------------------------------------------------------------------------------------------- |
| Stanford CS224N - NLP with Deep Learning                                       | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏à‡∏≤‡∏Å Stanford ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° NLP ‡∏™‡∏°‡∏±‡∏¢‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢ Deep Learning ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ transformers ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤            | Word embeddings, recurrent neural networks (RNNs), transformers, question answering, machine translation  | `[Intermediate/Advanced]` | [CS224N Course](http://web.stanford.edu/class/cs224n/)                                                                   |
| Jurafsky & Martin - Speech and Language Processing (3rd ed. draft)              | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô NLP ‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå (‡∏â‡∏ö‡∏±‡∏ö‡∏£‡πà‡∏≤‡∏á‡∏ü‡∏£‡∏µ) ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ñ‡∏∂‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á ‡πÄ‡∏ä‡πà‡∏ô language modeling          | Language modeling, parsing, semantics, discourse, machine translation                                        | `[Intermediate/Advanced]` | [SLP Book (3rd ed. draft)](https://web.stanford.edu/~jurafsky/slp3/)                                                       |
| Hugging Face - NLP Course                                                      | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™ interactive ‡∏™‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Transformers library ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô NLP ‡πÄ‡∏ä‡πà‡∏ô fine-tuning ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° | Transformers, tokenization, fine-tuning, ‡∏á‡∏≤‡∏ô NLP ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ                                               | `[Beginner/Intermediate]` | [Hugging Face Course](https://huggingface.co/learn/nlp-course/chapter1/1)                                                   |
| Natural Language Processing with Python (NLTK Book)                            | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏ü‡∏£‡∏µ‡∏™‡∏≠‡∏ô NLP ‡∏î‡πâ‡∏ß‡∏¢ Python ‡πÅ‡∏•‡∏∞ NLTK ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏ù‡∏∂‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥ (tokenization) | Tokenization, part-of-speech tagging, text classification, sentiment analysis                        | `[Beginner]`             | [NLTK Book](https://www.nltk.org/book/)                                                                                 |

### 1.5 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (How to Proceed)

1. **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:** ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ Machine Learning ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ Linear Algebra ‡∏Ç‡∏≠‡∏á 3Blue1Brown ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏£‡πå‡∏™ Probability and Statistics ‡∏Ç‡∏≠‡∏á Khan Academy ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô `[Beginner]`
2. **‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏†‡∏≤‡∏©‡∏≤ Python:** ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ Google's Python Class ‡∏´‡∏£‡∏∑‡∏≠ Automate the Boring Stuff ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏π‡πà‡πÑ‡∏õ‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏á‡πà‡∏≤‡∏¢‡πÜ `[Beginner/Intermediate]`
3. **‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏°:** ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô DeepLearning.AI Specialization ‡∏´‡∏£‡∏∑‡∏≠ fast.ai Course ‡πÅ‡∏•‡∏∞‡∏î‡∏π‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏Ç‡∏≠‡∏á 3Blue1Brown ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏´‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‡∏•‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ PyTorch `[Beginner/Intermediate]`
4. **‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å NLP:** ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ CS224N ‡∏Ç‡∏≠‡∏á Stanford ‡πÅ‡∏•‡∏∞‡∏•‡∏≠‡∏á‡∏ó‡∏≥ Hugging Face NLP Course ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å fine-tuning ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° `[Intermediate]`
5. **‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:** ‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠ MML ‡πÅ‡∏•‡∏∞ Jurafsky & Martin ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á language model `[Intermediate/Advanced]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ Machine Learning ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠ ‡∏ù‡∏∂‡∏Å‡∏ó‡∏≥‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à
- ‡∏≠‡∏¢‡πà‡∏≤‡∏Å‡∏•‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏•‡∏≠‡∏á‡∏ú‡∏¥‡∏î‡∏•‡∏≠‡∏á‡∏ñ‡∏π‡∏Å ‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏≥‡πÑ‡∏° gradient descent ‡∏ñ‡∏∂‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
- ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå ‡πÄ‡∏ä‡πà‡∏ô Reddit (r/MachineLearning), Stack Overflow ‡∏´‡∏£‡∏∑‡∏≠ Hugging Face Forums ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏Ç‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏±‡πà‡∏ô‡∏Ñ‡∏á‡πÉ‡∏ô‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå, Python, ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏° ‡πÅ‡∏•‡∏∞ NLP ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á*

### 1.1 ‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Machine Learning

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                    | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                   | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                    | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)     | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                              |
| :------------------------------------------- | :------------------------------------------------------------------------------------------------------------ | :----------------------------------------------------------------------------------------- | :---------------- | :-------------------------------------------------------------------------------------------------------------------------------- |
| 3Blue1Brown - Linear Algebra                 | ‡∏ä‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏™‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏û‡∏µ‡∏ä‡∏Ñ‡∏ì‡∏¥‡∏ï‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏´‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ã‡∏õ‡∏ï‡πå‡∏¢‡∏≤‡∏Å‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏°‡∏ó‡∏£‡∏¥‡∏Å‡∏ã‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô PCA | ‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå, ‡πÄ‡∏°‡∏ó‡∏£‡∏¥‡∏Å‡∏ã‡πå, ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á (transformations), ‡∏Ñ‡πà‡∏≤‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á (eigenvalues - ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô PCA), ‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á (eigenvectors - ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô SVD) | `[Beginner]`      | [YouTube Playlist](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)                                     |
| Khan Academy - Probability and Statistics    | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡∏ü‡∏£‡∏µ ‡∏™‡∏≠‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ML ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô, ‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á (distributions), ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö‡πÄ‡∏ö‡∏¢‡πå (Bayesian inference)      | `[Beginner/Intermediate]` | [Khan Academy Course](https://www.khanacademy.org/math/statistics-probability)                                                     |
| Mathematics for Machine Learning (MML)       | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ü‡∏£‡∏µ‡∏à‡∏≤‡∏Å Cambridge ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô ML ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö gradient descent | ‡∏û‡∏µ‡∏ä‡∏Ñ‡∏ì‡∏¥‡∏ï‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô, ‡πÅ‡∏Ñ‡∏•‡∏Ñ‡∏π‡∏•‡∏±‡∏™, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô, ‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (optimization)                        | `[Intermediate/Advanced]` | [MML Book](https://mml-book.github.io/)                                                                                       |
| All of Statistics (Wasserman)                | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏ô‡∏∏‡∏Å‡∏£‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô ML ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ñ‡∏î‡∏ñ‡∏≠‡∏¢‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á | ‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏≤‡∏ô‡∏ó‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ (statistical inference), ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡∏ñ‡∏î‡∏ñ‡∏≠‡∏¢ (regression), ‡∏≠‡∏ô‡∏∏‡∏Å‡∏£‡∏°‡πÄ‡∏ß‡∏•‡∏≤ (time series) | `[Advanced]`      | [All of Statistics Book](https://www.stat.cmu.edu/~larry/all-of-statistics/) ‡∏´‡∏£‡∏∑‡∏≠ [Springer Link](https://link.springer.com/book/10.1007/978-0-387-21736-9) |

### 1.2 ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Python

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                  | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                          | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                       | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)        | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                |
| :------------------------------------------- | :-------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------- | :------------------- | :-------------------------------------------------------------------------------------------------- |
| Python Official Documentation              | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á Python ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢‡πÉ‡∏ô ML ‡πÄ‡∏ä‡πà‡∏ô `random` ‡∏´‡∏£‡∏∑‡∏≠ `math` | ‡πÑ‡∏ß‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå (syntax), ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡πÇ‡∏°‡∏î‡∏π‡∏• (modules), ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô (standard library)               | `[All Levels]`   | [Python Docs](https://docs.python.org/3/)                                                               |
| Google's Python Class                      | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏ü‡∏£‡∏µ‡∏à‡∏≤‡∏Å Google ‡∏™‡∏≠‡∏ô Python ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏ù‡∏∂‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå | ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô, ‡∏™‡∏ï‡∏£‡∏¥‡∏á (strings), ‡∏•‡∏¥‡∏™‡∏ï‡πå (lists), ‡∏î‡∏¥‡∏Å‡∏ä‡∏±‡∏ô‡∏ô‡∏≤‡∏£‡∏µ (dictionaries), ‡πÑ‡∏ü‡∏•‡πå, regular expressions      | `[Beginner]`       | [Google's Python Class](https://developers.google.com/edu/python/)                                      |
| Corey Schafer - Python Tutorials           | ‡∏ä‡πà‡∏≠‡∏á YouTube ‡∏™‡∏≠‡∏ô Python ‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ OOP ‡πÅ‡∏•‡∏∞‡∏á‡∏≤‡∏ô data science ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ pandas | ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏ä‡∏¥‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ (OOP), ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏ß‡πá‡∏ö, ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (data science)            | `[Beginner/Intermediate]` | [Corey Schafer YouTube](https://www.youtube.com/c/Coreymschafer)                                        |
| Sentdex - Python Programming Tutorials     | ‡∏ä‡πà‡∏≠‡∏á YouTube ‡∏™‡∏≠‡∏ô Python ‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ML ‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ NumPy          | Machine Learning, ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏ß‡πá‡∏ö, ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏Å‡∏°                                 | `[Intermediate]`    | [Sentdex YouTube](https://www.youtube.com/c/sentdex)                                                 |
| Python for Data Analysis (Wes McKinney)    | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏™‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Python (‡πÄ‡∏ô‡πâ‡∏ô pandas) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô ML ‡πÅ‡∏•‡∏∞ data science   | pandas, NumPy, ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (data visualization)     | `[Intermediate/Advanced]` | [Python for Data Analysis](https://wesmckinney.com/book/)                                               |
| Automate the Boring Stuff with Python      | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏ü‡∏£‡∏µ ‡∏™‡∏≠‡∏ô Python ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏á‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô   | ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå, ‡∏Å‡∏≤‡∏£ scraping ‡πÄ‡∏ß‡πá‡∏ö, ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö Excel                                 | `[Beginner]`        | [Automate the Boring Stuff](https://automatetheboringstuff.com/)                                       |

### 1.3 ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏° (Neural Networks)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                    | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                                   | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                   |
| :------------------------------------------- | :--------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------- | :--------------------- | :--------------------------------------------------------------------------------------------------------------------- |
| DeepLearning.AI - Deep Learning Specialization | ‡∏ä‡∏∏‡∏î‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡∏ö‡∏ô Coursera ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô Deep Learning ‡πÄ‡∏ä‡πà‡∏ô backpropagation ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏°     | ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏°, backpropagation, convolutional neural networks (CNNs), recurrent neural networks (RNNs) | `[Beginner/Intermediate]` | [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning)                                  |
| 3Blue1Brown - Neural Networks                | ‡∏ä‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏° ‡πÄ‡∏ä‡πà‡∏ô gradient descent ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏≠‡∏£‡πå‡πÄ‡∏ã‡∏õ‡∏ï‡∏£‡∏≠‡∏ô       | ‡πÄ‡∏û‡∏≠‡∏£‡πå‡πÄ‡∏ã‡∏õ‡∏ï‡∏£‡∏≠‡∏ô (perceptrons), ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô (activation functions), backpropagation, gradient descent   | `[Beginner]`          | [Neural Networks Playlist](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)                  |
| fast.ai - Practical Deep Learning for Coders | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡πÄ‡∏ô‡πâ‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ ‡∏™‡∏≠‡∏ô Deep Learning ‡∏î‡πâ‡∏ß‡∏¢ fastai (‡∏ö‡∏ô PyTorch) ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏£‡∏¥‡∏á          | ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ Deep Learning, PyTorch, ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ fastai                                                  | `[Intermediate]`       | [fast.ai Course](https://course.fast.ai/)                                                                            |
| Stanford CS231n - Convolutional Neural Networks | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏à‡∏≤‡∏Å Stanford ‡πÄ‡∏ô‡πâ‡∏ô CNNs ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô Computer Vision ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° CNN ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î   | Convolutional layers, pooling layers, ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° CNN ‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°                                       | `[Intermediate/Advanced]` | [CS231n Course](http://cs231n.stanford.edu/)                                                                         |
| Transformers Explained (Hugging Face)        | ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡∏à‡∏≤‡∏Å Hugging Face ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô Transformers ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLM ‡πÄ‡∏ä‡πà‡∏ô attention mechanism     | Attention mechanism, self-attention, Transformer architecture                                  | `[Beginner/Intermediate]` | [Transformers Explained](https://huggingface.co/docs/transformers/quicktour)                                         |

### 1.4 ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ (NLP)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                                                       | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                  | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                                                | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                   |
| :------------------------------------------------------------------------------ | :----------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------- | :--------------------- | :--------------------------------------------------------------------------------------------------------------------- |
| Stanford CS224N - NLP with Deep Learning                                       | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏à‡∏≤‡∏Å Stanford ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° NLP ‡∏™‡∏°‡∏±‡∏¢‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢ Deep Learning ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ transformers ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤            | Word embeddings, recurrent neural networks (RNNs), transformers, question answering, machine translation  | `[Intermediate/Advanced]` | [CS224N Course](http://web.stanford.edu/class/cs224n/)                                                                   |
| Jurafsky & Martin - Speech and Language Processing (3rd ed. draft)              | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô NLP ‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå (‡∏â‡∏ö‡∏±‡∏ö‡∏£‡πà‡∏≤‡∏á‡∏ü‡∏£‡∏µ) ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ñ‡∏∂‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á ‡πÄ‡∏ä‡πà‡∏ô language modeling          | Language modeling, parsing, semantics, discourse, machine translation                                        | `[Intermediate/Advanced]` | [SLP Book (3rd ed. draft)](https://web.stanford.edu/~jurafsky/slp3/)                                                       |
| Hugging Face - NLP Course                                                      | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™ interactive ‡∏™‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Transformers library ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô NLP ‡πÄ‡∏ä‡πà‡∏ô fine-tuning ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° | Transformers, tokenization, fine-tuning, ‡∏á‡∏≤‡∏ô NLP ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ                                               | `[Beginner/Intermediate]` | [Hugging Face Course](https://huggingface.co/learn/nlp-course/chapter1/1)                                                   |
| Natural Language Processing with Python (NLTK Book)                            | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏ü‡∏£‡∏µ‡∏™‡∏≠‡∏ô NLP ‡∏î‡πâ‡∏ß‡∏¢ Python ‡πÅ‡∏•‡∏∞ NLTK ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏ù‡∏∂‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥ (tokenization) | Tokenization, part-of-speech tagging, text classification, sentiment analysis                        | `[Beginner]`             | [NLTK Book](https://www.nltk.org/book/)                                                                                 |

### 1.5 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (How to Proceed)

1. **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:** ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ Machine Learning ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ Linear Algebra ‡∏Ç‡∏≠‡∏á 3Blue1Brown ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏£‡πå‡∏™ Probability and Statistics ‡∏Ç‡∏≠‡∏á Khan Academy ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô `[Beginner]`
2. **‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏†‡∏≤‡∏©‡∏≤ Python:** ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ Google's Python Class ‡∏´‡∏£‡∏∑‡∏≠ Automate the Boring Stuff ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏π‡πà‡πÑ‡∏õ‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏á‡πà‡∏≤‡∏¢‡πÜ `[Beginner/Intermediate]`
3. **‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏°:** ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô DeepLearning.AI Specialization ‡∏´‡∏£‡∏∑‡∏≠ fast.ai Course ‡πÅ‡∏•‡∏∞‡∏î‡∏π‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏Ç‡∏≠‡∏á 3Blue1Brown ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏´‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‡∏•‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ PyTorch `[Beginner/Intermediate]`
4. **‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å NLP:** ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ CS224N ‡∏Ç‡∏≠‡∏á Stanford ‡πÅ‡∏•‡∏∞‡∏•‡∏≠‡∏á‡∏ó‡∏≥ Hugging Face NLP Course ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å fine-tuning ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° `[Intermediate]`
5. **‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:** ‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠ MML ‡πÅ‡∏•‡∏∞ Jurafsky & Martin ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á language model `[Intermediate/Advanced]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ Machine Learning ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠ ‡∏ù‡∏∂‡∏Å‡∏ó‡∏≥‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à
- ‡∏≠‡∏¢‡πà‡∏≤‡∏Å‡∏•‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏•‡∏≠‡∏á‡∏ú‡∏¥‡∏î‡∏•‡∏≠‡∏á‡∏ñ‡∏π‡∏Å ‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏≥‡πÑ‡∏° gradient descent ‡∏ñ‡∏∂‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
- ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå ‡πÄ‡∏ä‡πà‡∏ô Reddit (r/MachineLearning), Stack Overflow ‡∏´‡∏£‡∏∑‡∏≠ Hugging Face Forums ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏Ç‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£ LLM (The LLM Engineer)

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ LLM ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡πÇ‡∏î‡∏¢‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢*

### 3.1 ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢ LLMs (Building Applications with LLMs)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                  | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                      | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                               | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
| :----------------------------------------- | :----------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------- | :--------------------- | :----------------------------------------------------------------------------------------------- |
| LangChain Documentation                    | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á LangChain ‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Å‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏î‡πâ‡∏ß‡∏¢ LLM ‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó | LLM chains, agents, memory, document loaders, indexes                                      | `[Intermediate/Advanced]` | [LangChain Docs](https://python.langchain.com/docs/get_started/introduction)                     |
| LlamaIndex Documentation                   | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á LlamaIndex (‡πÄ‡∏î‡∏¥‡∏°‡∏ä‡∏∑‡πà‡∏≠ GPT Index) ‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° LLM ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ | Data connectors, indexes, query engines, data agents                                       | `[Intermediate/Advanced]` | [LlamaIndex Docs](https://docs.llamaindex.ai/en/stable/)                                         |
| Guidance Documentation (Microsoft)         | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏≠‡∏á Guidance ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏à‡∏≤‡∏Å Microsoft ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏±‡∏ö LLM ‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ó‡∏°‡πÄ‡∏û‡∏•‡∏ï‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö | Language model control, templating, logic, chat interface                                 | `[Intermediate]`       | [Guidance Docs](https://github.com/guidance-ai/guidance)                                         |
| Building LLM Applications (Hugging Face)   | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏™‡∏±‡πâ‡∏ô‡∏à‡∏≤‡∏Å DeepLearning.AI ‡πÅ‡∏•‡∏∞ Hugging Face ‡∏™‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ LLM ‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÇ‡∏≠‡πÄ‡∏û‡∏ô‡∏ã‡∏≠‡∏£‡πå‡∏™ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ retrieval | Prompt engineering, ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ LLM ‡πÇ‡∏≠‡πÄ‡∏û‡∏ô‡∏ã‡∏≠‡∏£‡πå‡∏™, retrieval, ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á agents                     | `[Intermediate]`       | [Hugging Face Course](https://www.deeplearning.ai/short-courses/building-llm-applications-with-hugging-face/) |
| Build a GitHub Copilot Clone (YouTube)     | ‡∏ö‡∏ó‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô ‡∏™‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ GitHub Copilot ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥            | LangChain, OpenAI API, vector databases, Streamlit                                       | `[Intermediate/Advanced]` | [GitHub Copilot Clone Tutorial](https://www.youtube.com/watch?v=M-D2_UrjR-E)                    |
| Build a Custom ChatGPT Clone (YouTube)     | ‡∏ö‡∏ó‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ ChatGPT ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞                    | LangChain, OpenAI API, Gradio                                                    | `[Intermediate/Advanced]` | [ChatGPT Clone Tutorial](https://www.youtube.com/watch?v=RIWbalZ7wTo)                   |

### 3.2 ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏≠‡∏á LLM (Enhancing LLM Performance and Efficiency)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                                           | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                   | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                                    | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                     |
| :------------------------------------------------------------------ | :------------------------------------------------------------------------------------------------------------ | :------------------------------------------------------------------------------------------ | :--------------------- | :----------------------------------------------------------------------------------------------------------------------- |
| vLLM Documentation                                                | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏≠‡∏á vLLM ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ inference LLM ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ PagedAttention           | PagedAttention, continuous batching, optimized CUDA kernels                                    | `[Advanced]`      | [vLLM Docs](https://docs.vllm.ai/en/latest/)                                                                          |
| Optimum Documentation (Hugging Face)                                 | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏≠‡∏á Hugging Face Optimum ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÇ‡∏°‡πÄ‡∏î‡∏• Transformers ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ quantization      | Quantization, pruning, graph optimization, ONNX Runtime, OpenVINO                               | `[Intermediate/Advanced]` | [Optimum Docs](https://huggingface.co/docs/optimum/index)                                                               |
| Text Generation Inference (TGI) (Hugging Face)                          | Inference container ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö tensor parallelism                          | Optimized transformers, tensor parallelism, continuous batching, PagedAttention                   | `[Advanced]`      | [TGI (GitHub)](https://github.com/huggingface/text-generation-inference)                                                  |
| FasterTransformer (NVIDIA)                                        | ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏à‡∏≤‡∏Å NVIDIA ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡πà‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÇ‡∏°‡πÄ‡∏î‡∏• Transformer ‡∏ö‡∏ô GPU ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ INT8 inference                     | Optimized CUDA kernels, INT8 inference, FP16 inference                                          | `[Advanced]`      | [FasterTransformer (GitHub)](https://github.com/NVIDIA/FasterTransformer)                                                |
| DeepSpeed Inference: Enabling Efficient Inference (Microsoft)     | ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡πâ‡∏≤‡∏ô inference ‡∏Ç‡∏≠‡∏á DeepSpeed ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥                       | Model parallelism, memory optimization, optimized kernels                                      | `[Advanced]`      | [DeepSpeed Inference Blog](https://www.deepspeed.ai/tutorials/inference-tutorial/)                                      |
| Efficient Inference on a Single GPU                               | ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏™‡∏≤‡∏ò‡∏¥‡∏ï‡∏Å‡∏≤‡∏£ inference LLM ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ FlashAttention ‡∏ö‡∏ô GPU ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß                | Quantization, FlashAttention, bettertransformer                                                | `[Advanced]`      | [Hugging Face Blog](https://huggingface.co/blog/4bit-transformers-bitsandbytes)                                         |

### 3.3 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á LLM (LLM Security)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                             | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                     | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                                                | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)   | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                                |
| :---------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------- | :------------- | :----------------------------------------------------------------------------------------------------------------------------------- |
| OWASP Top 10 for LLM Applications                  | ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ 10 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏≠‡∏õ LLM ‡∏à‡∏≤‡∏Å OWASP ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡∏î‡πâ‡∏ß‡∏¢ prompt injection          | Prompt injection, insecure output handling, training data poisoning, denial of service, sensitive information disclosure | `[Intermediate/Advanced]` | [OWASP Top 10 for LLM](https://owasp.org/www-project-top-10-for-large-language-model-applications/)                                |
| NIST - Adversarial Machine Learning: A Taxonomy and Terminology    | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏à‡∏≤‡∏Å NIST ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡∏î‡πâ‡∏≤‡∏ô Adversarial ML ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡πÅ‡∏ö‡∏ö poisoning                     | Poisoning attacks, evasion attacks, model extraction                                                  | `[Advanced]`     | [NIST Adversarial ML](https://csrc.nist.gov/pubs/ai/100/2/final)                                                                 |
| Robustness Gym (Hugging Face)                         | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• NLP ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡πÅ‡∏ö‡∏ö adversarial                                   | Attacks, evaluation metrics, robustness analysis                                              | `[Intermediate/Advanced]` | [Robustness Gym (GitHub)](https://github.com/robustness-gym/robustness-gym)                                              |
| Garak (llm-security.github.io)                        | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡πÅ‡∏Å‡∏ô‡∏ä‡πà‡∏≠‡∏á‡πÇ‡∏´‡∏ß‡πà‡∏Ç‡∏≠‡∏á LLM ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö prompt injection ‡∏´‡∏£‡∏∑‡∏≠ data leakage                           | Prompt injection, data leakage, jailbreaking                                                  | `[Intermediate/Advanced]` | [Garak](https://llm-security.github.io/garak/)                                                          |

### 3.4 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (How to Proceed)

1. **‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:** ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ LangChain ‡∏´‡∏£‡∏∑‡∏≠ LlamaIndex ‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ `[Intermediate]`
2. **‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Å‡∏±‡∏ö Guidance:** ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° LLM ‡πÉ‡∏´‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Guidance ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö `[Intermediate]`
3. **‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û:** ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏ä‡πà‡∏ô quantization, pruning ‡πÅ‡∏•‡∏∞ optimized kernels ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ vLLM, Optimum ‡∏´‡∏£‡∏∑‡∏≠ TGI `[Advanced]`
4. **‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢:** ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ OWASP Top 10 for LLM ‡πÅ‡∏•‡∏∞ NIST Adversarial ML ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô `[Intermediate/Advanced]`
5. **‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠:** ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Robustness Gym ‡πÅ‡∏•‡∏∞ Garak ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• `[Intermediate/Advanced]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ LLM ‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
- ‡∏ó‡∏î‡∏•‡∏≠‡∏á deploy ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå (AWS, GCP) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
- ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏ä‡∏∏‡∏°‡∏ä‡∏ô ‡πÄ‡∏ä‡πà‡∏ô Hugging Face Forums ‡∏´‡∏£‡∏∑‡∏≠ Reddit (r/MachineLearning) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏´‡∏°‡πà‡πÜ

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏•‡∏∞ Repository ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á (Advanced Scripts & Repositories)

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå repositories ‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏•‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤ LLM ‡πÉ‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å*

### 4.1 DeepSeek AI Repositories

*Repositories ‡∏à‡∏≤‡∏Å DeepSeek AI ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ß‡∏¥‡∏à‡∏±‡∏¢ AI ‡∏ó‡∏µ‡πà‡πÄ‡∏ô‡πâ‡∏ô‡∏á‡∏≤‡∏ô Open Source*

#### Performance Optimization

| Repository                                  | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                       | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                    |
| :------------------------------------------ | :------------------------------------------------------------------------------------------------------------ | :---------------------------------------------------------------------------------------- |
| DeepSpeed-FastGen                          | ‡∏£‡∏∞‡∏ö‡∏ö inference ‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ô DeepSpeed ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô real-time                          | [DeepSpeed-FastGen (GitHub)](https://github.com/DeepSpeed-MII/DeepSpeed-FastGen)             |
| DeepSpeed-Kernels                           | Custom CUDA kernels ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DeepSpeed ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÇ‡∏°‡πÄ‡∏î‡∏• LLM                                     | [DeepSpeed-Kernels (GitHub)](https://github.com/microsoft/DeepSpeed-Kernels)                |
| DeepSpeed-MII                            | ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö deploy ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û LLM ‡∏î‡πâ‡∏ß‡∏¢ DeepSpeed ‡πÄ‡∏ä‡πà‡∏ô ‡∏•‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥                          | [DeepSpeed-MII (GitHub)](https://github.com/microsoft/DeepSpeed-MII)                           |
| DeepSpeed                                     | ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏à‡∏≤‡∏Å Microsoft ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö optimize ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞ inference ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà                                   | [DeepSpeed (GitHub)](https://github.com/microsoft/DeepSpeed)                                  |
| 3FS: Fast, Flexible, and Friendly Sparse Attention    | ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Sparse Attention ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì attention                                     | [3FS](https://github.com/DeepSeek-AI/3FS)             |
| DeepGEMM                                  | GEMM (General Matrix Multiplication) ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å                            | [DeepGEMM (GitHub)](https://github.com/DeepSeek-AI/DeepGEMM)                                |

#### Model Architectures

| Repository                                       | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                  | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                           |
| :----------------------------------------------- | :------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------- |
| DeepSeek-LLM                                  | ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏≠‡πÄ‡∏û‡∏ô‡∏ã‡∏≠‡∏£‡πå‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DeepSeek LLM ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà                     | [DeepSeek-LLM (GitHub)](https://github.com/deepseek-ai/DeepSeek-LLM)                         |
| DeepSeek-MoE                                   | ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏≠‡πÄ‡∏û‡∏ô‡∏ã‡∏≠‡∏£‡πå‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DeepSeek MoE ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ö‡∏ö mixture-of-experts           | [DeepSeek-MoE (GitHub)](https://github.com/deepseek-ai/DeepSeek-MoE)                        |
| FastMoE                                        | ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Mixture of Experts (MoE) ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà       | [FastMoE](https://github.com/laekov/fastmoe)                                         |

#### Datasets
| Repository                                       | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                  | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                           |
| :----------------------------------------------- | :------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------- |
| UltraFeedback                                  | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö preference data ‡πÉ‡∏ä‡πâ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå      | [UltraFeedback](https://huggingface.co/datasets/openbmb/UltraFeedback)                     |

#### Other Tools
| Repository                                  | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                       | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                       |
| :----------------------------------------- | :----------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------ |
| ChatTemplate                              | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ó‡∏°‡πÄ‡∏û‡∏•‡∏ï‡πÅ‡∏ä‡∏ó            | [ChatTemplate](https://github.com/DeepSeek-AI/ChatTemplate)                             |

### 4.2 Uncensored AI Models

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ã‡πá‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå (uncensored) ‡∏ã‡∏∂‡πà‡∏á‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∞‡∏°‡∏±‡∏î‡∏£‡∏∞‡∏ß‡∏±‡∏á‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö‡∏ï‡πà‡∏≠‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏≤‡∏°‡∏°‡∏≤*

**‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô:** ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ uncensored models ‡∏≠‡∏≤‡∏à‡∏ô‡∏≥‡πÑ‡∏õ‡∏™‡∏π‡πà‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢ ‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡∏´‡∏£‡∏∑‡∏≠‡∏ú‡∏¥‡∏î‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢ ‡πÇ‡∏õ‡∏£‡∏î‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏™‡∏ï‡∏¥

| Repository/Model                | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                  |
| :------------------------------ | :-------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| Dolphin (Eric Hartford)          | ‡πÇ‡∏°‡πÄ‡∏î‡∏• fine-tuned ‡∏à‡∏≤‡∏Å Llama 2 ‡πÅ‡∏•‡∏∞ WizardLM ‡πÄ‡∏ô‡πâ‡∏ô‡∏•‡∏î bias ‡πÅ‡∏•‡∏∞ censorship ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢                 | [Dolphin (Hugging Face)](https://huggingface.co/ehartford/dolphin-2.2.1-mistral-7b)                   |
| OpenHathi-7B-Hi-v0.1-Base (Sarvam AI) | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏Æ‡∏¥‡∏ô‡∏î‡∏µ ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡πÅ‡∏•‡∏∞‡∏Æ‡∏¥‡∏á‡∏•‡∏¥‡∏ä ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢ Sarvam AI ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢                                | [OpenHathi (Hugging Face)](https://huggingface.co/sarvamai/OpenHathi-7B-Hi-v0.1-Base)                |
| OpenOrca (OpenOrca)              | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏≠‡πÄ‡∏û‡∏ô‡∏ã‡∏≠‡∏£‡πå‡∏™ ‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á (instruction following)                                     | [OpenOrca (Hugging Face)](https://huggingface.co/Open-Orca)                                          |
| mpt-30b-chat (MosaicML)         | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ ‡∏Ç‡∏ô‡∏≤‡∏î 30B parameters ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡πÅ‡∏ä‡∏ó‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô                        | [mpt-30b-chat (Hugging Face)](https://huggingface.co/mosaicml/mpt-30b-chat)                         |
| WizardLM (Microsoft)             | ‡πÇ‡∏°‡πÄ‡∏î‡∏• fine-tuned ‡∏à‡∏≤‡∏Å LLaMA ‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ ‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô                | [WizardLM (GitHub)](https://github.com/nlpxucan/WizardLM)                                          |
| OpenThaiGPT (OpenThaiGPT)        | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏≠‡πÄ‡∏û‡∏ô‡∏ã‡∏≠‡∏£‡πå‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡πÑ‡∏ó‡∏¢ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô NLP ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢                               | [OpenThaiGPT (Hugging Face)](https://huggingface.co/openthaigpt)                                   |

### 4.3 Fine-Tuning Tables

| Repository                                          | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                             |
| :-------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------- |
| Unsloth                                            | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö fine-tuning ‡πÅ‡∏•‡∏∞ quantization ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• 7B ‡∏ö‡∏ô GPU ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß           | [Unsloth (GitHub)](https://github.com/unslothai/unsloth)                                                            |
| LLaMA-Factory                                        | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö fine-tuning LLaMA ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö                                     | [LLaMA-Factory (GitHub)](https://github.com/hiyouga/LLaMA-Factory)                                               |
| Axolotl                                             | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ fine-tuning LLM ‡∏ó‡∏µ‡πà‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á                                            | [Axolotl (GitHub)](https://github.com/OpenAccess-AI-Collective/axolotl)                                        |
| PEFT (Hugging Face)                                  | ‡∏ß‡∏¥‡∏ò‡∏µ Parameter-Efficient Fine-Tuning (PEFT) ‡∏à‡∏≤‡∏Å Hugging Face ‡πÄ‡∏ä‡πà‡∏ô LoRA ‡πÅ‡∏•‡∏∞ Prompt Tuning                        | [PEFT (GitHub)](https://github.com/huggingface/peft)                                                        |
| trlX                                              | ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å LLM ‡∏î‡πâ‡∏ß‡∏¢ reinforcement learning (fork ‡∏à‡∏≤‡∏Å TRL) ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ PPO                                 | [trlX](https://github.com/CarperAI/trlx)                                                                  |
| AutoTrain (Hugging Face)                           | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ fine-tuning ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏á‡∏≤‡∏ô‡∏î‡πà‡∏ß‡∏ô                                  | [AutoTrain (Hugging Face)](https://huggingface.co/autotrain)                                              |

### 4.4 Awesome Colab Notebooks

| Notebook                                           | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                      | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                |
| :------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------- |
| Kaggle Notebooks - LLM Science Exam              | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á notebooks ‡∏à‡∏≤‡∏Å Kaggle ‡∏™‡∏≠‡∏ô‡πÉ‡∏ä‡πâ LLM ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö                             | [Kaggle LLM Science Exam](https://www.kaggle.com/competitions/kaggle-llm-science-exam/code)                          |
| ML-Engineering Open Book                         | ‡∏ä‡∏∏‡∏î notebooks ‡πÅ‡∏•‡∏∞‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏° ML ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£ deploy ‡πÇ‡∏°‡πÄ‡∏î‡∏•                                                | [ml-engineering-open-book](https://github.com/stas00/ml-engineering-open-book/tree/master/open-book)                |
| MLOps Course (Made With ML)                      | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏µ notebooks ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ pipeline ML                                                        | [mlops-course](https://github.com/GokuMohandas/mlops-course)                                                       |
| Unsloth Fine-Tuning Example                      | Notebook ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å Unsloth ‡∏™‡∏≠‡∏ô fine-tuning ‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏ä‡πà‡∏ô LLaMA ‡∏ö‡∏ô Colab                                         | [Unsloth Colab](https://colab.research.google.com/drive/1zB1t1qFO5n4bdnqP4KauS2sV_lPtP2Q)                        |

### 4.5 Research Papers

#### Quantization
- SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models: [SmoothQuant](https://arxiv.org/abs/2211.10438)
- GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers: [GPTQ](https://arxiv.org/abs/2210.17323)
- AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration: [AWQ](https://arxiv.org/abs/2306.00978)
- ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers: [ZeroQuant](https://arxiv.org/abs/2206.01861)

#### Fine-Tuning Techniques
- LoRA: Low-Rank Adaptation of Large Language Models: [LoRA](https://arxiv.org/abs/2106.09685)
- QLoRA: Efficient Finetuning of Quantized LLMs: [QLoRA](https://arxiv.org/abs/2305.14314)
- Direct Preference Optimization: Your Language Model is Secretly a Reward Model: [DPO](https://arxiv.org/abs/2305.18290)
- ORPO: Monolithic Preference Optimization without Reference Model: [ORPO](https://arxiv.org/abs/2403.07687)

#### Distributed Training
- ZeRO: Memory Optimizations Toward Training Trillion Parameter Models: [ZeRO](https://arxiv.org/abs/1910.02054)
- Megatron-LM: Training Multi-Billion Parameter Models Using Model Parallelism: [Megatron-LM](https://arxiv.org/abs/1909.08053)
- Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B: [Megatron-Turing NLG 530B](https://arxiv.org/abs/2201.11990)

#### Other Topics
- Llama 2: Open Foundation and Fine-Tuned Chat Models: [Llama2](https://arxiv.org/abs/2307.09288)
- FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness: [FlashAttention](https://arxiv.org/abs/2205.14135)
- FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning: [FlashAttention-2](https://arxiv.org/abs/2307.08691)
- A Survey of Large Language Models: [LLM Survey](https://arxiv.org/abs/2303.18223)
- Instruction Tuning for Large Language Models: A Survey: [Instruction Tuning](https://arxiv.org/abs/2308.10792)

### 4.6 Additional Learning Resources

#### Project Ideas and Datasets
- [Kaggle](https://www.kaggle.com/): ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô Data Science ‡πÅ‡∏•‡∏∞‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢
- [NLP Datasets (Hugging Face)](https://huggingface.co/datasets): ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô NLP

#### Online Courses
- Andrew Ng's Courses on Coursera and DeepLearning.AI: ‡∏Ñ‡∏≠‡∏£‡πå‡∏™ Machine Learning ‡πÅ‡∏•‡∏∞ Deep Learning ‡∏ä‡∏±‡πâ‡∏ô‡∏ô‡∏≥
- fast.ai: ‡∏Ñ‡∏≠‡∏£‡πå‡∏™ Deep Learning ‡πÄ‡∏ô‡πâ‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏à‡∏£‡∏¥‡∏á

#### Podcasts
- Lex Fridman Podcast: ‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ AI ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå
- Data Skeptic: ‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á Data Science, Machine Learning ‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
- The TWIML AI Podcast: ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ ML ‡πÅ‡∏•‡∏∞ AI

#### YouTube Channels
- Sentdex: ‡∏™‡∏≠‡∏ô Python ‡πÅ‡∏•‡∏∞ Machine Learning
- Corey Schafer: ‡∏™‡∏≠‡∏ô Python ‡∏ó‡∏∏‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö
- 3Blue1Brown: ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏î‡πâ‡∏ß‡∏¢‡∏†‡∏≤‡∏û‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß
- Two Minute Papers: ‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠ paper ‡∏ß‡∏¥‡∏à‡∏±‡∏¢ AI ‡πÅ‡∏ö‡∏ö‡∏™‡∏±‡πâ‡∏ô

#### Online Communities
- Reddit: r/MachineLearning, r/LanguageTechnology
- Stack Overflow: ‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏°‡∏≠‡∏£‡πå
- Hugging Face Forums: ‡∏ü‡∏≠‡∏£‡∏±‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ Hugging Face
- Discord Servers: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ "LLM Discord" ‡∏´‡∏£‡∏∑‡∏≠ "AI Discord" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ô‡πâ‡∏ô AI ‡πÅ‡∏•‡∏∞ LLM

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ LLM ‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï (Applying LLMs in Real-World and Future Trends)

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ LLM ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏à‡∏£‡∏¥‡∏á ‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏• ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà‡πÜ ‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï*

### 5.1 ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ LLM (Real-World LLM Projects)

| ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå                                      | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                       | ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ                              | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
| :------------------------------------------- | :----------------------------------------------------------------------------------------------- | :------------------------------------------ | :--------------------- | :----------------------------------------------------------------------------------------------- |
| Chatbot for Customer Support                 | ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô                              | LangChain, Llama 3, Gradio                  | `[Intermediate]`       | [Example Repo](https://github.com/langchain-ai/langchain/tree/master/templates)                  |
| Document Summarization Tool                  | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏¢‡∏≤‡∏ß ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£                                          | Hugging Face Transformers, Mistral 7B       | `[Intermediate/Advanced]` | [Hugging Face Tutorial](https://huggingface.co/docs/transformers/tasks/summarization)           |
| Code Generation Assistant                    | ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Python ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ bug                                      | OpenAI API, GitHub Copilot Clone, Streamlit | `[Intermediate/Advanced]` | [Copilot Clone Tutorial](https://www.youtube.com/watch?v=M-D2_UrjR-E)                          |
| Multilingual Translator                      | ‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡πÑ‡∏ó‡∏¢-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©-‡∏à‡∏µ‡∏ô ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• open-source                              | OpenThaiGPT, mBART                          | `[Advanced]`           | [mBART Docs](https://huggingface.co/docs/transformers/model_doc/mbart)                         |

### 5.2 ‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á LLM (Evaluation and Improvement)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                    | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                           | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                           | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
| :------------------------------------------- | :-------------------------------------------------------------------------------------------------- | :---------------------------------------------- | :--------------------- | :----------------------------------------------------------------------------------------------- |
| Hugging Face Evaluate                        | ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ (accuracy) ‡∏´‡∏£‡∏∑‡∏≠ BLEU score ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤                   | Metrics, evaluation datasets, benchmarking      | `[Intermediate]`       | [Evaluate Docs](https://huggingface.co/docs/evaluate/index)                                      |
| EleutherAI LM Evaluation Harness             | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û LLM ‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô MMLU ‡∏´‡∏£‡∏∑‡∏≠ TruthfulQA                       | Task-specific evaluation, zero-shot testing     | `[Advanced]`           | [LM Eval (GitHub)](https://github.com/EleutherAI/lm-evaluation-harness)                         |
| HumanEval: Evaluating Large Language Models  | Paper ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ HumanEval ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á LLM                             | Code generation metrics, functional correctness | `[Advanced]`           | [HumanEval (Arxiv)](https://arxiv.org/abs/2107.03374)                                           |
| MT-Bench: A Multi-turn Benchmark            | Paper ‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠ MT-Bench ‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á LLM                                | Multi-turn dialogue, human-like responses       | `[Advanced]`           | [MT-Bench (Arxiv)](https://arxiv.org/abs/2306.05685)                                            |

### 5.3 ‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÅ‡∏•‡∏∞‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ LLM (Emerging Trends and Innovations)

| ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠                                         | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                           | ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á                        | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
| :------------------------------------------- | :-------------------------------------------------------------------------------------------------- | :--------------------------------------------- | :----------------------------------------------------------------------------------------------- |
| Multimodal LLMs                              | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÄ‡∏ä‡πà‡∏ô CLIP-ViT ‡∏´‡∏£‡∏∑‡∏≠ DALL-E 3                                | Paper: "Flamingo" (Arxiv)                      | [Flamingo (Arxiv)](https://arxiv.org/abs/2204.14198)                                            |
| Smaller, Efficient Models                    | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡πÅ‡∏ï‡πà‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á ‡πÄ‡∏ä‡πà‡∏ô Phi-3 (Microsoft) ‡∏´‡∏£‡∏∑‡∏≠ TinyLlama ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£       | Phi-3 Blog (Microsoft)                         | [Phi-3 Blog](https://azure.microsoft.com/en-us/blog/introducing-phi-3/)                         |
| AI Agents and Tool Integration               | ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ AI agents ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ LLM ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ ‡πÄ‡∏ä‡πà‡∏ô AutoGen ‡∏´‡∏£‡∏∑‡∏≠ AgentGPT                          | AutoGen (GitHub)                               | [AutoGen (GitHub)](https://github.com/microsoft/autogen)                                        |
| Ethical AI and Regulation                    | ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏é‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏•‡∏î bias ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏î‡∏¢ LLM                 | AI Ethics Guidelines (UNESCO)                  | [UNESCO AI Ethics](https://unesdoc.unesco.org/ark:/48223/pf0000381137)                          |

### 5.4 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (How to Proceed)

1. **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏á‡πà‡∏≤‡∏¢‡πÜ:** ‡∏•‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ LangChain ‡∏´‡∏£‡∏∑‡∏≠ Hugging Face `[Intermediate]`
2. **‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•:** ‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏¢‡πà‡∏≤‡∏á Hugging Face Evaluate ‡∏´‡∏£‡∏∑‡∏≠ LM Evaluation Harness ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤ `[Intermediate/Advanced]`
3. **‡∏™‡∏≥‡∏£‡∏ß‡∏à‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà:** ‡∏≠‡πà‡∏≤‡∏ô paper ‡πÄ‡∏ä‡πà‡∏ô Flamingo ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏à‡∏≤‡∏Å Microsoft ‡πÅ‡∏•‡∏∞ xAI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ ‡πÄ‡∏ä‡πà‡∏ô multimodal LLMs `[Advanced]`
4. **‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á:** ‡∏•‡∏≠‡∏á‡∏£‡∏ß‡∏° LLM ‡∏Å‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏∑‡πà‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏£‡πâ‡∏≤‡∏á AI agent ‡∏î‡πâ‡∏ß‡∏¢ AutoGen ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö edge devices `[Advanced]`
5. **‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏°:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö bias ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô UNESCO AI Ethics `[All Levels]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ LLM ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô ‡∏ö‡∏ô‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡πâ‡∏≠‡∏á‡∏ñ‡∏¥‡πà‡∏ô
- ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏ä‡∏∏‡∏°‡∏ä‡∏ô ‡πÄ‡∏ä‡πà‡∏ô Arxiv ‡∏´‡∏£‡∏∑‡∏≠ X (Twitter) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏û‡∏•‡∏≤‡∏î‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö‡∏ï‡πà‡∏≠‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ç‡∏≠‡∏á LLM ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏¥‡πà‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 6: ‡∏®‡∏±‡∏û‡∏ó‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ LLM (Key Terminology in the LLM Field)

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ Large Language Models (LLM) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ï‡πà‡∏≤‡∏á‡πÜ*

### 6.1 ‡∏®‡∏±‡∏û‡∏ó‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (Basic Terminology)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå                   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢                                                                                       |
| :----------------------- | :--------------------------------------------------------------------------------------------- |
| LLM (Large Language Model) | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å ‡πÉ‡∏ä‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô GPT ‡∏´‡∏£‡∏∑‡∏≠ LLaMA |
| Transformer              | ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLM ‡πÉ‡∏ä‡πâ‡∏Å‡∏•‡πÑ‡∏Å attention ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ö‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö                       |
| Attention                | ‡∏Å‡∏•‡πÑ‡∏Å‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ                       |
| Pre-training             | ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏Å‡πà‡∏≠‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏ñ‡∏±‡∏î‡πÑ‡∏õ                |
| Fine-tuning             | ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà pre-trained ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á              |
| Token                    | ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏¢‡πà‡∏≠‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥ ‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•                            |
| Embedding                | ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡∏´‡∏£‡∏∑‡∏≠ token ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå              |

### 6.2 ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ (Techniques and Methods)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå                   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢                                                                                       |
| :----------------------- | :--------------------------------------------------------------------------------------------- |
| Self-Attention           | ‡∏Å‡∏•‡πÑ‡∏Å attention ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏∏‡∏Å token ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô                           |
| Multi-Head Attention     | ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ attention ‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏±‡πâ‡∏ô‡πÉ‡∏ô Transformer ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢                      |
| Masked Language Model (MLM) | ‡∏ß‡∏¥‡∏ò‡∏µ pre-training ‡∏ó‡∏µ‡πà‡∏ã‡πà‡∏≠‡∏ô‡∏ö‡∏≤‡∏á‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô BERT                        |
| Autoregressive Model     | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô GPT                                   |
| LoRA (Low-Rank Adaptation) | ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ fine-tuning ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£                      |
| QLoRA                    | ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏° quantization ‡∏Å‡∏±‡∏ö LoRA ‡πÄ‡∏û‡∏∑‡πà‡∏≠ fine-tuning ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡πâ‡∏≠‡∏¢‡∏•‡∏á                       |
| Quantization             | ‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏à‡∏≤‡∏Å FP32 ‡πÄ‡∏õ‡πá‡∏ô INT8 ‡∏´‡∏£‡∏∑‡∏≠ 4-bit ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô           |
| Prompt Engineering       | ‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡πâ LLM ‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô prompt                   |
| RLHF (Reinforcement Learning from Human Feedback) | ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ feedback ‡∏à‡∏≤‡∏Å‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£                     |

### 6.3 ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Performance and Deployment)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå                   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢                                                                                       |
| :----------------------- | :--------------------------------------------------------------------------------------------- |
| Inference                | ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏• ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°                            |
| Latency                  | ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö                                                  |
| Throughput               | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏ß‡∏•‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏≥‡∏ï‡πà‡∏≠‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ                                |
| Model Parallelism        | ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏õ‡∏£‡∏±‡∏ô‡∏ö‡∏ô GPU ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà                                  |
| Data Parallelism         | ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏ù‡∏∂‡∏Å‡∏ö‡∏ô GPU ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡πà‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•                                    |
| PagedAttention           | ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÉ‡∏ô inference ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏ç‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û              |
| FlashAttention           | ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ attention ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô pre-training ‡πÅ‡∏•‡∏∞ inference             |

### 6.4 ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏° (Safety and Ethics)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå                   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢                                                                                       |
| :----------------------- | :--------------------------------------------------------------------------------------------- |
| Bias                     | ‡∏≠‡∏Ñ‡∏ï‡∏¥‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏•‡∏≥‡πÄ‡∏≠‡∏µ‡∏¢‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏û‡∏®‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏ä‡∏≤‡∏ï‡∏¥                    |
| Prompt Injection         | ‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡πÇ‡∏î‡∏¢‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢‡πÉ‡∏ô prompt ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏≠‡∏Å‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£                       |
| Jailbreaking             | ‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏ö‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏´‡πâ‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢               |
| Data Poisoning           | ‡∏Å‡∏≤‡∏£‡∏õ‡∏ô‡πÄ‡∏õ‡∏∑‡πâ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î                      |
| Explainability           | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£                                 |

### 6.5 ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Evaluation and Datasets)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå                   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢                                                                                       |
| :----------------------- | :--------------------------------------------------------------------------------------------- |
| BLEU Score               | ‡∏ï‡∏±‡∏ß‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤ ‡πÇ‡∏î‡∏¢‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏õ‡∏•‡∏à‡∏≤‡∏Å‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå                            |
| Perplexity               | ‡∏ï‡∏±‡∏ß‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏à‡∏≠‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏ñ‡∏±‡∏î‡πÑ‡∏õ ‡∏Ñ‡πà‡∏≤‡∏¢‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≥‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ                                |
| MMLU (Massive Multitask Language Understanding) | ‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Ç‡∏≠‡∏á LLM ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏´‡∏•‡∏≤‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå                |
| TruthfulQA               | ‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å LLM                                 |
| HumanEval                | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á LLM ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÇ‡∏à‡∏ó‡∏¢‡πå‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°                    |

### 6.6 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏®‡∏±‡∏û‡∏ó‡πå (How to Proceed)

1. **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:** ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô LLM, Transformer, ‡πÅ‡∏•‡∏∞ Token ‡∏Å‡πà‡∏≠‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô `[Beginner]`
2. **‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏®‡∏±‡∏û‡∏ó‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á LoRA ‡∏´‡∏£‡∏∑‡∏≠ Quantization ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô paper ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ `[Intermediate]`
3. **‡∏ù‡∏∂‡∏Å‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á:** ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå ‡πÄ‡∏ä‡πà‡∏ô ‡∏ß‡∏±‡∏î latency ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥ prompt engineering ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏´‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô `[Intermediate/Advanced]`
4. **‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢:** ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ bias ‡πÅ‡∏•‡∏∞ prompt injection ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡πâ‡∏≤‡∏ó‡∏≤‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏° `[All Levels]`
5. **‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡πÉ‡∏´‡∏°‡πà:** ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏´‡∏£‡∏∑‡∏≠ paper ‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≤‡∏Å Hugging Face ‡∏´‡∏£‡∏∑‡∏≠ Arxiv ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î `[Advanced]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ LLM ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏Ñ‡∏≥‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡∏≤‡∏°‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤
- ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏®‡∏±‡∏û‡∏ó‡πå‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
- ‡∏•‡∏≠‡∏á‡∏à‡∏î‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠‡∏ö‡πà‡∏≠‡∏¢‡πÅ‡∏•‡∏∞‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∏‡πâ‡∏ô‡πÄ‡∏Ñ‡∏¢

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 7: ‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö LLM (Example Files and Links for LLMs)

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Colab Notebooks ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå ‡πÅ‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö Large Language Models (LLM) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏ô‡∏≥‡πÑ‡∏õ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏î‡πâ*

### 7.1 Colab Notebooks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM

| ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå/‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                              | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                   |
| :-------------------------------------------- | :--------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| LLaMA Fine-Tuning with Unsloth                | ‡∏™‡∏≠‡∏ô fine-tuning LLaMA ‡∏î‡πâ‡∏ß‡∏¢ Unsloth ‡∏ö‡∏ô Colab ‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏ö‡∏ô GPU ‡∏ü‡∏£‡∏µ                | [Unsloth Fine-Tuning](https://colab.research.google.com/drive/1zB1t1qFO5n4bdnqP4KauS2sV_lPtP2Q)         |
| Fine-Tune Llama 3 with DPO & LoRA             | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á fine-tuning Llama 3 ‡∏î‡πâ‡∏ß‡∏¢ DPO ‡πÅ‡∏•‡∏∞ LoRA                              | [Llama 3 DPO](https://colab.research.google.com/drive/1K2vQA9r5tB0n2XTR1Zc6oQ5s-w6WxxJ)              |
| Build Your Own GPT from Scratch               | ‡∏™‡∏£‡πâ‡∏≤‡∏á GPT ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏à‡∏≤‡∏Å‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏î‡πâ‡∏ß‡∏¢ Python ‡∏ö‡∏ô Colab                             | [Build GPT](https://colab.research.google.com/drive/1JMLaCPxM7B6UzT0I8vDwAIXeH-oQss4)                |
| Hugging Face Transformers Tutorial            | ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Transformers ‡πÄ‡∏ä‡πà‡∏ô BERT ‡∏´‡∏£‡∏∑‡∏≠ GPT-2                           | [Transformers Tutorial](https://colab.research.google.com/drive/1rXvHQMjt0r3ADP9gEg0rHfx)         |
| Quantization with BitsAndBytes                | ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ 4-bit quantization ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£          | [Quantization Colab](https://colab.research.google.com/drive/1VoYNfYdk7zLVRWj8DHRcvcK)             |
| LangChain RAG Example                         | ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö Retrieval-Augmented Generation (RAG) ‡∏î‡πâ‡∏ß‡∏¢ LangChain              | [LangChain RAG](https://colab.research.google.com/drive/1G5i7qQe7e5vU5gW5zR0rL8v)                |
| Mistral 7B Inference                          | ‡∏£‡∏±‡∏ô Mistral 7B ‡πÄ‡∏û‡∏∑‡πà‡∏≠ inference ‡∏ö‡∏ô Colab                                    | [Mistral 7B](https://colab.research.google.com/drive/1zXy5t8nXz9v5gW5sR0rL8v)                   |
| Train a Tiny LLM with TinyStories             | ‡∏ù‡∏∂‡∏Å LLM ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• TinyStories                                  | [Tiny LLM](https://colab.research.google.com/drive/1Xy5t8nXz9v5gW5sR0rL8v)                     |

### 7.2 ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å GitHub

| ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå/Repository                          | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                   |
| :------------------------------------------ | :--------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| minGPT (Karpathy)                            | ‡πÇ‡∏Ñ‡πâ‡∏î Python ‡∏™‡∏£‡πâ‡∏≤‡∏á GPT ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏à‡∏≤‡∏Å Andrej Karpathy                           | [minGPT](https://github.com/karpathy/minGPT)                                                          |
| nanoGPT                                      | ‡∏≠‡∏µ‡∏Å‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏Ç‡∏≠‡∏á GPT ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å ‡∏ù‡∏∂‡∏Å‡πÑ‡∏î‡πâ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤                           | [nanoGPT](https://github.com/karpathy/nanoGPT)                                                        |
| LLaMA-Factory Scripts                        | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö fine-tuning LLaMA ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô‡πÜ                              | [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory/tree/main/scripts)                           |
| DeepSpeed Training Example                   | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ DeepSpeed                                        | [DeepSpeed Examples](https://github.com/microsoft/DeepSpeed/tree/master/examples)                     |
| Hugging Face Transformers Examples           | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å BERT ‡∏´‡∏£‡∏∑‡∏≠ GPT-2                              | [Transformers Examples](https://github.com/huggingface/transformers/tree/main/examples)                |
| Axolotl Fine-Tuning Scripts                  | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå fine-tuning LLM ‡∏ó‡∏µ‡πà‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô                                       | [Axolotl Scripts](https://github.com/OpenAccess-AI-Collective/axolotl/tree/main/examples)             |
| vLLM Inference Script                        | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö inference ‡∏î‡πâ‡∏ß‡∏¢ vLLM                                         | [vLLM Examples](https://github.com/vllm-project/vllm/tree/main/examples)                              |
| FlashAttention Implementation                | ‡πÇ‡∏Ñ‡πâ‡∏î Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö FlashAttention                                         | [FlashAttention](https://github.com/Dao-AILab/flash-attention)                                        |

### 7.3 ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Datasets) ‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á

| ‡∏ä‡∏∑‡πà‡∏≠‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•/‡πÑ‡∏ü‡∏•‡πå                           | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                   |
| :------------------------------------------ | :--------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| The Pile                                      | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å LLM (800GB)                                    | [The Pile](https://pile.eleuther.ai/)                                                                 |
| TinyStories                                  | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏±‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å                                 | [TinyStories](https://huggingface.co/datasets/roneneldan/TinyStories)                                 |
| OpenWebText                                  | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö pre-training                                | [OpenWebText](https://huggingface.co/datasets/Skylion007/openwebtext)                                 |
| Alpaca Dataset                               | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• instruction-tuning ‡∏à‡∏≤‡∏Å Stanford                                 | [Alpaca](https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json)                     |
| Dolly 15k                                    | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 15,000 ‡∏Ñ‡∏π‡πà‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö fine-tuning                         | [Dolly 15k](https://huggingface.co/datasets/databricks-dolly-15k)                                     |
| UltraFeedback                                | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• preference ‡∏à‡∏≤‡∏Å OpenBMB                                          | [UltraFeedback](https://huggingface.co/datasets/openbmb/UltraFeedback)                                |
| MMLU Dataset                                 | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Ç‡∏≠‡∏á LLM                                       | [MMLU](https://huggingface.co/datasets/lukaemon/mmlu)                                                 |

### 7.4 ‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ (Pre-trained Models)

| ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•                                   | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                   |
| :------------------------------------------ | :--------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| Llama 3 (Meta)                               | ‡πÇ‡∏°‡πÄ‡∏î‡∏• Llama 3 ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡πà‡∏≤‡∏á‡πÜ (‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå)                                    | [Llama 3](https://huggingface.co/meta-llama/Llama-3-8b)                                               |
| Mistral 7B                                   | ‡πÇ‡∏°‡πÄ‡∏î‡∏• 7B parameters ‡∏à‡∏≤‡∏Å Mistral AI                                       | [Mistral 7B](https://huggingface.co/mistralai/Mixtral-7B-v0.1)                                        |
| GPT-2 (OpenAI)                               | ‡πÇ‡∏°‡πÄ‡∏î‡∏• GPT-2 ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏•‡∏≠‡∏á                                           | [GPT-2](https://huggingface.co/gpt2)                                                                  |
| BERT Base (Google)                           | ‡πÇ‡∏°‡πÄ‡∏î‡∏• BERT ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NLP                                             | [BERT Base](https://huggingface.co/bert-base-uncased)                                                 |
| OpenThaiGPT                                  | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏à‡∏≤‡∏Å‡∏ä‡∏∏‡∏°‡∏ä‡∏ô OpenThaiGPT                                         | [OpenThaiGPT](https://huggingface.co/openthaigpt/openthaigpt-1.0.0-7b)                                |
| DeepSeek R1                                  | ‡πÇ‡∏°‡πÄ‡∏î‡∏• open-weight 671B parameters                                        | [DeepSeek R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)                                         |
| Phi-3 (Microsoft)                            | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡πÅ‡∏ï‡πà‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å Microsoft                                      | [Phi-3](https://huggingface.co/microsoft/phi-3-mini-4k-instruct)                                      |

### 7.5 ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏∑‡πà‡∏ô‡πÜ

| ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå/‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠                      | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                   |
| :------------------------------------------ | :--------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| LangChain Examples                           | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô LangChain ‡πÄ‡∏ä‡πà‡∏ô RAG ‡∏´‡∏£‡∏∑‡∏≠ agents                          | [LangChain Examples](https://github.com/langchain-ai/langchain/tree/master/templates)                 |
| LlamaIndex Examples                          | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° LLM ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å‡∏î‡πâ‡∏ß‡∏¢ LlamaIndex                      | [LlamaIndex Examples](https://github.com/run-llama/llama_index/tree/main/examples)                    |
| AutoGen Multi-Agent Example                  | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏£‡πâ‡∏≤‡∏á multi-agent ‡∏î‡πâ‡∏ß‡∏¢ AutoGen                                    | [AutoGen Examples](https://github.com/microsoft/autogen/tree/main/samples)                            |
| Hugging Face Spaces                          | ‡πÅ‡∏≠‡∏õ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô LLM ‡∏ö‡∏ô Hugging Face Spaces                              | [HF Spaces](https://huggingface.co/spaces)                                                            |
| TRL Examples (RLHF)                          | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ù‡∏∂‡∏Å LLM ‡∏î‡πâ‡∏ß‡∏¢ reinforcement learning                               | [TRL Examples](https://github.com/huggingface/trl/tree/main/examples)                                 |
| PEFT Examples                                | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Parameter-Efficient Fine-Tuning ‡πÄ‡∏ä‡πà‡∏ô LoRA                       | [PEFT Examples](https://github.com/huggingface/peft/tree/main/examples)                               |

### 7.6 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå (How to Proceed)

1. **‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏ö‡∏ô Colab:** ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢ Colab Notebooks ‡πÄ‡∏ä‡πà‡∏ô "Build Your Own GPT" ‡∏´‡∏£‡∏∑‡∏≠ "LLaMA Fine-Tuning" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏≠‡∏∞‡πÑ‡∏£ `[Beginner/Intermediate]`
2. **‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå:** ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏à‡∏≤‡∏Å GitHub ‡πÄ‡∏ä‡πà‡∏ô minGPT ‡∏´‡∏£‡∏∑‡∏≠ nanoGPT ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì `[Intermediate]`
3. **‡πÉ‡∏ä‡πâ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:** ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏ä‡πà‡∏ô Alpaca ‡∏´‡∏£‡∏∑‡∏≠ TinyStories ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å‡∏´‡∏£‡∏∑‡∏≠ fine-tune ‡πÇ‡∏°‡πÄ‡∏î‡∏• `[Intermediate/Advanced]`
4. **‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏£‡∏π‡∏õ:** ‡∏•‡∏≠‡∏á‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏ä‡πà‡∏ô Mistral 7B ‡∏´‡∏£‡∏∑‡∏≠ OpenThaiGPT ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á `[Intermediate]`
5. **‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå:** ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å LangChain ‡∏´‡∏£‡∏∑‡∏≠ AutoGen ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏´‡∏£‡∏∑‡∏≠ RAG `[Advanced]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡∏≠‡∏á Colab (‡πÄ‡∏ä‡πà‡∏ô GPU ‡∏ü‡∏£‡∏µ‡∏°‡∏µ‡∏à‡∏≥‡∏Å‡∏±‡∏î) ‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏ô‡πÑ‡∏ü‡∏•‡πå
- ‡∏ö‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
- ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏µ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ GPU ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á


## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=JonusNattapong/Notebook-Git-Colab&type=Date)](https://star-history.com/#JonusNattapong/Notebook-Git-Colab&Date)