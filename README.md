# Fine-Tuning Large Language Models (LLMs) Resources

This document provides a curated list of resources for fine-tuning Large Language Models (LLMs), including links to GitHub repositories, Hugging Face models, and articles. The resources are categorized for easier navigation.

## QLoRA Fine-Tuning

- **QLoRA Fine-Tuning Pipeline**: [GitHub](https://github.com/WeixuanJiang/Qlora-Fine-Tuning-Pipeline) - Scripts and configuration files for fine-tuning LLMs using QLoRA.
- **LLM Fine-Tuning for Programming Queries**: [GitHub](https://github.com/Avani1297/LLM-Fine-Tuning-Project-for-Programming-Queries) - Fine-tuning LLMs on Stack Overflow datasets.
- **Llama-2 Fine-Tuning with QLoRA**: [GitHub](https://github.com/mert-delibalta/llama2-fine-tune-qlora) - Fine-tuning Llama-2 using QLoRA.
- **Llama2 Fine-Tuning with QLoRA (torchtune)**: [PyTorch](https://pytorch.org/torchtune/stable/tutorials/qlora_finetune.html) - Fine-tuning Llama2 using QLoRA with torchtune.
- **Fine-Tuning LLMs using QLoRA**: [GitHub](https://github.com/georgesung/llm_qlora) - Fine-tuning LLMs using QLoRA.

## Other Fine-Tuning Resources

- **FLUX.1 Fine-Tuning**: [Hugging Face](https://huggingface.co/black-forest-labs/FLUX.1-dev/discussions/196) - Fine-tuning FLUX.1.
- **BERT Fine-Tuning with NVIDIA NGC**: [NVIDIA NGC](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/bert_workshop) - Fine-tuning BERT.
- **Fine-Tuning LLMs with Kiln AI**: [GitHub](https://github.com/Kiln-AI/kiln) - Fine-tuning with Kiln AI, including a UI.
- **Fine-Tuning LLMs with Hugging Face**: [GitHub](https://github.com/Acerkhan/generative-ai-with-MS) - Step-by-step tutorial for fine-tuning with Hugging Face Transformers.
- **Fine-Tuning LLMs with Node-RED Flow**: [GitHub](https://github.com/rozek/node-red-flow-gpt4all-unfiltered) - Fine-tuning GPT4All using Node-RED.
- **Fine-Tuning LLMs with OpenAI**: [GitHub](https://github.com/openai/openai-python/blob/main/examples/fine_tuning.py) - Fine-tuning using the OpenAI API.
- **Fine-Tuning LLMs with Azure OpenAI**: [GitHub](https://github.com/Azure/azure-ai-openai/blob/main/samples/fine_tuning.ipynb) - Fine-tuning using Azure OpenAI Service.
- **Fine-Tuning LLMs with AWS SageMaker**: [GitHub](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/transformers/transformers_fine_tuning.ipynb) - Fine-tuning using AWS SageMaker.
- **Fine-Tuning LLMs with Google AI**: [GitHub](https://github.com/googleapis/python-aiplatform/blob/main/samples/v1beta1/fine_tune_model_sample.py) - Fine-tuning using Google AI Platform.
- **Fine-Tuning LLMs with Microsoft DeepSpeed**: [GitHub](https://github.com/microsoft/DeepSpeed/blob/main/examples/fine_tune.py) - Fine-tuning using DeepSpeed.
- **Fine-Tuning LLMs with NVIDIA Triton**: [GitHub](https://github.com/NVIDIA/triton-inference-server/blob/main/docs/Training.md) - Fine-tuning using NVIDIA Triton.

## Additional Resources (Various Platforms)

The document also includes numerous links to resources for fine-tuning on platforms like Azure, AWS, Hugging Face, and using tools like FastAI, PyTorch Lightning, TensorFlow, Keras, ONNX Runtime, and OpenVINO. These resources cover a wide range of techniques and frameworks for fine-tuning AI models. There are also links to academic papers on arXiv related to advanced fine-tuning techniques and distributed training.

## Kimi Fine-Tuning Resources

#### **1. QLoRA Fine-Tuning Pipeline**
- **GitHub**: [WeixuanJiang/Qlora-Fine-Tuning-Pipeline](https://github.com/WeixuanJiang/Qlora-Fine-Tuning-Pipeline)  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน QLoRA (Quantized Low-Rank Adaptation) พร้อม Script และ Configuration Files สำหรับการ Fine-Tuning และ Inference.  
    - **Script ตัวอย่าง**:  
      - [Train Script](https://github.com/WeixuanJiang/Qlora-Fine-Tuning-Pipeline/blob/main/scripts/run_training.bat)  
      - [Merge Script](https://github.com/WeixuanJiang/Qlora-Fine-Tuning-Pipeline/blob/main/scripts/run_merge_multiple_loras.bat)  

#### **2. LLM Fine-Tuning for Programming Queries**
- **GitHub**: [Avani1297/LLM-Fine-Tuning-Project-for-Programming-Queries](https://github.com/Avani1297/LLM-Fine-Tuning-Project-for-Programming-Queries)  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs บน Stack Overflow datasets ผ่าน Hugging Face และ Vast.ai.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/Avani1297/LLM-Fine-Tuning-Project-for-Programming-Queries/blob/main/train.py)  

#### **3. FLUX.1 Fine-Tuning**
- **Hugging Face**: [black-forest-labs/FLUX.1-dev](https://huggingface.co/black-forest-labs/FLUX.1-dev/discussions/196)  
  - **รายละเอียด**: วิธีการ Fine-Tuning FLUX.1 ผ่าน AI Toolkit.  
    - **Script ตัวอย่าง**:  
      - [Train Script](https://github.com/ostris/ai-toolkit/blob/main/train_lora_flux_24gb.py)  

#### **4. Llama-2 Fine-Tuning with QLoRA**
- **GitHub**: [mert-delibalta/llama2-fine-tune-qlora](https://github.com/mert-delibalta/llama2-fine-tune-qlora)  
  - **รายละเอียด**: วิธีการ Fine-Tuning Llama-2 ผ่าน QLoRA พร้อม Script และ Configuration Files.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/mert-delibalta/llama2-fine-tune-qlora/blob/main/train.py)  

#### **5. BERT Fine-Tuning with NVIDIA NGC**
- **NVIDIA NGC**: [Fine-Tune and Optimize BERT](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/bert_workshop)  
  - **รายละเอียด**: วิธีการ Fine-Tuning BERT ผ่าน NVIDIA NGC.  
    - **Script ตัวอย่าง**:  
      - [Training Notebook](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/bert_workshop)  

#### **6. Llama2 Fine-Tuning with QLoRA (torchtune)**
- **PyTorch**: [Fine-Tuning Llama2 with QLoRA](https://pytorch.org/torchtune/stable/tutorials/qlora_finetune.html)  
  - **รายละเอียด**: วิธีการ Fine-Tuning Llama2 ผ่าน QLoRA พร้อม Script และ Configuration Files.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Command](https://pytorch.org/torchtune/stable/tutorials/qlora_finetune.html)

### 5-10 ลิ้งค์ Script สำหรับ Fine-Tuning Uncensored AI Models

#### **1. Fine-Tuning LLMs using QLoRA**
- **GitHub**: [georgesung/llm_qlora](https://github.com/georgesung/llm_qlora)  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน QLoRA พร้อม Script และ Configuration Files.  
    - **Script ตัวอย่าง**:  
      - [Train Script](https://github.com/georgesung/llm_qlora/blob/main/train.py)  
      - [Config File](https://github.com/georgesung/llm_qlora/blob/main/configs/llama3_8b_chat_uncensored.yaml) 

#### **2. Fine-Tuning LLMs with Kiln AI**
- **GitHub**: [Kiln-AI/kiln](https://github.com/Kiln-AI/kiln)  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน Kiln AI พร้อม UI สำหรับการ Fine-Tuning และ Synthetic Data Generation.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Guide](https://github.com/Kiln-AI/kiln/blob/main/guides/Fine%20Tuning%20LLM%20Models%20Guide.md) 

#### **3. Fine-Tuning LLMs with Hugging Face**
- **GitHub**: [Acerkhan/generative-ai-with-MS](https://github.com/Acerkhan/generative-ai-with-MS/blob/main/18-fine-tuning/README.md)  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน Hugging Face Transformers พร้อม Step-by-Step Tutorial.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/Acerkhan/generative-ai-with-MS/blob/main/18-fine-tuning/README.md) 

#### **4. Fine-Tuning LLMs with Node-RED Flow**
- **GitHub**: [rozek/node-red-flow-gpt4all-unfiltered](https://github.com/rozek/node-red-flow-gpt4all-unfiltered)  
  - **รายละเอียด**: วิธีการ Fine-Tuning GPT4All ผ่าน Node-RED Flow พร้อม Function Node สำหรับการ Inference.  
    - **Script ตัวอย่าง**:  
      - [Function Node](https://github.com/rozek/node-red-flow-gpt4all-unfiltered/blob/main/GPT4All-unfiltered-Function.json) 

#### **5. Fine-Tuning LLMs with OpenAI**
- **GitHub**: [OpenAI Fine-Tuning](https://github.com/openai/openai-python/blob/main/examples/fine_tuning.py)  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน OpenAI API พร้อม Script และ Example.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/openai/openai-python/blob/main/examples/fine_tuning.py) 

#### **6. Fine-Tuning LLMs with Azure OpenAI**
- **GitHub**: [Azure OpenAI Fine-Tuning](https://github.com/Azure/azure-ai-openai/blob/main/samples/fine_tuning.ipynb)  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน Azure OpenAI Service พร้อม Notebook และ Example.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Notebook](https://github.com/Azure/azure-ai-openai/blob/main/samples/fine_tuning.ipynb) 

#### **7. Fine-Tuning LLMs with AWS SageMaker**
- **GitHub**: [AWS SageMaker Fine-Tuning](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/transformers/transformers_fine_tuning.ipynb)  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน AWS SageMaker พร้อม Notebook และ Example.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Notebook](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/transformers/transformers_fine_tuning.ipynb) 

#### **8. Fine-Tuning LLMs with Google AI**
- **GitHub**: [Google AI Fine-Tuning](https://github.com/googleapis/python-aiplatform/blob/main/samples/v1beta1/fine_tune_model_sample.py)  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน Google AI Platform พร้อม Script และ Example.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/googleapis/python-aiplatform/blob/main/samples/v1beta1/fine_tune_model_sample.py) 

#### **9. Fine-Tuning LLMs with Microsoft DeepSpeed**
- **GitHub**: [Microsoft DeepSpeed](https://github.com/microsoft/DeepSpeed/blob/main/examples/fine_tune.py)  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน Microsoft DeepSpeed พร้อม Script และ Example.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Script](https://github.com/microsoft/DeepSpeed/blob/main/examples/fine_tune.py) 

#### **10. Fine-Tuning LLMs with NVIDIA Triton**
- **GitHub**: [NVIDIA Triton](https://github.com/NVIDIA/triton-inference-server/blob/main/docs/Training.md)  
  - **รายละเอียด**: วิธีการ Fine-Tuning LLMs ผ่าน NVIDIA Triton พร้อม Documentation และ Example.  
    - **Script ตัวอย่าง**:  
      - [Fine-Tuning Documentation](https://github.com/NVIDIA/triton-inference-server/blob/main/docs/Training.md)

## Kimi Chat Resources

*อัปเดตล่าสุด: 4 มีนาคม 2025*
*ที่มา: [Kimi Chat](https://kimi.moonshot.cn/)*

### 🔗 Kimi Chat Links

#### **1. Kimi Chat**
- **URL**: [https://kimi.moonshot.cn/](https://kimi.moonshot.cn/)
- **คำอธิบาย**: แชทบอท AI ที่สามารถสนทนาและตอบคำถามได้หลากหลาย
- **วิธีใช้**: เข้าสู่เว็บไซต์ Kimi Chat และเริ่มการสนทนา

#### **2. Kimi Chat API**
- **URL**: [https://kimi.moonshot.cn/api](https://kimi.moonshot.cn/api) (สมมติฐาน)
- **คำอธิบาย**: API สำหรับนักพัฒนาเพื่อเชื่อมต่อกับ Kimi Chat
- **วิธีใช้**: สมัครใช้งาน API, รับ API Key, และใช้ API Calls ในแอปพลิเคชัน

#### **3. Kimi Chat Documentation**
- **URL**: [https://kimi.moonshot.cn/docs](https://kimi.moonshot.cn/docs) (สมมติฐาน)
- **คำอธิบาย**: เอกสารสำหรับนักพัฒนาเกี่ยวกับ Kimi Chat API และการใช้งาน
- **วิธีใช้**: อ่านเอกสารเพื่อทำความเข้าใจ API และวิธีการใช้งาน

#### **4. Kimi Chat Examples**
- **URL**: [https://kimi.moonshot.cn/examples](https://kimi.moonshot.cn/examples) (สมมติฐาน)
- **คำอธิบาย**: ตัวอย่างการใช้งาน Kimi Chat API ในสถานการณ์ต่างๆ
- **วิธีใช้**: ดูตัวอย่างเพื่อเป็นแนวทางในการพัฒนาแอปพลิเคชัน

#### **5. Kimi Chat Pricing**
- **URL**: [https://kimi.moonshot.cn/pricing](https://kimi.moonshot.cn/pricing) (สมมติฐาน)
- **คำอธิบาย**: ข้อมูลราคาสำหรับการใช้งาน Kimi Chat API
- **วิธีใช้**: ตรวจสอบราคาและเลือกแพ็กเกจที่เหมาะสม

#### **6. Kimi Chat Support**
- **URL**: [https://kimi.moonshot.cn/support](https://kimi.moonshot.cn/support) (สมมติฐาน)
- **คำอธิบาย**: ช่องทางการติดต่อทีมสนับสนุนของ Kimi Chat
- **วิธีใช้**: ติดต่อทีมสนับสนุนเมื่อมีคำถามหรือปัญหา

#### **7. Kimi Chat Blog**
- **URL**: [https://kimi.moonshot.cn/blog](https://kimi.moonshot.cn/blog) (สมมติฐาน)
- **คำอธิบาย**: บล็อกเกี่ยวกับข่าวสารและการอัปเดตของ Kimi Chat
- **วิธีใช้**: อ่านบล็อกเพื่อติดตามข่าวสารและบทความที่น่าสนใจ

#### **8. Kimi Chat Community**
- **URL**: [https://kimi.moonshot.cn/community](https://kimi.moonshot.cn/community) (สมมติฐาน)
- **คำอธิบาย**: ชุมชนออนไลน์สำหรับผู้ใช้งาน Kimi Chat
- **วิธีใช้**: เข้าร่วมชุมชนเพื่อแลกเปลี่ยนความรู้และประสบการณ์

#### **9. Kimi Chat Status**
- **URL**: [https://status.kimi.moonshot.cn/](https://status.kimi.moonshot.cn/) (สมมติฐาน)
- **คำอธิบาย**: หน้าแสดงสถานะการทำงานของ Kimi Chat API
- **วิธีใช้**: ตรวจสอบสถานะ API เมื่อพบปัญหาการเชื่อมต่อ

#### **10. Kimi Chat Terms of Service**
- **URL**: [https://kimi.moonshot.cn/tos](https://kimi.moonshot.cn/tos) (สมมติฐาน)
- **คำอธิบาย**: ข้อกำหนดและเงื่อนไขการใช้งาน Kimi Chat
- **วิธีใช้**: อ่านข้อกำหนดและเงื่อนไขก่อนการใช้งาน

---

### 🚀 How to Get Started
1. **เข้าสู่เว็บไซต์**: ไปที่ [https://kimi.moonshot.cn/](https://kimi.moonshot.cn/)
2. **ลองใช้งาน**: เริ่มแชทกับ Kimi Chat ได้ทันที
3. **สำรวจ**: ดูตัวอย่าง, เอกสาร, และข้อมูลราคา (ถ้ามี)
4. **พัฒนา**: ใช้ API (ถ้ามี) เพื่อสร้างแอปพลิเคชันที่เชื่อมต่อกับ Kimi Chat

## AI2025 Resources

*อัปเดตล่าสุด: 4 มีนาคม 2025*
*ที่มา: [AI2025](https://www.ai2025.com/)* (สมมติฐาน)

### 🔗 AI2025 Links

#### **1. AI2025 Homepage**
- **URL**: [https://www.ai2025.com/](https://www.ai2025.com/) (สมมติฐาน)
- **คำอธิบาย**: หน้าหลักของ AI2025
- **วิธีใช้**: เข้าสู่เว็บไซต์เพื่อดูข้อมูลภาพรวม

#### **2. AI2025 API**
- **URL**: [https://api.ai2025.com/](https://api.ai2025.com/) (สมมติฐาน)
- **คำอธิบาย**: API สำหรับนักพัฒนาเพื่อเชื่อมต่อกับบริการของ AI2025
- **วิธีใช้**: สมัครใช้งาน API, รับ API Key, และใช้ API Calls

#### **3. AI2025 Documentation**
- **URL**: [https://docs.ai2025.com/](https://docs.ai2025.com/) (สมมติฐาน)
- **คำอธิบาย**: เอกสารสำหรับนักพัฒนาเกี่ยวกับ AI2025 API
- **วิธีใช้**: อ่านเอกสารเพื่อทำความเข้าใจ API และการใช้งาน

#### **4. AI2025 Examples**
- **URL**: [https://examples.ai2025.com/](https://examples.ai2025.com/) (สมมติฐาน)
- **คำอธิบาย**: ตัวอย่างการใช้งาน AI2025 API
- **วิธีใช้**: ดูตัวอย่างเพื่อเป็นแนวทางในการพัฒนา

#### **5. AI2025 Pricing**
- **URL**: [https://pricing.ai2025.com/](https://pricing.ai2025.com/) (สมมติฐาน)
- **คำอธิบาย**: ข้อมูลราคาสำหรับการใช้งาน AI2025 API
- **วิธีใช้**: ตรวจสอบราคาและเลือกแพ็กเกจที่เหมาะสม

#### **6. AI2025 Support**
- **URL**: [https://support.ai2025.com/](https://support.ai2025.com/) (สมมติฐาน)
- **คำอธิบาย**: ช่องทางการติดต่อทีมสนับสนุนของ AI2025
- **วิธีใช้**: ติดต่อทีมสนับสนุนเมื่อมีคำถามหรือปัญหา

#### **7. AI2025 Blog**
- **URL**: [https://blog.ai2025.com/](https://blog.ai2025.com/) (สมมติฐาน)
- **คำอธิบาย**: บล็อกเกี่ยวกับข่าวสารและการอัปเดตของ AI2025
- **วิธีใช้**: อ่านบล็อกเพื่อติดตามข่าวสารและบทความ

#### **8. AI2025 Community**
- **URL**: [https://community.ai2025.com/](https://community.ai2025.com/) (สมมติฐาน)
- **คำอธิบาย**: ชุมชนออนไลน์สำหรับผู้ใช้งาน AI2025
- **วิธีใช้**: เข้าร่วมชุมชนเพื่อแลกเปลี่ยนความรู้

#### **9. AI2025 Status**
- **URL**: [https://status.ai2025.com/](https://status.ai2025.com/) (สมมติฐาน)
- **คำอธิบาย**: หน้าแสดงสถานะการทำงานของ AI2025 API
- **วิธีใช้**: ตรวจสอบสถานะ API เมื่อพบปัญหา

#### **10. AI2025 Terms of Service**
- **URL**: [https://tos.ai2025.com/](https://tos.ai2025.com/) (สมมติฐาน)
- **คำอธิบาย**: ข้อกำหนดและเงื่อนไขการใช้งาน AI2025
- **วิธีใช้**: อ่านข้อกำหนดและเงื่อนไขก่อนการใช้งาน

---
### 🚀 How to Get Started

1.  **เยี่ยมชมเว็บไซต์**: เข้าไปที่ [https://www.ai2025.com/](https://www.ai2025.com/) (สมมติฐาน)
2.  **สำรวจ**: ดูข้อมูลต่างๆ เกี่ยวกับ AI2025
3.  **ลองใช้**: หากมี API หรือ Demo ให้ทดลองใช้งาน
4.  **พัฒนา**: ใช้ API (ถ้ามี) เพื่อสร้างแอปพลิเคชัน

## DeepSeek AI GitHub Repositories

*อัปเดตล่าสุด: 4 มีนาคม 2025*  
*ที่มา: [DeepSeek AI GitHub Repositories](https://github.com/orgs/deepseek-ai/repositories)*

### 📂 DeepSeek AI Repositories

#### 1. DeepEP  
- **URL**: [https://github.com/deepseek-ai/DeepEP](https://github.com/deepseek-ai/DeepEP)  
- **คำอธิบาย**: ไลบรารีการสื่อสารแบบ Expert-Parallel ที่มีประสิทธิภาพสูง ช่วยจัดการการสื่อสารระหว่างโมเดลในระบบฝึก AI ขนาดใหญ่  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: ใช้กลไก Expert-Parallel เพื่อแบ่งงานฝึกโมเดลให้กระจายไปยัง GPU หลายตัว ลดการติดขัดในการสื่อสารระหว่างอุปกรณ์  
  - **วิธีใช้**: ดาวน์โหลดโค้ด, ติดตั้ง Dependencies (เช่น PyTorch), รวมเข้ากับ Pipeline การฝึกโมเดล โดยกำหนด Expert Modules ใน Config  

#### 2. 3FS  
- **URL**: [https://github.com/deepseek-ai/3FS](https://github.com/deepseek-ai/3FS)  
- **คำอธิบาย**: ระบบไฟล์กระจายประสิทธิภาพสูง ออกแบบมาเพื่อรองรับการฝึกและ Inference AI โดยเฉพาะ  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: จัดเก็บและเข้าถึงข้อมูลแบบกระจาย (Distributed File System) เพื่อลด Latency ในงาน AI ขนาดใหญ่  
  - **วิธีใช้**: ติดตั้งผ่าน Docker หรือ Source Code, กำหนด Cluster Configuration, ใช้คู่กับ Framework เช่น TensorFlow หรือ PyTorch  

#### 3. DeepGEMM  
- **URL**: [https://github.com/deepseek-ai/DeepGEMM](https://github.com/deepseek-ai/DeepGEMM)  
- **คำอธิบาย**: Kernel GEMM แบบ FP8 ที่สะอาดและมีประสิทธิภาพ รองรับการปรับขนาดแบบละเอียด (Fine-grained Scaling)  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: ปรับปรุงการคำนวณ Matrix Multiplication ด้วย FP8 Precision เพื่อประหยัดหน่วยความจำและเพิ่มความเร็ว  
  - **วิธีใช้**: รวม Kernel เข้ากับโมเดล Deep Learning, คอมไพล์ด้วย CUDA, เรียกใช้ใน Layer ที่ต้องการ GEMM  

#### 4. open-infra-index  
- **URL**: [https://github.com/deepseek-ai/open-infra-index](https://github.com/deepseek-ai/open-infra-index)  
- **คำอธิบาย**: เครื่องมือโครงสร้างพื้นฐาน AI ที่ผ่านการทดสอบใน Production เพื่อพัฒนา AGI และนวัตกรรมชุมชน  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: รวบรวมเครื่องมือ Open-source ที่ผ่านการทดสอบจริงสำหรับงาน AGI  
  - **วิธีใช้**: เลือกเครื่องมือจาก Index, ดาวน์โหลดตามลิงก์ใน README, ปรับใช้ใน Workflow ของคุณ  

#### 5. profile-data  
- **URL**: [https://github.com/deepseek-ai/profile-data](https://github.com/deepseek-ai/profile-data)  
- **คำอธิบาย**: วิเคราะห์การทับซ้อนระหว่างการคำนวณและการสื่อสารใน DeepSeek-V3/R1  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: สร้างโปรไฟล์การทำงานของ V3/R1 เพื่อหาจุดที่สามารถปรับปรุงประสิทธิภาพ  
  - **วิธีใช้**: รัน Script วิเคราะห์กับ Log การฝึก, ใช้ผลลัพธ์ปรับ Hyperparameters หรือ Pipeline  

#### 6. awesome-deepseek-integration  
- **URL**: [https://github.com/deepseek-ai/awesome-deepseek-integration](https://github.com/deepseek-ai/awesome-deepseek-integration)  
- **คำอธิบาย**: รวมวิธีผสาน DeepSeek API เข้ากับซอฟต์แวร์ยอดนิยม เช่น IDEs และแพลตฟอร์มอื่น ๆ  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: จัดเตรียมโค้ดตัวอย่างสำหรับเชื่อมต่อ DeepSeek API กับแอปพลิเคชัน  
  - **วิธีใช้**: เลือกซอฟต์แวร์เป้าหมาย (เช่น VS Code), คัดลอกโค้ดจากตัวอย่าง, ปรับแต่งด้วย API Key  

#### 7. smallpond  
- **URL**: [https://github.com/deepseek-ai/smallpond](https://github.com/deepseek-ai/smallpond)  
- **คำอธิบาย**: เฟรมเวิร์กประมวลผลข้อมูลน้ำหนักเบา สร้างบน DuckDB และ 3FS  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: ใช้ DuckDB สำหรับ Query และ 3FS สำหรับจัดเก็บข้อมูลแบบกระจาย  
  - **วิธีใช้**: ติดตั้ง DuckDB และ 3FS, รัน Script ตัวอย่างใน README, ป้อนข้อมูลเพื่อประมวลผล  

#### 8. FlashMLA  
- **URL**: [https://github.com/deepseek-ai/FlashMLA](https://github.com/deepseek-ai/FlashMLA)  
- **คำอธิบาย**: Kernel ถอดรหัส MLA (Multi-head Latent Attention) ที่มีประสิทธิภาพสูง  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: ลดความซับซ้อนของ Attention Mechanism ด้วย Kernel ที่เร็วขึ้น  
  - **วิธีใช้**: คอมไพล์ Kernel ด้วย CUDA, รวมเข้ากับโมเดล Transformer, ทดสอบ Inference  

#### 9. DualPipe  
- **URL**: [https://github.com/deepseek-ai/DualPipe](https://github.com/deepseek-ai/DualPipe)  
- **คำอธิบาย**: อัลกอริทึม Pipeline Parallelism แบบสองทิศทาง เพื่อการทับซ้อนการคำนวณ-สื่อสารใน V3/R1  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: ฝึกโมเดลแบบ Pipeline โดยให้ Forward และ Backward Pass ทับซ้อนกัน  
  - **วิธีใช้**: ปรับ Config การฝึกใน V3/R1, รวมโค้ด DualPipe, รันบน Multi-GPU  

#### 10. EPLB  
- **URL**: [https://github.com/deepseek-ai/EPLB](https://github.com/deepseek-ai/EPLB)  
- **คำอธิบาย**: Expert Parallelism Load Balancer สำหรับกระจายงานในระบบฝึกโมเดล  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: ปรับสมดุลโหลดงานระหว่าง Experts เพื่อลดการรอคอย  
  - **วิธีใช้**: รวม EPLB เข้ากับ Framework การฝึก, กำหนดจำนวน Experts ใน Config  

#### 11. DeepSeek-VL2  
- **URL**: [https://github.com/deepseek-ai/DeepSeek-VL2](https://github.com/deepseek-ai/DeepSeek-VL2)  
- **คำอธิบาย**: โมเดล Mixture-of-Experts Vision-Language สำหรับการเข้าใจหลายรูปแบบขั้นสูง  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: รวม Vision และ Language Processing ด้วย MoE Architecture  
  - **วิธีใช้**: ดาวน์โหลดโมเดล, รัน Inference ด้วยภาพและข้อความตามตัวอย่างใน README  

#### 12. DeepSeek-V3  
- **URL**: [https://github.com/deepseek-ai/DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3)  
- **คำอธิบาย**: โมเดล Mixture-of-Experts ขนาด 671B Parameters (37B ใช้งานต่อ Token) ที่มีประสิทธิภาพสูง  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: ใช้ MoE เพื่อเลือก Experts ที่เหมาะสมต่อการตอบคำถาม  
  - **วิธีใช้**: ดาวน์โหลด Weights, รัน Inference หรือ Fine-Tune ด้วย Script ที่ให้มา  

#### 13. DeepSeek-R1  
- **URL**: [https://github.com/deepseek-ai/DeepSeek-R1](https://github.com/deepseek-ai/DeepSeek-R1)  
- **คำอธิบาย**: โมเดล Reasoning รุ่นแรกที่ฝึกด้วย Reinforcement Learning มีความสามารถเทียบเท่า OpenAI-o1  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: ฝึกด้วย RL เพื่อแก้ปัญหาเชิง Reasoning เช่น คณิตศาสตร์และโค้ด  
  - **วิธีใช้**: รันโมเดลด้วย Prompt ที่ซับซ้อน, ใช้ API หรือ Local Inference  

#### 14. Janus  
- **URL**: [https://github.com/deepseek-ai/Janus](https://github.com/deepseek-ai/Janus)  
- **คำอธิบาย**: โมเดล Multimodal รุ่น Janus-Series สำหรับการเข้าใจและสร้างข้อมูลหลายรูปแบบ  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: รวม Text, Image และข้อมูลอื่น ๆ ในโมเดลเดียว  
  - **วิธีใช้**: ดาวน์โหลด Janus-Series, ทดสอบด้วย Input หลายรูปแบบตามตัวอย่าง  

#### 15. DeepSeek-V2  
- **URL**: [https://github.com/deepseek-ai/DeepSeek-V2](https://github.com/deepseek-ai/DeepSeek-V2)  
- **คำอธิบาย**: โมเดล Mixture-of-Experts ที่แข็งแกร่ง, ประหยัด, และมีประสิทธิภาพ (236B Parameters)  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: ลดต้นทุนการคำนวณด้วย MoE ในงานภาษาทั่วไป  
  - **วิธีใช้**: ใช้ Weights ที่ให้มา, รัน Inference หรือ Fine-Tune บน Dataset เฉพาะ  

#### 16. DeepSeek-Coder-V2  
- **URL**: [https://github.com/deepseek-ai/DeepSeek-Coder-V2](https://github.com/deepseek-ai/DeepSeek-Coder-V2)  
- **คำอธิบาย**: โมเดลรหัสที่ทลายกำแพง Closed-source ในด้าน Code Intelligence  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: ฝึกเพื่อเข้าใจและสร้างโค้ดในหลายภาษาโปรแกรม  
  - **วิธีใช้**: รันโมเดลด้วย Prompt โค้ด, ใช้ใน IDE หรือผ่าน API  

#### 17. ESFT  
- **URL**: [https://github.com/deepseek-ai/ESFT](https://github.com/deepseek-ai/ESFT)  
- **คำอธิบาย**: Expert Specialized Fine-Tuning เทคนิคการปรับแต่งโมเดลสำหรับผู้เชี่ยวชาญ  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: ปรับแต่ง Experts ใน MoE ให้เชี่ยวชาญงานเฉพาะ  
  - **วิธีใช้**: รัน Script Fine-Tuning ด้วย Dataset เป้าหมายตาม README  

#### 18. DreamCraft3D  
- **URL**: [https://github.com/deepseek-ai/DreamCraft3D](https://github.com/deepseek-ai/DreamCraft3D)  
- **คำอธิบาย**: การใช้งาน DreamCraft3D (ICLR 2024) สำหรับสร้าง 3D แบบลำดับขั้นด้วย Diffusion Prior  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: ใช้ Diffusion Model สร้างโมเดล 3D จาก Text หรือ Image  
  - **วิธีใช้**: ติดตั้ง Dependencies, รันโค้ดด้วย Input เช่น Text Prompt  

#### 19. DeepSeek-Prover-V1.5  
- **URL**: [https://github.com/deepseek-ai/DeepSeek-Prover-V1.5](https://github.com/deepseek-ai/DeepSeek-Prover-V1.5)  
- **คำอธิบาย**: โมเดลสำหรับพิสูจน์คณิตศาสตร์  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: ฝึกเพื่อพิสูจน์ทฤษฎีคณิตศาสตร์และ Reasoning  
  - **วิธีใช้**: รันโมเดลด้วยโจทย์คณิตศาสตร์, ตรวจสอบ Output ตามตัวอย่าง  

#### 20. DeepSeek-Coder  
- **URL**: [https://github.com/deepseek-ai/DeepSeek-Coder](https://github.com/deepseek-ai/DeepSeek-Coder)  
- **คำอธิบาย**: DeepSeek Coder: "Let the Code Write Itself" โมเดลเขียนโค้ดอัตโนมัติ  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: สร้างโค้ดจาก Prompt หรือคอมเมนต์ในหลายภาษา  
  - **วิธีใช้**: ใช้ API หรือ Local Weights, ป้อน Prompt เพื่อสร้างโค้ด  

#### 21. DeepSeek-VL  
- **URL**: [https://github.com/deepseek-ai/DeepSeek-VL](https://github.com/deepseek-ai/DeepSeek-VL)  
- **คำอธิบาย**: DeepSeek-VL: โมเดล Vision-Language สำหรับการเข้าใจโลกจริง  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: ประมวลผลภาพและข้อความพร้อมกันเพื่อตอบคำถาม  
  - **วิธีใช้**: รัน Inference ด้วยภาพและคำถามตาม Script ตัวอย่าง  

#### 22. DeepSeek-Math  
- **URL**: [https://github.com/deepseek-ai/DeepSeek-Math](https://github.com/deepseek-ai/DeepSeek-Math)  
- **คำอธิบาย**: DeepSeekMath: โมเดลที่ขยายขีดจำกัดการแก้ปัญหาคณิตศาสตร์ใน LLMs  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: ฝึกเพื่อแก้โจทย์คณิตศาสตร์และแสดงขั้นตอนการคิด  
  - **วิธีใช้**: รันโมเดลด้วยโจทย์คณิตศาสตร์, ปรับแต่ง Output Format  

#### 23. awesome-deepseek-coder  
- **URL**: [https://github.com/deepseek-ai/awesome-deepseek-coder](https://github.com/deepseek-ai/awesome-deepseek-coder)  
- **คำอธิบาย**: รายการโปรเจกต์ Open-source ที่เกี่ยวข้องกับ DeepSeek Coder  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: รวบรวมทรัพยากรและตัวอย่างการใช้ DeepSeek Coder  
  - **วิธีใช้**: เลือกโปรเจกต์จาก List, ดาวน์โหลดโค้ด, ทดลองใช้งาน  

#### 24. DeepSeek-LLM  
- **URL**: [https://github.com/deepseek-ai/DeepSeek-LLM](https://github.com/deepseek-ai/DeepSeek-LLM)  
- **คำอธิบาย**: DeepSeek LLM: "Let there be answers" โมเดลภาษาสำหรับงานทั่วไป  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: โมเดลพื้นฐานสำหรับงาน Text Generation และ Q&A  
  - **วิธีใช้**: รัน Inference ด้วย Prompt หรือ Fine-Tune ตามความต้องการ  

#### 25. DeepSeek-MoE  
- **URL**: [https://github.com/deepseek-ai/DeepSeek-MoE](https://github.com/deepseek-ai/DeepSeek-MoE)  
- **คำอธิบาย**: DeepSeekMoE: โมเดล Mixture-of-Experts ที่มุ่งสู่ความเชี่ยวชาญสูงสุด  
- **หลักการทำงานและวิธีใช้**:  
  - **หลักการ**: ใช้ MoE เพื่อแบ่งงานให้ Experts เฉพาะด้าน  
  - **วิธีใช้**: ดาวน์โหลด Weights, รัน Inference หรือฝึกต่อด้วย Script  

---

### 🚀 How to Proceed
1. **เลือกคลัง**: เริ่มจากคลังที่ตรงกับงานของคุณ (เช่น DeepSeek-Coder สำหรับโค้ด, DeepSeek-V3 สำหรับ LLM)  
2. **ดาวน์โหลด**: ใช้ `git clone <URL>` หรือดาวน์โหลด ZIP จาก GitHub  
3. **ติดตั้ง**: รัน `pip install -r requirements.txt` หรือตามคำแนะนำใน README  
4. **ทดลอง**: ใช้ Script หรือ API ตามตัวอย่าง, ปรับแต่งตามความต้องการ  
5. **Hardware**: เตรียม GPU (แนะนำ 16GB+ VRAM) หรือใช้ Cloud เช่น Colab Pro
