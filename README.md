<div align="center">

![Project Logo](./public/Zom.png)

# üìö AI LLM Learning Resources

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/Apache-2.0-green.svg)](LICENSE)
[![GitHub Stars](https://img.shields.io/github/stars/JonusNattapong/Notebook-Git-Colab.svg?style=social)](https://github.com/JonusNattapong/Notebook-Git-Colab/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/JonusNattapong/Notebook-Git-Colab.svg?style=social)](https://github.com/JonusNattapong/Notebook-Git-Colab/network/members)
[![GitHub Followers](https://img.shields.io/github/followers/JonusNattapong.svg?style=social)](https://github.com/JonusNattapong/followers)

</div>

# Notebook Git Colab ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏°‡∏∑‡πà‡∏≠ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 7/3/2025

<div align="center">

## üìë ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç

| ‡∏•‡∏≥‡∏î‡∏±‡∏ö | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠                                                                                                 |
| :---- | :----------------------------------------------------------------------------------------------------- |
| 1     | [üìò ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô](#section1)                                                                         |
| 2     | [üõ†Ô∏è ‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£ LLM](#section3)                                                                             |
| 3     | [üìö ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏•‡∏∞ Repository ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á](#section4)                                                              |
| 4     | [üåê ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ LLM ‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï](#section5)                                                |
| 5     | [üìñ ‡∏®‡∏±‡∏û‡∏ó‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ LLM](#section6)                                                                 |
| 6     | [üìÇ ‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö LLM](#section7)                                                  |
| 7     | [üöÄ ‡∏Å‡∏≤‡∏£ Deploy LLM ‡πÉ‡∏ô Production](#section8)                                                            |
| 8     | [üìÑ ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö LLM](#section9)                                                                   |
| 9     | [üîß ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á](#section10)                                                            |
| 10    | [üéØ ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ Model ‡πÅ‡∏•‡∏∞ Dataset](#section11)                                                           |
| 11    | [‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏∞‡∏ö‡∏ö](#section12)                                                              |
| 12    | [üíª ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ LLM](#section13)                                                               |
| 13    | [üåü ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏´‡∏°‡πà ‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà](#section14)                                              |

</div>

---

<a name="section1"></a>
## üìò ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
- [1.1 ‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Machine Learning](#math-ml)
- [1.2 ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Python](#python-prog)
- [1.3 ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏°](#neural-networks)
- [1.4 ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥](#nlp)
- [1.5 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ](#learning-path-1)

<a name="section3"></a>
## üõ†Ô∏è ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£ LLM
- [3.1 ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢ LLMs](#llm-apps)
- [3.2 ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏≠‡∏á LLM](#llm-optimization)
- [3.3 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á LLM](#llm-security)
- [3.4 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ](#learning-path-3)

<a name="section4"></a>
## üìö ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏•‡∏∞ Repository ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á
- [4.1 DeepSeek AI Repositories](#deepseek)
- [4.2 Uncensored AI Models](#uncensored-models)
- [4.3 Fine-Tuning Tables](#fine-tuning)
- [4.4 Awesome Colab Notebooks](#colab-notebooks)
- [4.5 Research Papers](#research-papers)
- [4.6 Additional Learning Resources](#additional-resources)

<a name="section5"></a>
## üåê ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ LLM ‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡∏à‡∏£‡∏¥‡∏á
- [5.1 ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ LLM](#llm-projects)
- [5.2 ‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á LLM](#llm-evaluation)
- [5.3 ‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÅ‡∏•‡∏∞‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°‡πÉ‡∏´‡∏°‡πà](#emerging-trends)
- [5.4 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ](#learning-path-5)

<a name="section6"></a>
## üìñ ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 6: ‡∏®‡∏±‡∏û‡∏ó‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ LLM
- [6.1 ‡∏®‡∏±‡∏û‡∏ó‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô](#basic-terms)
- [6.2 ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£](#technical-terms)
- [6.3 ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û](#performance-terms)
- [6.4 ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢](#security-terms)
- [6.5 ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏•](#evaluation-terms)
- [6.6 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏®‡∏±‡∏û‡∏ó‡πå](#learning-terms)

<a name="section7"></a>
## üìÇ ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 7: ‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
- [7.1 Colab Notebooks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM](#colab-examples)
- [7.2 ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏à‡∏≤‡∏Å GitHub](#github-scripts)
- [7.3 ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á](#datasets)
- [7.4 ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ](#pretrained-models)
- [7.5 ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠](#tools-links)
- [7.6 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô](#usage-guidelines)
- [7.3 ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á](#datasets)
- [7.4 ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ](#pretrained-models)
- [7.5 ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠](#tools-links)
- [7.6 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô](#usage-guidelines)

<a name="section8"></a>
## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 8: ‡∏Å‡∏≤‡∏£ Deploy LLM ‡πÉ‡∏ô Production üöÄ
- [8.1 ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Deployment](#deployment-tools)
- [8.2 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£ Deploy](#deployment-steps)
- [8.3 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Deployment](#deployment-examples)
- [8.4 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ](#learning-path-8)

<a name="section9"></a>
## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 9: ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö LLM üìÑ
- [9.1 ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô](#foundational-papers)
- [9.2 ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á](#training-papers)
- [9.3 ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•](#evaluation-papers)
- [9.4 ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢](#security-papers)
- [9.5 ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î](#recent-papers)
- [9.6 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤](#research-path)

<a name="section10"></a>
## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 10: ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á üîß
- [10.1 ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô](#core-principles)
- [10.2 ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£](#methodologies)
- [10.3 ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏û‡∏¥‡πÄ‡∏®‡∏©](#special-techniques)
- [10.4 ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠](#tools)
- [10.5 Framework](#frameworks)
- [10.6 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô](#framework-usage)

<a name="section11"></a>
## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 11: ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ Model ‡πÅ‡∏•‡∏∞ Dataset üéØ
- [11.1 ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ Model AI](#model-selection)
- [11.2 ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ Dataset](#dataset-selection)
- [11.3 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ](#other-concepts)
- [11.4 ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•](#resources)
- [11.5 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô](#selection-guidelines)

<a name="section12"></a>
## ‚öôÔ∏è ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 12: ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏∞‡∏ö‡∏ö
- [12.1 ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies](#dependencies)
  - Python ‡πÅ‡∏•‡∏∞ Package Manager
  - CUDA ‡πÅ‡∏•‡∏∞ GPU Drivers
  - Framework ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
- [12.2 ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Environment](#environment-setup)
  - Virtual Environment
  - Docker Container
  - Cloud Environment
- [12.3 ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥](#memory-management)
  - RAM Optimization
  - GPU Memory Management
  - Disk Space Requirements
- [12.4 ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö](#system-config)
  - Operating System
  - Network Configuration
  - Security Settings
- [12.5 Troubleshooting Guide](#troubleshooting)
  - Common Issues
  - Solutions
  - Support Resources

<a name="section13"></a>
## üíª ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 13: ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ LLM
- [13.1 Command Line Interface](#cli-usage)
  - Basic Commands
  - Advanced Operations
  - Automation Scripts
- [13.2 API Integration](#api-integration)
  - REST API
  - WebSocket
  - GraphQL
- [13.3 Monitoring & Logging](#monitoring)
  - Performance Metrics
  - Error Tracking
  - Usage Statistics
- [13.4 Resource Management](#resource-management)
  - Load Balancing
  - Scaling
  - Backup & Recovery
- [13.5 Best Practices](#best-practices)
  - Code Style
  - Documentation
  - Testing Strategy

<a name="section14"></a>
## üåü ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 14: ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏´‡∏°‡πà ‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà
- [14.1 ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç](#resources-code)
- [14.2 ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏´‡∏°‡πà](#new-techniques)
- [14.3 ‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà](#new-trends)
- [14.4 ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°](#additional-resources)
- [14.5 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô](#usage-guidelines)

# Notebook-Git-Colab ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏°‡∏∑‡πà‡∏≠ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 7/3/2025

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏Ñ‡∏£‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡∏ï‡πâ‡∏≠‡∏á Old version ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏î‡∏π‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà READMEOLD ‡∏ó‡∏µ‡πà‡πÇ‡∏ü‡∏£‡πå‡πÄ‡∏î‡∏≠‡∏£‡πå ReadmeCrack



*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏±‡πà‡∏ô‡∏Ñ‡∏á‡πÉ‡∏ô‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå, Python, ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏° ‡πÅ‡∏•‡∏∞ NLP ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á*

### 1.1 ‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Machine Learning

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                    | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                   | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                    | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)     | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                              |
| :------------------------------------------- | :------------------------------------------------------------------------------------------------------------ | :----------------------------------------------------------------------------------------- | :---------------- | :-------------------------------------------------------------------------------------------------------------------------------- |
| 3Blue1Brown - Linear Algebra                 | ‡∏ä‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏™‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏û‡∏µ‡∏ä‡∏Ñ‡∏ì‡∏¥‡∏ï‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏´‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ã‡∏õ‡∏ï‡πå‡∏¢‡∏≤‡∏Å‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏°‡∏ó‡∏£‡∏¥‡∏Å‡∏ã‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô PCA | ‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå, ‡πÄ‡∏°‡∏ó‡∏£‡∏¥‡∏Å‡∏ã‡πå, ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á (transformations), ‡∏Ñ‡πà‡∏≤‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á (eigenvalues - ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô PCA), ‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á (eigenvectors - ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô SVD) | `[Beginner]`      | [YouTube Playlist](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)                                     |
| Khan Academy - Probability and Statistics    | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡∏ü‡∏£‡∏µ ‡∏™‡∏≠‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ML ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô, ‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á (distributions), ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö‡πÄ‡∏ö‡∏¢‡πå (Bayesian inference)      | `[Beginner/Intermediate]` | [Khan Academy Course](https://www.khanacademy.org/math/statistics-probability)                                                     |
| Mathematics for Machine Learning (MML)       | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ü‡∏£‡∏µ‡∏à‡∏≤‡∏Å Cambridge ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô ML ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö gradient descent | ‡∏û‡∏µ‡∏ä‡∏Ñ‡∏ì‡∏¥‡∏ï‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô, ‡πÅ‡∏Ñ‡∏•‡∏Ñ‡∏π‡∏•‡∏±‡∏™, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô, ‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (optimization)                        | `[Intermediate/Advanced]` | [MML Book](https://mml-book.github.io/)                                                                                       |
| All of Statistics (Wasserman)                | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏ô‡∏∏‡∏Å‡∏£‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô ML ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ñ‡∏î‡∏ñ‡∏≠‡∏¢‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á | ‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏≤‡∏ô‡∏ó‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ (statistical inference), ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡∏ñ‡∏î‡∏ñ‡∏≠‡∏¢ (regression), ‡∏≠‡∏ô‡∏∏‡∏Å‡∏£‡∏°‡πÄ‡∏ß‡∏•‡∏≤ (time series) | `[Advanced]`      | [All of Statistics Book](https://www.stat.cmu.edu/~larry/all-of-statistics/) ‡∏´‡∏£‡∏∑‡∏≠ [Springer Link](https://link.springer.com/book/10.1007/978-0-387-21736-9) |

### 1.2 ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Python

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                  | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                          | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                       | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)        | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                |
| :------------------------------------------- | :-------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------- | :------------------- | :-------------------------------------------------------------------------------------------------- |
| Python Official Documentation              | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á Python ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢‡πÉ‡∏ô ML ‡πÄ‡∏ä‡πà‡∏ô `random` ‡∏´‡∏£‡∏∑‡∏≠ `math` | ‡πÑ‡∏ß‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå (syntax), ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡πÇ‡∏°‡∏î‡∏π‡∏• (modules), ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô (standard library)               | `[All Levels]`   | [Python Docs](https://docs.python.org/3/)                                                               |
| Google's Python Class                      | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏ü‡∏£‡∏µ‡∏à‡∏≤‡∏Å Google ‡∏™‡∏≠‡∏ô Python ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏ù‡∏∂‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå | ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô, ‡∏™‡∏ï‡∏£‡∏¥‡∏á (strings), ‡∏•‡∏¥‡∏™‡∏ï‡πå (lists), ‡∏î‡∏¥‡∏Å‡∏ä‡∏±‡∏ô‡∏ô‡∏≤‡∏£‡∏µ (dictionaries), ‡πÑ‡∏ü‡∏•‡πå, regular expressions      | `[Beginner]`       | [Google's Python Class](https://developers.google.com/edu/python/)                                      |
| Corey Schafer - Python Tutorials           | ‡∏ä‡πà‡∏≠‡∏á YouTube ‡∏™‡∏≠‡∏ô Python ‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ OOP ‡πÅ‡∏•‡∏∞‡∏á‡∏≤‡∏ô data science ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ pandas | ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏ä‡∏¥‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ (OOP), ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏ß‡πá‡∏ö, ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (data science)            | `[Beginner/Intermediate]` | [Corey Schafer YouTube](https://www.youtube.com/c/Coreymschafer)                                        |
| Sentdex - Python Programming Tutorials     | ‡∏ä‡πà‡∏≠‡∏á YouTube ‡∏™‡∏≠‡∏ô Python ‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ML ‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ NumPy          | Machine Learning, ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏ß‡πá‡∏ö, ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏Å‡∏°                                 | `[Intermediate]`    | [Sentdex YouTube](https://www.youtube.com/c/sentdex)                                                 |
| Python for Data Analysis (Wes McKinney)    | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏™‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Python (‡πÄ‡∏ô‡πâ‡∏ô pandas) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô ML ‡πÅ‡∏•‡∏∞ data science   | pandas, NumPy, ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (data visualization)     | `[Intermediate/Advanced]` | [Python for Data Analysis](https://wesmckinney.com/book/)                                               |
| Automate the Boring Stuff with Python      | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏ü‡∏£‡∏µ ‡∏™‡∏≠‡∏ô Python ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏á‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô   | ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå, ‡∏Å‡∏≤‡∏£ scraping ‡πÄ‡∏ß‡πá‡∏ö, ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö Excel                                 | `[Beginner]`        | [Automate the Boring Stuff](https://automatetheboringstuff.com/)                                       |

### 1.3 ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏° (Neural Networks)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                    | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                                   | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                   |
| :------------------------------------------- | :--------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------- | :--------------------- | :--------------------------------------------------------------------------------------------------------------------- |
| DeepLearning.AI - Deep Learning Specialization | ‡∏ä‡∏∏‡∏î‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡∏ö‡∏ô Coursera ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô Deep Learning ‡πÄ‡∏ä‡πà‡∏ô backpropagation ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏°     | ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏°, backpropagation, convolutional neural networks (CNNs), recurrent neural networks (RNNs) | `[Beginner/Intermediate]` | [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning)                                  |
| 3Blue1Brown - Neural Networks                | ‡∏ä‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏° ‡πÄ‡∏ä‡πà‡∏ô gradient descent ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏≠‡∏£‡πå‡πÄ‡∏ã‡∏õ‡∏ï‡∏£‡∏≠‡∏ô       | ‡πÄ‡∏û‡∏≠‡∏£‡πå‡πÄ‡∏ã‡∏õ‡∏ï‡∏£‡∏≠‡∏ô (perceptrons), ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô (activation functions), backpropagation, gradient descent   | `[Beginner]`          | [Neural Networks Playlist](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)                  |
| fast.ai - Practical Deep Learning for Coders | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡πÄ‡∏ô‡πâ‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ ‡∏™‡∏≠‡∏ô Deep Learning ‡∏î‡πâ‡∏ß‡∏¢ fastai (‡∏ö‡∏ô PyTorch) ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏£‡∏¥‡∏á          | ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ Deep Learning, PyTorch, ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ fastai                                                  | `[Intermediate]`       | [fast.ai Course](https://course.fast.ai/)                                                                            |
| Stanford CS231n - Convolutional Neural Networks | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏à‡∏≤‡∏Å Stanford ‡πÄ‡∏ô‡πâ‡∏ô CNNs ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô Computer Vision ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° CNN ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î   | Convolutional layers, pooling layers, ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° CNN ‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°                                       | `[Intermediate/Advanced]` | [CS231n Course](http://cs231n.stanford.edu/)                                                                         |
| Transformers Explained (Hugging Face)        | ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡∏à‡∏≤‡∏Å Hugging Face ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô Transformers ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLM ‡πÄ‡∏ä‡πà‡∏ô attention mechanism     | Attention mechanism, self-attention, Transformer architecture                                  | `[Beginner/Intermediate]` | [Transformers Explained](https://huggingface.co/docs/transformers/quicktour)                                         |

### 1.4 ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ (NLP)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                                                       | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                  | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                                                | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                   |
| :------------------------------------------------------------------------------ | :----------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------- | :--------------------- | :--------------------------------------------------------------------------------------------------------------------- |
| Stanford CS224N - NLP with Deep Learning                                       | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏à‡∏≤‡∏Å Stanford ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° NLP ‡∏™‡∏°‡∏±‡∏¢‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢ Deep Learning ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ transformers ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤            | Word embeddings, recurrent neural networks (RNNs), transformers, question answering, machine translation  | `[Intermediate/Advanced]` | [CS224N Course](http://web.stanford.edu/class/cs224n/)                                                                   |
| Jurafsky & Martin - Speech and Language Processing (3rd ed. draft)              | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô NLP ‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå (‡∏â‡∏ö‡∏±‡∏ö‡∏£‡πà‡∏≤‡∏á‡∏ü‡∏£‡∏µ) ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ñ‡∏∂‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á ‡πÄ‡∏ä‡πà‡∏ô language modeling          | Language modeling, parsing, semantics, discourse, machine translation                                        | `[Intermediate/Advanced]` | [SLP Book (3rd ed. draft)](https://web.stanford.edu/~jurafsky/slp3/)                                                       |
| Hugging Face - NLP Course                                                      | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™ interactive ‡∏™‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Transformers library ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô NLP ‡πÄ‡∏ä‡πà‡∏ô fine-tuning ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° | Transformers, tokenization, fine-tuning, ‡∏á‡∏≤‡∏ô NLP ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ                                               | `[Beginner/Intermediate]` | [Hugging Face Course](https://huggingface.co/learn/nlp-course/chapter1/1)                                                   |
| Natural Language Processing with Python (NLTK Book)                            | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏ü‡∏£‡∏µ‡∏™‡∏≠‡∏ô NLP ‡∏î‡πâ‡∏ß‡∏¢ Python ‡πÅ‡∏•‡∏∞ NLTK ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏ù‡∏∂‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥ (tokenization) | Tokenization, part-of-speech tagging, text classification, sentiment analysis                        | `[Beginner]`             | [NLTK Book](https://www.nltk.org/book/)                                                                                 |

### 1.5 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (How to Proceed)

1. **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:** ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ Machine Learning ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ Linear Algebra ‡∏Ç‡∏≠‡∏á 3Blue1Brown ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏£‡πå‡∏™ Probability and Statistics ‡∏Ç‡∏≠‡∏á Khan Academy ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô `[Beginner]`
2. **‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏†‡∏≤‡∏©‡∏≤ Python:** ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ Google's Python Class ‡∏´‡∏£‡∏∑‡∏≠ Automate the Boring Stuff ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏π‡πà‡πÑ‡∏õ‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏á‡πà‡∏≤‡∏¢‡πÜ `[Beginner/Intermediate]`
3. **‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏°:** ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô DeepLearning.AI Specialization ‡∏´‡∏£‡∏∑‡∏≠ fast.ai Course ‡πÅ‡∏•‡∏∞‡∏î‡∏π‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏Ç‡∏≠‡∏á 3Blue1Brown ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏´‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‡∏•‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ PyTorch `[Beginner/Intermediate]`
4. **‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å NLP:** ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ CS224N ‡∏Ç‡∏≠‡∏á Stanford ‡πÅ‡∏•‡∏∞‡∏•‡∏≠‡∏á‡∏ó‡∏≥ Hugging Face NLP Course ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å fine-tuning ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° `[Intermediate]`
5. **‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:** ‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠ MML ‡πÅ‡∏•‡∏∞ Jurafsky & Martin ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á language model `[Intermediate/Advanced]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ Machine Learning ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠ ‡∏ù‡∏∂‡∏Å‡∏ó‡∏≥‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à
- ‡∏≠‡∏¢‡πà‡∏≤‡∏Å‡∏•‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏•‡∏≠‡∏á‡∏ú‡∏¥‡∏î‡∏•‡∏≠‡∏á‡∏ñ‡∏π‡∏Å ‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏≥‡πÑ‡∏° gradient descent ‡∏ñ‡∏∂‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
- ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå ‡πÄ‡∏ä‡πà‡∏ô Reddit (r/MachineLearning), Stack Overflow ‡∏´‡∏£‡∏∑‡∏≠ Hugging Face Forums ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏Ç‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏±‡πà‡∏ô‡∏Ñ‡∏á‡πÉ‡∏ô‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå, Python, ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏° ‡πÅ‡∏•‡∏∞ NLP ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á*

### 1.1 ‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Machine Learning

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                    | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                   | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                    | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)     | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                              |
| :------------------------------------------- | :------------------------------------------------------------------------------------------------------------ | :----------------------------------------------------------------------------------------- | :---------------- | :-------------------------------------------------------------------------------------------------------------------------------- |
| 3Blue1Brown - Linear Algebra                 | ‡∏ä‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏™‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏û‡∏µ‡∏ä‡∏Ñ‡∏ì‡∏¥‡∏ï‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏´‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ã‡∏õ‡∏ï‡πå‡∏¢‡∏≤‡∏Å‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏°‡∏ó‡∏£‡∏¥‡∏Å‡∏ã‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô PCA | ‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå, ‡πÄ‡∏°‡∏ó‡∏£‡∏¥‡∏Å‡∏ã‡πå, ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á (transformations), ‡∏Ñ‡πà‡∏≤‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á (eigenvalues - ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô PCA), ‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á (eigenvectors - ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô SVD) | `[Beginner]`      | [YouTube Playlist](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)                                     |
| Khan Academy - Probability and Statistics    | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡∏ü‡∏£‡∏µ ‡∏™‡∏≠‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ML ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô, ‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á (distributions), ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö‡πÄ‡∏ö‡∏¢‡πå (Bayesian inference)      | `[Beginner/Intermediate]` | [Khan Academy Course](https://www.khanacademy.org/math/statistics-probability)                                                     |
| Mathematics for Machine Learning (MML)       | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ü‡∏£‡∏µ‡∏à‡∏≤‡∏Å Cambridge ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô ML ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö gradient descent | ‡∏û‡∏µ‡∏ä‡∏Ñ‡∏ì‡∏¥‡∏ï‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô, ‡πÅ‡∏Ñ‡∏•‡∏Ñ‡∏π‡∏•‡∏±‡∏™, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô, ‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (optimization)                        | `[Intermediate/Advanced]` | [MML Book](https://mml-book.github.io/)                                                                                       |
| All of Statistics (Wasserman)                | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏ô‡∏∏‡∏Å‡∏£‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô ML ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ñ‡∏î‡∏ñ‡∏≠‡∏¢‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á | ‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏≤‡∏ô‡∏ó‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ (statistical inference), ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡∏ñ‡∏î‡∏ñ‡∏≠‡∏¢ (regression), ‡∏≠‡∏ô‡∏∏‡∏Å‡∏£‡∏°‡πÄ‡∏ß‡∏•‡∏≤ (time series) | `[Advanced]`      | [All of Statistics Book](https://www.stat.cmu.edu/~larry/all-of-statistics/) ‡∏´‡∏£‡∏∑‡∏≠ [Springer Link](https://link.springer.com/book/10.1007/978-0-387-21736-9) |

### 1.2 ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Python

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                  | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                          | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                       | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)        | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                |
| :------------------------------------------- | :-------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------- | :------------------- | :-------------------------------------------------------------------------------------------------- |
| Python Official Documentation              | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á Python ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢‡πÉ‡∏ô ML ‡πÄ‡∏ä‡πà‡∏ô `random` ‡∏´‡∏£‡∏∑‡∏≠ `math` | ‡πÑ‡∏ß‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå (syntax), ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡πÇ‡∏°‡∏î‡∏π‡∏• (modules), ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô (standard library)               | `[All Levels]`   | [Python Docs](https://docs.python.org/3/)                                                               |
| Google's Python Class                      | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏ü‡∏£‡∏µ‡∏à‡∏≤‡∏Å Google ‡∏™‡∏≠‡∏ô Python ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏ù‡∏∂‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå | ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô, ‡∏™‡∏ï‡∏£‡∏¥‡∏á (strings), ‡∏•‡∏¥‡∏™‡∏ï‡πå (lists), ‡∏î‡∏¥‡∏Å‡∏ä‡∏±‡∏ô‡∏ô‡∏≤‡∏£‡∏µ (dictionaries), ‡πÑ‡∏ü‡∏•‡πå, regular expressions      | `[Beginner]`       | [Google's Python Class](https://developers.google.com/edu/python/)                                      |
| Corey Schafer - Python Tutorials           | ‡∏ä‡πà‡∏≠‡∏á YouTube ‡∏™‡∏≠‡∏ô Python ‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ OOP ‡πÅ‡∏•‡∏∞‡∏á‡∏≤‡∏ô data science ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ pandas | ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏ä‡∏¥‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ (OOP), ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏ß‡πá‡∏ö, ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (data science)            | `[Beginner/Intermediate]` | [Corey Schafer YouTube](https://www.youtube.com/c/Coreymschafer)                                        |
| Sentdex - Python Programming Tutorials     | ‡∏ä‡πà‡∏≠‡∏á YouTube ‡∏™‡∏≠‡∏ô Python ‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ML ‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ NumPy          | Machine Learning, ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏ß‡πá‡∏ö, ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏Å‡∏°                                 | `[Intermediate]`    | [Sentdex YouTube](https://www.youtube.com/c/sentdex)                                                 |
| Python for Data Analysis (Wes McKinney)    | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏™‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Python (‡πÄ‡∏ô‡πâ‡∏ô pandas) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô ML ‡πÅ‡∏•‡∏∞ data science   | pandas, NumPy, ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (data visualization)     | `[Intermediate/Advanced]` | [Python for Data Analysis](https://wesmckinney.com/book/)                                               |
| Automate the Boring Stuff with Python      | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏ü‡∏£‡∏µ ‡∏™‡∏≠‡∏ô Python ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏á‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô   | ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå, ‡∏Å‡∏≤‡∏£ scraping ‡πÄ‡∏ß‡πá‡∏ö, ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö Excel                                 | `[Beginner]`        | [Automate the Boring Stuff](https://automatetheboringstuff.com/)                                       |

### 1.3 ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏° (Neural Networks)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                    | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                                   | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                   |
| :------------------------------------------- | :--------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------- | :--------------------- | :--------------------------------------------------------------------------------------------------------------------- |
| DeepLearning.AI - Deep Learning Specialization | ‡∏ä‡∏∏‡∏î‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡∏ö‡∏ô Coursera ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô Deep Learning ‡πÄ‡∏ä‡πà‡∏ô backpropagation ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏°     | ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏°, backpropagation, convolutional neural networks (CNNs), recurrent neural networks (RNNs) | `[Beginner/Intermediate]` | [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning)                                  |
| 3Blue1Brown - Neural Networks                | ‡∏ä‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏° ‡πÄ‡∏ä‡πà‡∏ô gradient descent ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏≠‡∏£‡πå‡πÄ‡∏ã‡∏õ‡∏ï‡∏£‡∏≠‡∏ô       | ‡πÄ‡∏û‡∏≠‡∏£‡πå‡πÄ‡∏ã‡∏õ‡∏ï‡∏£‡∏≠‡∏ô (perceptrons), ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô (activation functions), backpropagation, gradient descent   | `[Beginner]`          | [Neural Networks Playlist](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)                  |
| fast.ai - Practical Deep Learning for Coders | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡πÄ‡∏ô‡πâ‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ ‡∏™‡∏≠‡∏ô Deep Learning ‡∏î‡πâ‡∏ß‡∏¢ fastai (‡∏ö‡∏ô PyTorch) ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏£‡∏¥‡∏á          | ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ Deep Learning, PyTorch, ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ fastai                                                  | `[Intermediate]`       | [fast.ai Course](https://course.fast.ai/)                                                                            |
| Stanford CS231n - Convolutional Neural Networks | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏à‡∏≤‡∏Å Stanford ‡πÄ‡∏ô‡πâ‡∏ô CNNs ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô Computer Vision ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° CNN ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î   | Convolutional layers, pooling layers, ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° CNN ‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°                                       | `[Intermediate/Advanced]` | [CS231n Course](http://cs231n.stanford.edu/)                                                                         |
| Transformers Explained (Hugging Face)        | ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡∏à‡∏≤‡∏Å Hugging Face ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô Transformers ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLM ‡πÄ‡∏ä‡πà‡∏ô attention mechanism     | Attention mechanism, self-attention, Transformer architecture                                  | `[Beginner/Intermediate]` | [Transformers Explained](https://huggingface.co/docs/transformers/quicktour)                                         |

### 1.4 ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ (NLP)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                                                       | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                  | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                                                | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                   |
| :------------------------------------------------------------------------------ | :----------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------- | :--------------------- | :--------------------------------------------------------------------------------------------------------------------- |
| Stanford CS224N - NLP with Deep Learning                                       | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏à‡∏≤‡∏Å Stanford ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° NLP ‡∏™‡∏°‡∏±‡∏¢‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢ Deep Learning ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ transformers ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤            | Word embeddings, recurrent neural networks (RNNs), transformers, question answering, machine translation  | `[Intermediate/Advanced]` | [CS224N Course](http://web.stanford.edu/class/cs224n/)                                                                   |
| Jurafsky & Martin - Speech and Language Processing (3rd ed. draft)              | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô NLP ‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå (‡∏â‡∏ö‡∏±‡∏ö‡∏£‡πà‡∏≤‡∏á‡∏ü‡∏£‡∏µ) ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ñ‡∏∂‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á ‡πÄ‡∏ä‡πà‡∏ô language modeling          | Language modeling, parsing, semantics, discourse, machine translation                                        | `[Intermediate/Advanced]` | [SLP Book (3rd ed. draft)](https://web.stanford.edu/~jurafsky/slp3/)                                                       |
| Hugging Face - NLP Course                                                      | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™ interactive ‡∏™‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Transformers library ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô NLP ‡πÄ‡∏ä‡πà‡∏ô fine-tuning ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° | Transformers, tokenization, fine-tuning, ‡∏á‡∏≤‡∏ô NLP ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ                                               | `[Beginner/Intermediate]` | [Hugging Face Course](https://huggingface.co/learn/nlp-course/chapter1/1)                                                   |
| Natural Language Processing with Python (NLTK Book)                            | ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏ü‡∏£‡∏µ‡∏™‡∏≠‡∏ô NLP ‡∏î‡πâ‡∏ß‡∏¢ Python ‡πÅ‡∏•‡∏∞ NLTK ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏ù‡∏∂‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥ (tokenization) | Tokenization, part-of-speech tagging, text classification, sentiment analysis                        | `[Beginner]`             | [NLTK Book](https://www.nltk.org/book/)                                                                                 |

### 1.5 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (How to Proceed)

1. **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:** ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ Machine Learning ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ Linear Algebra ‡∏Ç‡∏≠‡∏á 3Blue1Brown ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏£‡πå‡∏™ Probability and Statistics ‡∏Ç‡∏≠‡∏á Khan Academy ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô `[Beginner]`
2. **‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏†‡∏≤‡∏©‡∏≤ Python:** ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ Google's Python Class ‡∏´‡∏£‡∏∑‡∏≠ Automate the Boring Stuff ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏π‡πà‡πÑ‡∏õ‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏á‡πà‡∏≤‡∏¢‡πÜ `[Beginner/Intermediate]`
3. **‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏°:** ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô DeepLearning.AI Specialization ‡∏´‡∏£‡∏∑‡∏≠ fast.ai Course ‡πÅ‡∏•‡∏∞‡∏î‡∏π‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏Ç‡∏≠‡∏á 3Blue1Brown ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏´‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‡∏•‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ PyTorch `[Beginner/Intermediate]`
4. **‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å NLP:** ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ CS224N ‡∏Ç‡∏≠‡∏á Stanford ‡πÅ‡∏•‡∏∞‡∏•‡∏≠‡∏á‡∏ó‡∏≥ Hugging Face NLP Course ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å fine-tuning ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° `[Intermediate]`
5. **‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:** ‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠ MML ‡πÅ‡∏•‡∏∞ Jurafsky & Martin ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á language model `[Intermediate/Advanced]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ Machine Learning ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠ ‡∏ù‡∏∂‡∏Å‡∏ó‡∏≥‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à
- ‡∏≠‡∏¢‡πà‡∏≤‡∏Å‡∏•‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏•‡∏≠‡∏á‡∏ú‡∏¥‡∏î‡∏•‡∏≠‡∏á‡∏ñ‡∏π‡∏Å ‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏≥‡πÑ‡∏° gradient descent ‡∏ñ‡∏∂‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
- ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå ‡πÄ‡∏ä‡πà‡∏ô Reddit (r/MachineLearning), Stack Overflow ‡∏´‡∏£‡∏∑‡∏≠ Hugging Face Forums ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏Ç‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£ LLM (The LLM Engineer)

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ LLM ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡πÇ‡∏î‡∏¢‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢*

### 3.1 ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢ LLMs (Building Applications with LLMs)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                  | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                      | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                               | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
| :----------------------------------------- | :----------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------- | :--------------------- | :----------------------------------------------------------------------------------------------- |
| LangChain Documentation                    | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á LangChain ‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Å‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏î‡πâ‡∏ß‡∏¢ LLM ‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó | LLM chains, agents, memory, document loaders, indexes                                      | `[Intermediate/Advanced]` | [LangChain Docs](https://python.langchain.com/docs/get_started/introduction)                     |
| LlamaIndex Documentation                   | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á LlamaIndex (‡πÄ‡∏î‡∏¥‡∏°‡∏ä‡∏∑‡πà‡∏≠ GPT Index) ‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° LLM ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ | Data connectors, indexes, query engines, data agents                                       | `[Intermediate/Advanced]` | [LlamaIndex Docs](https://docs.llamaindex.ai/en/stable/)                                         |
| Guidance Documentation (Microsoft)         | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏≠‡∏á Guidance ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏à‡∏≤‡∏Å Microsoft ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏±‡∏ö LLM ‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ó‡∏°‡πÄ‡∏û‡∏•‡∏ï‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö | Language model control, templating, logic, chat interface                                 | `[Intermediate]`       | [Guidance Docs](https://github.com/guidance-ai/guidance)                                         |
| Building LLM Applications (Hugging Face)   | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏™‡∏±‡πâ‡∏ô‡∏à‡∏≤‡∏Å DeepLearning.AI ‡πÅ‡∏•‡∏∞ Hugging Face ‡∏™‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ LLM ‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÇ‡∏≠‡πÄ‡∏û‡∏ô‡∏ã‡∏≠‡∏£‡πå‡∏™ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ retrieval | Prompt engineering, ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ LLM ‡πÇ‡∏≠‡πÄ‡∏û‡∏ô‡∏ã‡∏≠‡∏£‡πå‡∏™, retrieval, ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á agents                     | `[Intermediate]`       | [Hugging Face Course](https://www.deeplearning.ai/short-courses/building-llm-applications-with-hugging-face/) |
| Build a GitHub Copilot Clone (YouTube)     | ‡∏ö‡∏ó‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô ‡∏™‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ GitHub Copilot ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥            | LangChain, OpenAI API, vector databases, Streamlit                                       | `[Intermediate/Advanced]` | [GitHub Copilot Clone Tutorial](https://www.youtube.com/watch?v=M-D2_UrjR-E)                    |
| Build a Custom ChatGPT Clone (YouTube)     | ‡∏ö‡∏ó‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ ChatGPT ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞                    | LangChain, OpenAI API, Gradio                                                    | `[Intermediate/Advanced]` | [ChatGPT Clone Tutorial](https://www.youtube.com/watch?v=RIWbalZ7wTo)                   |

### 3.2 ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏≠‡∏á LLM (Enhancing LLM Performance and Efficiency)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                                           | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                   | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                                    | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                     |
| :------------------------------------------------------------------ | :------------------------------------------------------------------------------------------------------------ | :------------------------------------------------------------------------------------------ | :--------------------- | :----------------------------------------------------------------------------------------------------------------------- |
| vLLM Documentation                                                | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏≠‡∏á vLLM ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ inference LLM ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ PagedAttention           | PagedAttention, continuous batching, optimized CUDA kernels                                    | `[Advanced]`      | [vLLM Docs](https://docs.vllm.ai/en/latest/)                                                                          |
| Optimum Documentation (Hugging Face)                                 | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏≠‡∏á Hugging Face Optimum ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÇ‡∏°‡πÄ‡∏î‡∏• Transformers ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ quantization      | Quantization, pruning, graph optimization, ONNX Runtime, OpenVINO                               | `[Intermediate/Advanced]` | [Optimum Docs](https://huggingface.co/docs/optimum/index)                                                               |
| Text Generation Inference (TGI) (Hugging Face)                          | Inference container ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö tensor parallelism                          | Optimized transformers, tensor parallelism, continuous batching, PagedAttention                   | `[Advanced]`      | [TGI (GitHub)](https://github.com/huggingface/text-generation-inference)                                                  |
| FasterTransformer (NVIDIA)                                        | ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏à‡∏≤‡∏Å NVIDIA ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡πà‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÇ‡∏°‡πÄ‡∏î‡∏• Transformer ‡∏ö‡∏ô GPU ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ INT8 inference                     | Optimized CUDA kernels, INT8 inference, FP16 inference                                          | `[Advanced]`      | [FasterTransformer (GitHub)](https://github.com/NVIDIA/FasterTransformer)                                                |
| DeepSpeed Inference: Enabling Efficient Inference (Microsoft)     | ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡πâ‡∏≤‡∏ô inference ‡∏Ç‡∏≠‡∏á DeepSpeed ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥                       | Model parallelism, memory optimization, optimized kernels                                      | `[Advanced]`      | [DeepSpeed Inference Blog](https://www.deepspeed.ai/tutorials/inference-tutorial/)                                      |
| Efficient Inference on a Single GPU                               | ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏™‡∏≤‡∏ò‡∏¥‡∏ï‡∏Å‡∏≤‡∏£ inference LLM ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ FlashAttention ‡∏ö‡∏ô GPU ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß                | Quantization, FlashAttention, bettertransformer                                                | `[Advanced]`      | [Hugging Face Blog](https://huggingface.co/blog/4bit-transformers-bitsandbytes)                                         |

### 3.3 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á LLM (LLM Security)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                             | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                     | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                                                                                                | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)   | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                                |
| :---------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------- | :------------- | :----------------------------------------------------------------------------------------------------------------------------------- |
| OWASP Top 10 for LLM Applications                  | ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ 10 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏≠‡∏õ LLM ‡∏à‡∏≤‡∏Å OWASP ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡∏î‡πâ‡∏ß‡∏¢ prompt injection          | Prompt injection, insecure output handling, training data poisoning, denial of service, sensitive information disclosure | `[Intermediate/Advanced]` | [OWASP Top 10 for LLM](https://owasp.org/www-project-top-10-for-large-language-model-applications/)                                |
| NIST - Adversarial Machine Learning: A Taxonomy and Terminology    | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏à‡∏≤‡∏Å NIST ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡∏î‡πâ‡∏≤‡∏ô Adversarial ML ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡πÅ‡∏ö‡∏ö poisoning                     | Poisoning attacks, evasion attacks, model extraction                                                  | `[Advanced]`     | [NIST Adversarial ML](https://csrc.nist.gov/pubs/ai/100/2/final)                                                                 |
| Robustness Gym (Hugging Face)                         | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• NLP ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡πÅ‡∏ö‡∏ö adversarial                                   | Attacks, evaluation metrics, robustness analysis                                              | `[Intermediate/Advanced]` | [Robustness Gym (GitHub)](https://github.com/robustness-gym/robustness-gym)                                              |
| Garak (llm-security.github.io)                        | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡πÅ‡∏Å‡∏ô‡∏ä‡πà‡∏≠‡∏á‡πÇ‡∏´‡∏ß‡πà‡∏Ç‡∏≠‡∏á LLM ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö prompt injection ‡∏´‡∏£‡∏∑‡∏≠ data leakage                           | Prompt injection, data leakage, jailbreaking                                                  | `[Intermediate/Advanced]` | [Garak](https://llm-security.github.io/garak/)                                                          |

### 3.4 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (How to Proceed)

1. **‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:** ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ LangChain ‡∏´‡∏£‡∏∑‡∏≠ LlamaIndex ‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ `[Intermediate]`
2. **‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Å‡∏±‡∏ö Guidance:** ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° LLM ‡πÉ‡∏´‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Guidance ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö `[Intermediate]`
3. **‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û:** ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏ä‡πà‡∏ô quantization, pruning ‡πÅ‡∏•‡∏∞ optimized kernels ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ vLLM, Optimum ‡∏´‡∏£‡∏∑‡∏≠ TGI `[Advanced]`
4. **‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢:** ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ OWASP Top 10 for LLM ‡πÅ‡∏•‡∏∞ NIST Adversarial ML ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô `[Intermediate/Advanced]`
5. **‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠:** ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Robustness Gym ‡πÅ‡∏•‡∏∞ Garak ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• `[Intermediate/Advanced]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ LLM ‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
- ‡∏ó‡∏î‡∏•‡∏≠‡∏á deploy ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå (AWS, GCP) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
- ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏ä‡∏∏‡∏°‡∏ä‡∏ô ‡πÄ‡∏ä‡πà‡∏ô Hugging Face Forums ‡∏´‡∏£‡∏∑‡∏≠ Reddit (r/MachineLearning) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏´‡∏°‡πà‡πÜ

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏•‡∏∞ Repository ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á (Advanced Scripts & Repositories)

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå repositories ‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏•‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤ LLM ‡πÉ‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å*

### 4.1 DeepSeek AI Repositories

*Repositories ‡∏à‡∏≤‡∏Å DeepSeek AI ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ß‡∏¥‡∏à‡∏±‡∏¢ AI ‡∏ó‡∏µ‡πà‡πÄ‡∏ô‡πâ‡∏ô‡∏á‡∏≤‡∏ô Open Source*

#### Performance Optimization

| Repository                                  | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                       | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                    |
| :------------------------------------------ | :------------------------------------------------------------------------------------------------------------ | :---------------------------------------------------------------------------------------- |
| DeepSpeed-FastGen                          | ‡∏£‡∏∞‡∏ö‡∏ö inference ‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ô DeepSpeed ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô real-time                          | [DeepSpeed-FastGen (GitHub)](https://github.com/DeepSpeed-MII/DeepSpeed-FastGen)             |
| DeepSpeed-Kernels                           | Custom CUDA kernels ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DeepSpeed ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÇ‡∏°‡πÄ‡∏î‡∏• LLM                                     | [DeepSpeed-Kernels (GitHub)](https://github.com/microsoft/DeepSpeed-Kernels)                |
| DeepSpeed-MII                            | ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö deploy ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û LLM ‡∏î‡πâ‡∏ß‡∏¢ DeepSpeed ‡πÄ‡∏ä‡πà‡∏ô ‡∏•‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥                          | [DeepSpeed-MII (GitHub)](https://github.com/microsoft/DeepSpeed-MII)                           |
| DeepSpeed                                     | ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏à‡∏≤‡∏Å Microsoft ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö optimize ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞ inference ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà                                   | [DeepSpeed (GitHub)](https://github.com/microsoft/DeepSpeed)                                  |
| 3FS: Fast, Flexible, and Friendly Sparse Attention    | ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Sparse Attention ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì attention                                     | [3FS](https://github.com/DeepSeek-AI/3FS)             |
| DeepGEMM                                  | GEMM (General Matrix Multiplication) ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å                            | [DeepGEMM (GitHub)](https://github.com/DeepSeek-AI/DeepGEMM)                                |

#### Model Architectures

| Repository                                       | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                  | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                           |
| :----------------------------------------------- | :------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------- |
| DeepSeek-LLM                                  | ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏≠‡πÄ‡∏û‡∏ô‡∏ã‡∏≠‡∏£‡πå‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DeepSeek LLM ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà                     | [DeepSeek-LLM (GitHub)](https://github.com/deepseek-ai/DeepSeek-LLM)                         |
| DeepSeek-MoE                                   | ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏≠‡πÄ‡∏û‡∏ô‡∏ã‡∏≠‡∏£‡πå‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DeepSeek MoE ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ö‡∏ö mixture-of-experts           | [DeepSeek-MoE (GitHub)](https://github.com/deepseek-ai/DeepSeek-MoE)                        |
| FastMoE                                        | ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Mixture of Experts (MoE) ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà       | [FastMoE](https://github.com/laekov/fastmoe)                                         |

#### Datasets
| Repository                                       | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                  | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                           |
| :----------------------------------------------- | :------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------- |
| UltraFeedback                                  | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö preference data ‡πÉ‡∏ä‡πâ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå      | [UltraFeedback](https://huggingface.co/datasets/openbmb/UltraFeedback)                     |

#### Other Tools
| Repository                                  | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                       | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                       |
| :----------------------------------------- | :----------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------ |
| ChatTemplate                              | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ó‡∏°‡πÄ‡∏û‡∏•‡∏ï‡πÅ‡∏ä‡∏ó            | [ChatTemplate](https://github.com/DeepSeek-AI/ChatTemplate)                             |

### 4.2 Uncensored AI Models

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ã‡πá‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå (uncensored) ‡∏ã‡∏∂‡πà‡∏á‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∞‡∏°‡∏±‡∏î‡∏£‡∏∞‡∏ß‡∏±‡∏á‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö‡∏ï‡πà‡∏≠‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏≤‡∏°‡∏°‡∏≤*

**‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô:** ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ uncensored models ‡∏≠‡∏≤‡∏à‡∏ô‡∏≥‡πÑ‡∏õ‡∏™‡∏π‡πà‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢ ‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡∏´‡∏£‡∏∑‡∏≠‡∏ú‡∏¥‡∏î‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢ ‡πÇ‡∏õ‡∏£‡∏î‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏™‡∏ï‡∏¥

| Repository/Model                | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                  |
| :------------------------------ | :-------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| Dolphin (Eric Hartford)          | ‡πÇ‡∏°‡πÄ‡∏î‡∏• fine-tuned ‡∏à‡∏≤‡∏Å Llama 2 ‡πÅ‡∏•‡∏∞ WizardLM ‡πÄ‡∏ô‡πâ‡∏ô‡∏•‡∏î bias ‡πÅ‡∏•‡∏∞ censorship ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢                 | [Dolphin (Hugging Face)](https://huggingface.co/ehartford/dolphin-2.2.1-mistral-7b)                   |
| OpenHathi-7B-Hi-v0.1-Base (Sarvam AI) | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏Æ‡∏¥‡∏ô‡∏î‡∏µ ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡πÅ‡∏•‡∏∞‡∏Æ‡∏¥‡∏á‡∏•‡∏¥‡∏ä ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢ Sarvam AI ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢                                | [OpenHathi (Hugging Face)](https://huggingface.co/sarvamai/OpenHathi-7B-Hi-v0.1-Base)                |
| OpenOrca (OpenOrca)              | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏≠‡πÄ‡∏û‡∏ô‡∏ã‡∏≠‡∏£‡πå‡∏™ ‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á (instruction following)                                     | [OpenOrca (Hugging Face)](https://huggingface.co/Open-Orca)                                          |
| mpt-30b-chat (MosaicML)         | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ ‡∏Ç‡∏ô‡∏≤‡∏î 30B parameters ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡πÅ‡∏ä‡∏ó‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô                        | [mpt-30b-chat (Hugging Face)](https://huggingface.co/mosaicml/mpt-30b-chat)                         |
| WizardLM (Microsoft)             | ‡πÇ‡∏°‡πÄ‡∏î‡∏• fine-tuned ‡∏à‡∏≤‡∏Å LLaMA ‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ ‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô                | [WizardLM (GitHub)](https://github.com/nlpxucan/WizardLM)                                          |
| OpenThaiGPT (OpenThaiGPT)        | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏≠‡πÄ‡∏û‡∏ô‡∏ã‡∏≠‡∏£‡πå‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡πÑ‡∏ó‡∏¢ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô NLP ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢                               | [OpenThaiGPT (Hugging Face)](https://huggingface.co/openthaigpt)                                   |

### 4.3 Fine-Tuning Tables

| Repository                                          | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                             |
| :-------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------- |
| Unsloth                                            | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö fine-tuning ‡πÅ‡∏•‡∏∞ quantization ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• 7B ‡∏ö‡∏ô GPU ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß           | [Unsloth (GitHub)](https://github.com/unslothai/unsloth)                                                            |
| LLaMA-Factory                                        | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö fine-tuning LLaMA ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö                                     | [LLaMA-Factory (GitHub)](https://github.com/hiyouga/LLaMA-Factory)                                               |
| Axolotl                                             | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ fine-tuning LLM ‡∏ó‡∏µ‡πà‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á                                            | [Axolotl (GitHub)](https://github.com/OpenAccess-AI-Collective/axolotl)                                        |
| PEFT (Hugging Face)                                  | ‡∏ß‡∏¥‡∏ò‡∏µ Parameter-Efficient Fine-Tuning (PEFT) ‡∏à‡∏≤‡∏Å Hugging Face ‡πÄ‡∏ä‡πà‡∏ô LoRA ‡πÅ‡∏•‡∏∞ Prompt Tuning                        | [PEFT (GitHub)](https://github.com/huggingface/peft)                                                        |
| trlX                                              | ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å LLM ‡∏î‡πâ‡∏ß‡∏¢ reinforcement learning (fork ‡∏à‡∏≤‡∏Å TRL) ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ PPO                                 | [trlX](https://github.com/CarperAI/trlx)                                                                  |
| AutoTrain (Hugging Face)                           | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ fine-tuning ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏á‡∏≤‡∏ô‡∏î‡πà‡∏ß‡∏ô                                  | [AutoTrain (Hugging Face)](https://huggingface.co/autotrain)                                              |

### 4.4 Awesome Colab Notebooks

| Notebook                                           | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                                      | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                                |
| :------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------- |
| Kaggle Notebooks - LLM Science Exam              | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á notebooks ‡∏à‡∏≤‡∏Å Kaggle ‡∏™‡∏≠‡∏ô‡πÉ‡∏ä‡πâ LLM ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö                             | [Kaggle LLM Science Exam](https://www.kaggle.com/competitions/kaggle-llm-science-exam/code)                          |
| ML-Engineering Open Book                         | ‡∏ä‡∏∏‡∏î notebooks ‡πÅ‡∏•‡∏∞‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏° ML ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£ deploy ‡πÇ‡∏°‡πÄ‡∏î‡∏•                                                | [ml-engineering-open-book](https://github.com/stas00/ml-engineering-open-book/tree/master/open-book)                |
| MLOps Course (Made With ML)                      | ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏µ notebooks ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ pipeline ML                                                        | [mlops-course](https://github.com/GokuMohandas/mlops-course)                                                       |
| Unsloth Fine-Tuning Example                      | Notebook ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å Unsloth ‡∏™‡∏≠‡∏ô fine-tuning ‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏ä‡πà‡∏ô LLaMA ‡∏ö‡∏ô Colab                                         | [Unsloth Colab](https://colab.research.google.com/drive/1zB1t1qFO5n4bdnqP4KauS2sV_lPtP2Q)                        |

### 4.5 Research Papers

#### Quantization
- SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models: [SmoothQuant](https://arxiv.org/abs/2211.10438)
- GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers: [GPTQ](https://arxiv.org/abs/2210.17323)
- AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration: [AWQ](https://arxiv.org/abs/2306.00978)
- ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers: [ZeroQuant](https://arxiv.org/abs/2206.01861)

#### Fine-Tuning Techniques
- LoRA: Low-Rank Adaptation of Large Language Models: [LoRA](https://arxiv.org/abs/2106.09685)
- QLoRA: Efficient Finetuning of Quantized LLMs: [QLoRA](https://arxiv.org/abs/2305.14314)
- Direct Preference Optimization: Your Language Model is Secretly a Reward Model: [DPO](https://arxiv.org/abs/2305.18290)
- ORPO: Monolithic Preference Optimization without Reference Model: [ORPO](https://arxiv.org/abs/2403.07687)

#### Distributed Training
- ZeRO: Memory Optimizations Toward Training Trillion Parameter Models: [ZeRO](https://arxiv.org/abs/1910.02054)
- Megatron-LM: Training Multi-Billion Parameter Models Using Model Parallelism: [Megatron-LM](https://arxiv.org/abs/1909.08053)
- Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B: [Megatron-Turing NLG 530B](https://arxiv.org/abs/2201.11990)

#### Other Topics
- Llama 2: Open Foundation and Fine-Tuned Chat Models: [Llama2](https://arxiv.org/abs/2307.09288)
- FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness: [FlashAttention](https://arxiv.org/abs/2205.14135)
- FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning: [FlashAttention-2](https://arxiv.org/abs/2307.08691)
- A Survey of Large Language Models: [LLM Survey](https://arxiv.org/abs/2303.18223)
- Instruction Tuning for Large Language Models: A Survey: [Instruction Tuning](https://arxiv.org/abs/2308.10792)

### 4.6 Additional Learning Resources

#### Project Ideas and Datasets
- [Kaggle](https://www.kaggle.com/): ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô Data Science ‡πÅ‡∏•‡∏∞‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢
- [NLP Datasets (Hugging Face)](https://huggingface.co/datasets): ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô NLP

#### Online Courses
- Andrew Ng's Courses on Coursera and DeepLearning.AI: ‡∏Ñ‡∏≠‡∏£‡πå‡∏™ Machine Learning ‡πÅ‡∏•‡∏∞ Deep Learning ‡∏ä‡∏±‡πâ‡∏ô‡∏ô‡∏≥
- fast.ai: ‡∏Ñ‡∏≠‡∏£‡πå‡∏™ Deep Learning ‡πÄ‡∏ô‡πâ‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏à‡∏£‡∏¥‡∏á

#### Podcasts
- Lex Fridman Podcast: ‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ AI ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå
- Data Skeptic: ‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á Data Science, Machine Learning ‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
- The TWIML AI Podcast: ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ ML ‡πÅ‡∏•‡∏∞ AI

#### YouTube Channels
- Sentdex: ‡∏™‡∏≠‡∏ô Python ‡πÅ‡∏•‡∏∞ Machine Learning
- Corey Schafer: ‡∏™‡∏≠‡∏ô Python ‡∏ó‡∏∏‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö
- 3Blue1Brown: ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏î‡πâ‡∏ß‡∏¢‡∏†‡∏≤‡∏û‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß
- Two Minute Papers: ‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠ paper ‡∏ß‡∏¥‡∏à‡∏±‡∏¢ AI ‡πÅ‡∏ö‡∏ö‡∏™‡∏±‡πâ‡∏ô

#### Online Communities
- Reddit: r/MachineLearning, r/LanguageTechnology
- Stack Overflow: ‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏°‡∏≠‡∏£‡πå
- Hugging Face Forums: ‡∏ü‡∏≠‡∏£‡∏±‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ Hugging Face
- Discord Servers: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ "LLM Discord" ‡∏´‡∏£‡∏∑‡∏≠ "AI Discord" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ô‡πâ‡∏ô AI ‡πÅ‡∏•‡∏∞ LLM

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ LLM ‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï (Applying LLMs in Real-World and Future Trends)

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ LLM ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏à‡∏£‡∏¥‡∏á ‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏• ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà‡πÜ ‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï*

### 5.1 ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ LLM (Real-World LLM Projects)

| ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå                                      | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                       | ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ                              | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
| :------------------------------------------- | :----------------------------------------------------------------------------------------------- | :------------------------------------------ | :--------------------- | :----------------------------------------------------------------------------------------------- |
| Chatbot for Customer Support                 | ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô                              | LangChain, Llama 3, Gradio                  | `[Intermediate]`       | [Example Repo](https://github.com/langchain-ai/langchain/tree/master/templates)                  |
| Document Summarization Tool                  | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏¢‡∏≤‡∏ß ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£                                          | Hugging Face Transformers, Mistral 7B       | `[Intermediate/Advanced]` | [Hugging Face Tutorial](https://huggingface.co/docs/transformers/tasks/summarization)           |
| Code Generation Assistant                    | ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Python ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ bug                                      | OpenAI API, GitHub Copilot Clone, Streamlit | `[Intermediate/Advanced]` | [Copilot Clone Tutorial](https://www.youtube.com/watch?v=M-D2_UrjR-E)                          |
| Multilingual Translator                      | ‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡πÑ‡∏ó‡∏¢-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©-‡∏à‡∏µ‡∏ô ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• open-source                              | OpenThaiGPT, mBART                          | `[Advanced]`           | [mBART Docs](https://huggingface.co/docs/transformers/model_doc/mbart)                         |

### 5.2 ‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á LLM (Evaluation and Improvement)

| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                    | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                           | ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ (Subtopics)                           | ‡∏£‡∏∞‡∏î‡∏±‡∏ö (Level)          | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
| :------------------------------------------- | :-------------------------------------------------------------------------------------------------- | :---------------------------------------------- | :--------------------- | :----------------------------------------------------------------------------------------------- |
| Hugging Face Evaluate                        | ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ (accuracy) ‡∏´‡∏£‡∏∑‡∏≠ BLEU score ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤                   | Metrics, evaluation datasets, benchmarking      | `[Intermediate]`       | [Evaluate Docs](https://huggingface.co/docs/evaluate/index)                                      |
| EleutherAI LM Evaluation Harness             | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û LLM ‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô MMLU ‡∏´‡∏£‡∏∑‡∏≠ TruthfulQA                       | Task-specific evaluation, zero-shot testing     | `[Advanced]`           | [LM Eval (GitHub)](https://github.com/EleutherAI/lm-evaluation-harness)                         |
| HumanEval: Evaluating Large Language Models  | Paper ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ HumanEval ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á LLM                             | Code generation metrics, functional correctness | `[Advanced]`           | [HumanEval (Arxiv)](https://arxiv.org/abs/2107.03374)                                           |
| MT-Bench: A Multi-turn Benchmark            | Paper ‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠ MT-Bench ‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á LLM                                | Multi-turn dialogue, human-like responses       | `[Advanced]`           | [MT-Bench (Arxiv)](https://arxiv.org/abs/2306.05685)                                            |

### 5.3 ‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÅ‡∏•‡∏∞‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ LLM (Emerging Trends and Innovations)

| ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠                                         | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                           | ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á                        | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
| :------------------------------------------- | :-------------------------------------------------------------------------------------------------- | :--------------------------------------------- | :----------------------------------------------------------------------------------------------- |
| Multimodal LLMs                              | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÄ‡∏ä‡πà‡∏ô CLIP-ViT ‡∏´‡∏£‡∏∑‡∏≠ DALL-E 3                                | Paper: "Flamingo" (Arxiv)                      | [Flamingo (Arxiv)](https://arxiv.org/abs/2204.14198)                                            |
| Smaller, Efficient Models                    | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡πÅ‡∏ï‡πà‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á ‡πÄ‡∏ä‡πà‡∏ô Phi-3 (Microsoft) ‡∏´‡∏£‡∏∑‡∏≠ TinyLlama ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£       | Phi-3 Blog (Microsoft)                         | [Phi-3 Blog](https://azure.microsoft.com/en-us/blog/introducing-phi-3/)                         |
| AI Agents and Tool Integration               | ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ AI agents ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ LLM ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ ‡πÄ‡∏ä‡πà‡∏ô AutoGen ‡∏´‡∏£‡∏∑‡∏≠ AgentGPT                          | AutoGen (GitHub)                               | [AutoGen (GitHub)](https://github.com/microsoft/autogen)                                        |
| Ethical AI and Regulation                    | ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏é‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏•‡∏î bias ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏î‡∏¢ LLM                 | AI Ethics Guidelines (UNESCO)                  | [UNESCO AI Ethics](https://unesdoc.unesco.org/ark:/48223/pf0000381137)                          |

### 5.4 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (How to Proceed)

1. **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏á‡πà‡∏≤‡∏¢‡πÜ:** ‡∏•‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ LangChain ‡∏´‡∏£‡∏∑‡∏≠ Hugging Face `[Intermediate]`
2. **‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•:** ‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏¢‡πà‡∏≤‡∏á Hugging Face Evaluate ‡∏´‡∏£‡∏∑‡∏≠ LM Evaluation Harness ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤ `[Intermediate/Advanced]`
3. **‡∏™‡∏≥‡∏£‡∏ß‡∏à‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà:** ‡∏≠‡πà‡∏≤‡∏ô paper ‡πÄ‡∏ä‡πà‡∏ô Flamingo ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏à‡∏≤‡∏Å Microsoft ‡πÅ‡∏•‡∏∞ xAI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ ‡πÄ‡∏ä‡πà‡∏ô multimodal LLMs `[Advanced]`
4. **‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á:** ‡∏•‡∏≠‡∏á‡∏£‡∏ß‡∏° LLM ‡∏Å‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏∑‡πà‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏£‡πâ‡∏≤‡∏á AI agent ‡∏î‡πâ‡∏ß‡∏¢ AutoGen ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö edge devices `[Advanced]`
5. **‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏°:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö bias ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô UNESCO AI Ethics `[All Levels]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ LLM ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô ‡∏ö‡∏ô‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡πâ‡∏≠‡∏á‡∏ñ‡∏¥‡πà‡∏ô
- ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏ä‡∏∏‡∏°‡∏ä‡∏ô ‡πÄ‡∏ä‡πà‡∏ô Arxiv ‡∏´‡∏£‡∏∑‡∏≠ X (Twitter) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏û‡∏•‡∏≤‡∏î‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö‡∏ï‡πà‡∏≠‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ç‡∏≠‡∏á LLM ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏¥‡πà‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 6: ‡∏®‡∏±‡∏û‡∏ó‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ LLM (Key Terminology in the LLM Field)

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ Large Language Models (LLM) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ï‡πà‡∏≤‡∏á‡πÜ*

### 6.1 ‡∏®‡∏±‡∏û‡∏ó‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (Basic Terminology)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå                   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢                                                                                       |
| :----------------------- | :--------------------------------------------------------------------------------------------- |
| LLM (Large Language Model) | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å ‡πÉ‡∏ä‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô GPT ‡∏´‡∏£‡∏∑‡∏≠ LLaMA |
| Transformer              | ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLM ‡πÉ‡∏ä‡πâ‡∏Å‡∏•‡πÑ‡∏Å attention ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ö‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö                       |
| Attention                | ‡∏Å‡∏•‡πÑ‡∏Å‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ                       |
| Pre-training             | ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏Å‡πà‡∏≠‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏ñ‡∏±‡∏î‡πÑ‡∏õ                |
| Fine-tuning             | ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà pre-trained ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á              |
| Token                    | ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏¢‡πà‡∏≠‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥ ‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•                            |
| Embedding                | ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡∏´‡∏£‡∏∑‡∏≠ token ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå              |

### 6.2 ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ (Techniques and Methods)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå                   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢                                                                                       |
| :----------------------- | :--------------------------------------------------------------------------------------------- |
| Self-Attention           | ‡∏Å‡∏•‡πÑ‡∏Å attention ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏∏‡∏Å token ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô                           |
| Multi-Head Attention     | ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ attention ‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏±‡πâ‡∏ô‡πÉ‡∏ô Transformer ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢                      |
| Masked Language Model (MLM) | ‡∏ß‡∏¥‡∏ò‡∏µ pre-training ‡∏ó‡∏µ‡πà‡∏ã‡πà‡∏≠‡∏ô‡∏ö‡∏≤‡∏á‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô BERT                        |
| Autoregressive Model     | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô GPT                                   |
| LoRA (Low-Rank Adaptation) | ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ fine-tuning ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£                      |
| QLoRA                    | ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏° quantization ‡∏Å‡∏±‡∏ö LoRA ‡πÄ‡∏û‡∏∑‡πà‡∏≠ fine-tuning ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡πâ‡∏≠‡∏¢‡∏•‡∏á                       |
| Quantization             | ‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏à‡∏≤‡∏Å FP32 ‡πÄ‡∏õ‡πá‡∏ô INT8 ‡∏´‡∏£‡∏∑‡∏≠ 4-bit ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô           |
| Prompt Engineering       | ‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡πâ LLM ‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô prompt                   |
| RLHF (Reinforcement Learning from Human Feedback) | ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ feedback ‡∏à‡∏≤‡∏Å‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£                     |

### 6.3 ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Performance and Deployment)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå                   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢                                                                                       |
| :----------------------- | :--------------------------------------------------------------------------------------------- |
| Inference                | ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏• ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°                            |
| Latency                  | ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö                                                  |
| Throughput               | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏ß‡∏•‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏≥‡∏ï‡πà‡∏≠‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ                                |
| Model Parallelism        | ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏õ‡∏£‡∏±‡∏ô‡∏ö‡∏ô GPU ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà                                  |
| Data Parallelism         | ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏ù‡∏∂‡∏Å‡∏ö‡∏ô GPU ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡πà‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•                                    |
| PagedAttention           | ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÉ‡∏ô inference ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏ç‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û              |
| FlashAttention           | ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ attention ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô pre-training ‡πÅ‡∏•‡∏∞ inference             |

### 6.4 ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏° (Safety and Ethics)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå                   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢                                                                                       |
| :----------------------- | :--------------------------------------------------------------------------------------------- |
| Bias                     | ‡∏≠‡∏Ñ‡∏ï‡∏¥‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏•‡∏≥‡πÄ‡∏≠‡∏µ‡∏¢‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏û‡∏®‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏ä‡∏≤‡∏ï‡∏¥                    |
| Prompt Injection         | ‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡πÇ‡∏î‡∏¢‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢‡πÉ‡∏ô prompt ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏≠‡∏Å‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£                       |
| Jailbreaking             | ‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏ö‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏´‡πâ‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢               |
| Data Poisoning           | ‡∏Å‡∏≤‡∏£‡∏õ‡∏ô‡πÄ‡∏õ‡∏∑‡πâ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î                      |
| Explainability           | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£                                 |

### 6.5 ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Evaluation and Datasets)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå                   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢                                                                                       |
| :----------------------- | :--------------------------------------------------------------------------------------------- |
| BLEU Score               | ‡∏ï‡∏±‡∏ß‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤ ‡πÇ‡∏î‡∏¢‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏õ‡∏•‡∏à‡∏≤‡∏Å‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå                            |
| Perplexity               | ‡∏ï‡∏±‡∏ß‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏à‡∏≠‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏ñ‡∏±‡∏î‡πÑ‡∏õ ‡∏Ñ‡πà‡∏≤‡∏¢‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≥‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ                                |
| MMLU (Massive Multitask Language Understanding) | ‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Ç‡∏≠‡∏á LLM ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏´‡∏•‡∏≤‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå                |
| TruthfulQA               | ‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å LLM                                 |
| HumanEval                | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á LLM ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÇ‡∏à‡∏ó‡∏¢‡πå‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°                    |

### 6.6 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏®‡∏±‡∏û‡∏ó‡πå (How to Proceed)

1. **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:** ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô LLM, Transformer, ‡πÅ‡∏•‡∏∞ Token ‡∏Å‡πà‡∏≠‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô `[Beginner]`
2. **‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏®‡∏±‡∏û‡∏ó‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á LoRA ‡∏´‡∏£‡∏∑‡∏≠ Quantization ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô paper ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ `[Intermediate]`
3. **‡∏ù‡∏∂‡∏Å‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á:** ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå ‡πÄ‡∏ä‡πà‡∏ô ‡∏ß‡∏±‡∏î latency ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥ prompt engineering ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏´‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô `[Intermediate/Advanced]`
4. **‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢:** ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ bias ‡πÅ‡∏•‡∏∞ prompt injection ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡πâ‡∏≤‡∏ó‡∏≤‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏° `[All Levels]`
5. **‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡πÉ‡∏´‡∏°‡πà:** ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏´‡∏£‡∏∑‡∏≠ paper ‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≤‡∏Å Hugging Face ‡∏´‡∏£‡∏∑‡∏≠ Arxiv ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î `[Advanced]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ LLM ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏Ñ‡∏≥‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡∏≤‡∏°‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤
- ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏®‡∏±‡∏û‡∏ó‡πå‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
- ‡∏•‡∏≠‡∏á‡∏à‡∏î‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠‡∏ö‡πà‡∏≠‡∏¢‡πÅ‡∏•‡∏∞‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∏‡πâ‡∏ô‡πÄ‡∏Ñ‡∏¢

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 7: ‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö LLM (Example Files and Links for LLMs)

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Colab Notebooks ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå ‡πÅ‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö Large Language Models (LLM) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏ô‡∏≥‡πÑ‡∏õ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏î‡πâ*

### 7.1 Colab Notebooks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM

| ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå/‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                              | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                   |
| :-------------------------------------------- | :--------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| LLaMA Fine-Tuning with Unsloth                | ‡∏™‡∏≠‡∏ô fine-tuning LLaMA ‡∏î‡πâ‡∏ß‡∏¢ Unsloth ‡∏ö‡∏ô Colab ‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏ö‡∏ô GPU ‡∏ü‡∏£‡∏µ                | [Unsloth Fine-Tuning](https://colab.research.google.com/drive/1zB1t1qFO5n4bdnqP4KauS2sV_lPtP2Q)         |
| Fine-Tune Llama 3 with DPO & LoRA             | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á fine-tuning Llama 3 ‡∏î‡πâ‡∏ß‡∏¢ DPO ‡πÅ‡∏•‡∏∞ LoRA                              | [Llama 3 DPO](https://colab.research.google.com/drive/1K2vQA9r5tB0n2XTR1Zc6oQ5s-w6WxxJ)              |
| Build Your Own GPT from Scratch               | ‡∏™‡∏£‡πâ‡∏≤‡∏á GPT ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏à‡∏≤‡∏Å‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏î‡πâ‡∏ß‡∏¢ Python ‡∏ö‡∏ô Colab                             | [Build GPT](https://colab.research.google.com/drive/1JMLaCPxM7B6UzT0I8vDwAIXeH-oQss4)                |
| Hugging Face Transformers Tutorial            | ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Transformers ‡πÄ‡∏ä‡πà‡∏ô BERT ‡∏´‡∏£‡∏∑‡∏≠ GPT-2                           | [Transformers Tutorial](https://colab.research.google.com/drive/1rXvHQMjt0r3ADP9gEg0rHfx)         |
| Quantization with BitsAndBytes                | ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ 4-bit quantization ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£          | [Quantization Colab](https://colab.research.google.com/drive/1VoYNfYdk7zLVRWj8DHRcvcK)             |
| LangChain RAG Example                         | ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö Retrieval-Augmented Generation (RAG) ‡∏î‡πâ‡∏ß‡∏¢ LangChain              | [LangChain RAG](https://colab.research.google.com/drive/1G5i7qQe7e5vU5gW5zR0rL8v)                |
| Mistral 7B Inference                          | ‡∏£‡∏±‡∏ô Mistral 7B ‡πÄ‡∏û‡∏∑‡πà‡∏≠ inference ‡∏ö‡∏ô Colab                                    | [Mistral 7B](https://colab.research.google.com/drive/1zXy5t8nXz9v5gW5sR0rL8v)                   |
| Train a Tiny LLM with TinyStories             | ‡∏ù‡∏∂‡∏Å LLM ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• TinyStories                                  | [Tiny LLM](https://colab.research.google.com/drive/1Xy5t8nXz9v5gW5sR0rL8v)                     |

### 7.2 ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å GitHub

| ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå/Repository                          | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                   |
| :------------------------------------------ | :--------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| minGPT (Karpathy)                            | ‡πÇ‡∏Ñ‡πâ‡∏î Python ‡∏™‡∏£‡πâ‡∏≤‡∏á GPT ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏à‡∏≤‡∏Å Andrej Karpathy                           | [minGPT](https://github.com/karpathy/minGPT)                                                          |
| nanoGPT                                      | ‡∏≠‡∏µ‡∏Å‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏Ç‡∏≠‡∏á GPT ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å ‡∏ù‡∏∂‡∏Å‡πÑ‡∏î‡πâ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤                           | [nanoGPT](https://github.com/karpathy/nanoGPT)                                                        |
| LLaMA-Factory Scripts                        | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö fine-tuning LLaMA ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô‡πÜ                              | [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory/tree/main/scripts)                           |
| DeepSpeed Training Example                   | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ DeepSpeed                                        | [DeepSpeed Examples](https://github.com/microsoft/DeepSpeed/tree/master/examples)                     |
| Hugging Face Transformers Examples           | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å BERT ‡∏´‡∏£‡∏∑‡∏≠ GPT-2                              | [Transformers Examples](https://github.com/huggingface/transformers/tree/main/examples)                |
| Axolotl Fine-Tuning Scripts                  | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå fine-tuning LLM ‡∏ó‡∏µ‡πà‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô                                       | [Axolotl Scripts](https://github.com/OpenAccess-AI-Collective/axolotl/tree/main/examples)             |
| vLLM Inference Script                        | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö inference ‡∏î‡πâ‡∏ß‡∏¢ vLLM                                         | [vLLM Examples](https://github.com/vllm-project/vllm/tree/main/examples)                              |
| FlashAttention Implementation                | ‡πÇ‡∏Ñ‡πâ‡∏î Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö FlashAttention                                         | [FlashAttention](https://github.com/Dao-AILab/flash-attention)                                        |

### 7.3 ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Datasets) ‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á

| ‡∏ä‡∏∑‡πà‡∏≠‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•/‡πÑ‡∏ü‡∏•‡πå                           | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                   |
| :------------------------------------------ | :--------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| The Pile                                      | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å LLM (800GB)                                    | [The Pile](https://pile.eleuther.ai/)                                                                 |
| TinyStories                                  | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏±‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å                                 | [TinyStories](https://huggingface.co/datasets/roneneldan/TinyStories)                                 |
| OpenWebText                                  | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö pre-training                                | [OpenWebText](https://huggingface.co/datasets/Skylion007/openwebtext)                                 |
| Alpaca Dataset                               | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• instruction-tuning ‡∏à‡∏≤‡∏Å Stanford                                 | [Alpaca](https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json)                     |
| Dolly 15k                                    | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 15,000 ‡∏Ñ‡∏π‡πà‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö fine-tuning                         | [Dolly 15k](https://huggingface.co/datasets/databricks-dolly-15k)                                     |
| UltraFeedback                                | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• preference ‡∏à‡∏≤‡∏Å OpenBMB                                          | [UltraFeedback](https://huggingface.co/datasets/openbmb/UltraFeedback)                                |
| MMLU Dataset                                 | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Ç‡∏≠‡∏á LLM                                       | [MMLU](https://huggingface.co/datasets/lukaemon/mmlu)                                                 |

### 7.4 ‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ (Pre-trained Models)

| ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•                                   | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                   |
| :------------------------------------------ | :--------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| Llama 3 (Meta)                               | ‡πÇ‡∏°‡πÄ‡∏î‡∏• Llama 3 ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡πà‡∏≤‡∏á‡πÜ (‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå)                                    | [Llama 3](https://huggingface.co/meta-llama/Llama-3-8b)                                               |
| Mistral 7B                                   | ‡πÇ‡∏°‡πÄ‡∏î‡∏• 7B parameters ‡∏à‡∏≤‡∏Å Mistral AI                                       | [Mistral 7B](https://huggingface.co/mistralai/Mixtral-7B-v0.1)                                        |
| GPT-2 (OpenAI)                               | ‡πÇ‡∏°‡πÄ‡∏î‡∏• GPT-2 ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏•‡∏≠‡∏á                                           | [GPT-2](https://huggingface.co/gpt2)                                                                  |
| BERT Base (Google)                           | ‡πÇ‡∏°‡πÄ‡∏î‡∏• BERT ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NLP                                             | [BERT Base](https://huggingface.co/bert-base-uncased)                                                 |
| OpenThaiGPT                                  | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏à‡∏≤‡∏Å‡∏ä‡∏∏‡∏°‡∏ä‡∏ô OpenThaiGPT                                         | [OpenThaiGPT](https://huggingface.co/openthaigpt/openthaigpt-1.0.0-7b)                                |
| DeepSeek R1                                  | ‡πÇ‡∏°‡πÄ‡∏î‡∏• open-weight 671B parameters                                        | [DeepSeek R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)                                         |
| Phi-3 (Microsoft)                            | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡πÅ‡∏ï‡πà‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å Microsoft                                      | [Phi-3](https://huggingface.co/microsoft/phi-3-mini-4k-instruct)                                      |

### 7.5 ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏∑‡πà‡∏ô‡πÜ

| ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå/‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠                      | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                   |
| :------------------------------------------ | :--------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| LangChain Examples                           | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô LangChain ‡πÄ‡∏ä‡πà‡∏ô RAG ‡∏´‡∏£‡∏∑‡∏≠ agents                          | [LangChain Examples](https://github.com/langchain-ai/langchain/tree/master/templates)                 |
| LlamaIndex Examples                          | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° LLM ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å‡∏î‡πâ‡∏ß‡∏¢ LlamaIndex                      | [LlamaIndex Examples](https://github.com/run-llama/llama_index/tree/main/examples)                    |
| AutoGen Multi-Agent Example                  | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏£‡πâ‡∏≤‡∏á multi-agent ‡∏î‡πâ‡∏ß‡∏¢ AutoGen                                    | [AutoGen Examples](https://github.com/microsoft/autogen/tree/main/samples)                            |
| Hugging Face Spaces                          | ‡πÅ‡∏≠‡∏õ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô LLM ‡∏ö‡∏ô Hugging Face Spaces                              | [HF Spaces](https://huggingface.co/spaces)                                                            |
| TRL Examples (RLHF)                          | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ù‡∏∂‡∏Å LLM ‡∏î‡πâ‡∏ß‡∏¢ reinforcement learning                               | [TRL Examples](https://github.com/huggingface/trl/tree/main/examples)                                 |
| PEFT Examples                                | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Parameter-Efficient Fine-Tuning ‡πÄ‡∏ä‡πà‡∏ô LoRA                       | [PEFT Examples](https://github.com/huggingface/peft/tree/main/examples)                               |

### 7.6 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå (How to Proceed)

1. **‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏ö‡∏ô Colab:** ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢ Colab Notebooks ‡πÄ‡∏ä‡πà‡∏ô "Build Your Own GPT" ‡∏´‡∏£‡∏∑‡∏≠ "LLaMA Fine-Tuning" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏≠‡∏∞‡πÑ‡∏£ `[Beginner/Intermediate]`
2. **‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå:** ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏à‡∏≤‡∏Å GitHub ‡πÄ‡∏ä‡πà‡∏ô minGPT ‡∏´‡∏£‡∏∑‡∏≠ nanoGPT ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì `[Intermediate]`
3. **‡πÉ‡∏ä‡πâ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:** ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏ä‡πà‡∏ô Alpaca ‡∏´‡∏£‡∏∑‡∏≠ TinyStories ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å‡∏´‡∏£‡∏∑‡∏≠ fine-tune ‡πÇ‡∏°‡πÄ‡∏î‡∏• `[Intermediate/Advanced]`
4. **‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏£‡∏π‡∏õ:** ‡∏•‡∏≠‡∏á‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏ä‡πà‡∏ô Mistral 7B ‡∏´‡∏£‡∏∑‡∏≠ OpenThaiGPT ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á `[Intermediate]`
5. **‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå:** ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å LangChain ‡∏´‡∏£‡∏∑‡∏≠ AutoGen ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏´‡∏£‡∏∑‡∏≠ RAG `[Advanced]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡∏≠‡∏á Colab (‡πÄ‡∏ä‡πà‡∏ô GPU ‡∏ü‡∏£‡∏µ‡∏°‡∏µ‡∏à‡∏≥‡∏Å‡∏±‡∏î) ‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏ô‡πÑ‡∏ü‡∏•‡πå
- ‡∏ö‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
- ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏µ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ GPU ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 7: ‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö LLM (Example Files and Links for LLMs)

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Colab Notebooks ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå ‡πÅ‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö Large Language Models (LLM) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏ô‡∏≥‡πÑ‡∏õ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏î‡πâ*

### 7.1 Colab Notebooks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM

| ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå/‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                              | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                   |
| :-------------------------------------------- | :--------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| LLaMA Fine-Tuning with Unsloth                | ‡∏™‡∏≠‡∏ô fine-tuning LLaMA ‡∏î‡πâ‡∏ß‡∏¢ Unsloth ‡∏ö‡∏ô Colab ‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏ö‡∏ô GPU ‡∏ü‡∏£‡∏µ                | [Unsloth Fine-Tuning](https://colab.research.google.com/drive/1zB1t1qFO5n4bdnqP4KauS2sV_lPtP2Q)         |
| Fine-Tune Llama 3 with DPO & LoRA             | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á fine-tuning Llama 3 ‡∏î‡πâ‡∏ß‡∏¢ DPO ‡πÅ‡∏•‡∏∞ LoRA                              | [Llama 3 DPO](https://colab.research.google.com/drive/1K2vQA9r5tB0n2XTR1Zc6oQ5s-w6WxxJ)              |
| Build Your Own GPT from Scratch               | ‡∏™‡∏£‡πâ‡∏≤‡∏á GPT ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏à‡∏≤‡∏Å‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏î‡πâ‡∏ß‡∏¢ Python ‡∏ö‡∏ô Colab                             | [Build GPT](https://colab.research.google.com/drive/1JMLaCPxM7B6UzT0I8vDwAIXeH-oQss4)                |
| Hugging Face Transformers Tutorial            | ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Transformers ‡πÄ‡∏ä‡πà‡∏ô BERT ‡∏´‡∏£‡∏∑‡∏≠ GPT-2                           | [Transformers Tutorial](https://colab.research.google.com/drive/1rXvHQMjt0r3ADP9gEg0rHfx)         |
| Quantization with BitsAndBytes                | ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ 4-bit quantization ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£          | [Quantization Colab](https://colab.research.google.com/drive/1VoYNfYdk7zLVRWj8DHRcvcK)             |
| LangChain RAG Example                         | ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö Retrieval-Augmented Generation (RAG) ‡∏î‡πâ‡∏ß‡∏¢ LangChain              | [LangChain RAG](https://colab.research.google.com/drive/1G5i7qQe7e5vU5gW5zR0rL8v)                |
| Mistral 7B Inference                          | ‡∏£‡∏±‡∏ô Mistral 7B ‡πÄ‡∏û‡∏∑‡πà‡∏≠ inference ‡∏ö‡∏ô Colab                                    | [Mistral 7B](https://colab.research.google.com/drive/1zXy5t8nXz9v5gW5sR0rL8v)                   |
| Train a Tiny LLM with TinyStories             | ‡∏ù‡∏∂‡∏Å LLM ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• TinyStories                                  | [Tiny LLM](https://colab.research.google.com/drive/1Xy5t8nXz9v5gW5sR0rL8v)                     |

### 7.2 ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å GitHub

| ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå/Repository                          | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                   |
| :------------------------------------------ | :--------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| minGPT (Karpathy)                            | ‡πÇ‡∏Ñ‡πâ‡∏î Python ‡∏™‡∏£‡πâ‡∏≤‡∏á GPT ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏à‡∏≤‡∏Å Andrej Karpathy                           | [minGPT](https://github.com/karpathy/minGPT)                                                          |
| nanoGPT                                      | ‡∏≠‡∏µ‡∏Å‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏Ç‡∏≠‡∏á GPT ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å ‡∏ù‡∏∂‡∏Å‡πÑ‡∏î‡πâ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤                           | [nanoGPT](https://github.com/karpathy/nanoGPT)                                                        |
| LLaMA-Factory Scripts                        | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö fine-tuning LLaMA ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô‡πÜ                              | [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory/tree/main/scripts)                           |
| DeepSpeed Training Example                   | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ DeepSpeed                                        | [DeepSpeed Examples](https://github.com/microsoft/DeepSpeed/tree/master/examples)                     |
| Hugging Face Transformers Examples           | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å BERT ‡∏´‡∏£‡∏∑‡∏≠ GPT-2                              | [Transformers Examples](https://github.com/huggingface/transformers/tree/main/examples)                |
| Axolotl Fine-Tuning Scripts                  | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå fine-tuning LLM ‡∏ó‡∏µ‡πà‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô                                       | [Axolotl Scripts](https://github.com/OpenAccess-AI-Collective/axolotl/tree/main/examples)             |
| vLLM Inference Script                        | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö inference ‡∏î‡πâ‡∏ß‡∏¢ vLLM                                         | [vLLM Examples](https://github.com/vllm-project/vllm/tree/main/examples)                              |
| FlashAttention Implementation                | ‡πÇ‡∏Ñ‡πâ‡∏î Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö FlashAttention                                         | [FlashAttention](https://github.com/Dao-AILab/flash-attention)                                        |

### 7.3 ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Datasets) ‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á

| ‡∏ä‡∏∑‡πà‡∏≠‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•/‡πÑ‡∏ü‡∏•‡πå                           | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                   |
| :------------------------------------------ | :--------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| The Pile                                      | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å LLM (800GB)                                    | [The Pile](https://pile.eleuther.ai/)                                                                 |
| TinyStories                                  | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏±‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å                                 | [TinyStories](https://huggingface.co/datasets/roneneldan/TinyStories)                                 |
| OpenWebText                                  | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö pre-training                                | [OpenWebText](https://huggingface.co/datasets/Skylion007/openwebtext)                                 |
| Alpaca Dataset                               | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• instruction-tuning ‡∏à‡∏≤‡∏Å Stanford                                 | [Alpaca](https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json)                     |
| Dolly 15k                                    | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 15,000 ‡∏Ñ‡∏π‡πà‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö fine-tuning                         | [Dolly 15k](https://huggingface.co/datasets/databricks-dolly-15k)                                     |
| UltraFeedback                                | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• preference ‡∏à‡∏≤‡∏Å OpenBMB                                          | [UltraFeedback](https://huggingface.co/datasets/openbmb/UltraFeedback)                                |
| MMLU Dataset                                 | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Ç‡∏≠‡∏á LLM                                       | [MMLU](https://huggingface.co/datasets/lukaemon/mmlu)                                                 |

### 7.4 ‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ (Pre-trained Models)

| ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•                                   | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                   |
| :------------------------------------------ | :--------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| Llama 3 (Meta)                               | ‡πÇ‡∏°‡πÄ‡∏î‡∏• Llama 3 ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡πà‡∏≤‡∏á‡πÜ (‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå)                                    | [Llama 3](https://huggingface.co/meta-llama/Llama-3-8b)                                               |
| Mistral 7B                                   | ‡πÇ‡∏°‡πÄ‡∏î‡∏• 7B parameters ‡∏à‡∏≤‡∏Å Mistral AI                                       | [Mistral 7B](https://huggingface.co/mistralai/Mixtral-7B-v0.1)                                        |
| GPT-2 (OpenAI)                               | ‡πÇ‡∏°‡πÄ‡∏î‡∏• GPT-2 ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏•‡∏≠‡∏á                                           | [GPT-2](https://huggingface.co/gpt2)                                                                  |
| BERT Base (Google)                           | ‡πÇ‡∏°‡πÄ‡∏î‡∏• BERT ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NLP                                             | [BERT Base](https://huggingface.co/bert-base-uncased)                                                 |
| OpenThaiGPT                                  | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏à‡∏≤‡∏Å‡∏ä‡∏∏‡∏°‡∏ä‡∏ô OpenThaiGPT                                         | [OpenThaiGPT](https://huggingface.co/openthaigpt/openthaigpt-1.0.0-7b)                                |
| DeepSeek R1                                  | ‡πÇ‡∏°‡πÄ‡∏î‡∏• open-weight 671B parameters                                        | [DeepSeek R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)                                         |
| Phi-3 (Microsoft)                            | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡πÅ‡∏ï‡πà‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å Microsoft                                      | [Phi-3](https://huggingface.co/microsoft/phi-3-mini-4k-instruct)                                      |

### 7.5 ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏∑‡πà‡∏ô‡πÜ

| ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå/‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠                      | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                                   |
| :------------------------------------------ | :--------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| LangChain Examples                           | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô LangChain ‡πÄ‡∏ä‡πà‡∏ô RAG ‡∏´‡∏£‡∏∑‡∏≠ agents                          | [LangChain Examples](https://github.com/langchain-ai/langchain/tree/master/templates)                 |
| LlamaIndex Examples                          | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° LLM ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å‡∏î‡πâ‡∏ß‡∏¢ LlamaIndex                      | [LlamaIndex Examples](https://github.com/run-llama/llama_index/tree/main/examples)                    |
| AutoGen Multi-Agent Example                  | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏£‡πâ‡∏≤‡∏á multi-agent ‡∏î‡πâ‡∏ß‡∏¢ AutoGen                                    | [AutoGen Examples](https://github.com/microsoft/autogen/tree/main/samples)                            |
| Hugging Face Spaces                          | ‡πÅ‡∏≠‡∏õ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô LLM ‡∏ö‡∏ô Hugging Face Spaces                              | [HF Spaces](https://huggingface.co/spaces)                                                            |
| TRL Examples (RLHF)                          | ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ù‡∏∂‡∏Å LLM ‡∏î‡πâ‡∏ß‡∏¢ reinforcement learning                               | [TRL Examples](https://github.com/huggingface/trl/tree/main/examples)                                 |
| PEFT Examples                                | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Parameter-Efficient Fine-Tuning ‡πÄ‡∏ä‡πà‡∏ô LoRA                       | [PEFT Examples](https://github.com/huggingface/peft/tree/main/examples)                               |

### 7.6 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå (How to Proceed)

1. **‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏ö‡∏ô Colab:** ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢ Colab Notebooks ‡πÄ‡∏ä‡πà‡∏ô "Build Your Own GPT" ‡∏´‡∏£‡∏∑‡∏≠ "LLaMA Fine-Tuning" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏≠‡∏∞‡πÑ‡∏£ `[Beginner/Intermediate]`
2. **‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå:** ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏à‡∏≤‡∏Å GitHub ‡πÄ‡∏ä‡πà‡∏ô minGPT ‡∏´‡∏£‡∏∑‡∏≠ nanoGPT ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì `[Intermediate]`
3. **‡πÉ‡∏ä‡πâ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:** ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏ä‡πà‡∏ô Alpaca ‡∏´‡∏£‡∏∑‡∏≠ TinyStories ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å‡∏´‡∏£‡∏∑‡∏≠ fine-tune ‡πÇ‡∏°‡πÄ‡∏î‡∏• `[Intermediate/Advanced]`
4. **‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏£‡∏π‡∏õ:** ‡∏•‡∏≠‡∏á‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏ä‡πà‡∏ô Mistral 7B ‡∏´‡∏£‡∏∑‡∏≠ OpenThaiGPT ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á `[Intermediate]`
5. **‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå:** ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å LangChain ‡∏´‡∏£‡∏∑‡∏≠ AutoGen ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏´‡∏£‡∏∑‡∏≠ RAG `[Advanced]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡∏≠‡∏á Colab (‡πÄ‡∏ä‡πà‡∏ô GPU ‡∏ü‡∏£‡∏µ‡∏°‡∏µ‡∏à‡∏≥‡∏Å‡∏±‡∏î) ‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏ô‡πÑ‡∏ü‡∏•‡πå
- ‡∏ö‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
- ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏µ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ GPU ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 8: ‡∏Å‡∏≤‡∏£ deploy LLM ‡πÉ‡∏ô Production (Deploying LLMs in Production)

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ LLM ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö production ‡πÄ‡∏ä‡πà‡∏ô ‡∏ö‡∏ô‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô*

### 8.1 ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Deployment

| ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠                             | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                     | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                           |
| :------------------------------------ | :------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------- |
| Hugging Face Inference API            | API ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏£‡∏π‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏ô‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå‡∏Ç‡∏≠‡∏á Hugging Face                                       | [Inference API](https://huggingface.co/inference-api)                                          |
| Text Generation Inference (TGI)       | Container ‡∏à‡∏≤‡∏Å Hugging Face ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö inference LLM ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà                                 | [TGI](https://github.com/huggingface/text-generation-inference)                                |
| vLLM                                  | ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö inference ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö PagedAttention                                  | [vLLM](https://github.com/vllm-project/vllm)                                                  |
| FastAPI                               | ‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Å Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á API ‡πÄ‡∏û‡∏∑‡πà‡∏≠ serve LLM                                       | [FastAPI](https://fastapi.tiangolo.com/)                                                      |
| Docker                                | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á container ‡πÄ‡∏û‡∏∑‡πà‡∏≠ deploy LLM ‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πà                                      | [Docker](https://www.docker.com/)                                                             |
| AWS SageMaker                         | ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå‡∏à‡∏≤‡∏Å AWS ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞ deploy ‡πÇ‡∏°‡πÄ‡∏î‡∏• ML/LLM                                     | [SageMaker](https://aws.amazon.com/sagemaker/)                                                |

### 8.2 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£ Deploy LLM

1. **‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ optimize:**
   - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÄ‡∏ä‡πà‡∏ô Mistral 7B ‡∏´‡∏£‡∏∑‡∏≠ Llama 3
   - ‡πÉ‡∏ä‡πâ quantization (‡πÄ‡∏ä‡πà‡∏ô BitsAndBytes) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
   - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö inference ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡πâ‡∏≠‡∏á‡∏ñ‡∏¥‡πà‡∏ô‡∏Å‡πà‡∏≠‡∏ô

2. **‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°:**
   - ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies ‡πÄ‡∏ä‡πà‡∏ô PyTorch, Transformers
   - ‡πÉ‡∏ä‡πâ Docker ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á container ‡∏ó‡∏µ‡πà‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠

3. **‡∏™‡∏£‡πâ‡∏≤‡∏á API:**
   - ‡πÉ‡∏ä‡πâ FastAPI ‡∏´‡∏£‡∏∑‡∏≠ Flask ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á endpoint ‡πÄ‡∏ä‡πà‡∏ô `/generate`
   - ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î: [FastAPI Example](https://github.com/tiangolo/fastapi/tree/master/docs/en/docs/tutorial)

4. **Deploy ‡∏ö‡∏ô‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå:**
   - ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î container ‡πÑ‡∏õ‡∏¢‡∏±‡∏á AWS, GCP ‡∏´‡∏£‡∏∑‡∏≠ Azure
   - ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ load balancer ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å

5. **‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á:**
   - ‡∏ß‡∏±‡∏î latency ‡πÅ‡∏•‡∏∞ throughput
   - ‡∏õ‡∏£‡∏±‡∏ö batch size ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ vLLM ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û

### 8.3 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Deployment

| ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á                               | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                                                                                     | ‡∏•‡∏¥‡∏á‡∏Å‡πå/‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                                                      |
| :------------------------------------ | :------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------- |
| Deploy Llama 3 on AWS                 | ‡∏™‡∏≠‡∏ô deploy Llama 3 ‡∏î‡πâ‡∏ß‡∏¢ SageMaker                                                  | [AWS Tutorial](https://aws.amazon.com/blogs/machine-learning/deploy-llama-3-on-aws/)   |
| Chatbot API with FastAPI              | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î FastAPI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö serve LLM ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó                                  | [GitHub](https://github.com/fastapi-users/fastapi-llm-example)                        |
| TGI on Docker                         | ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏£‡∏±‡∏ô TGI container ‡∏ö‡∏ô Docker                                                 | [TGI Docker](https://huggingface.co/docs/text-generation-inference/quicktour)         |

### 8.4 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (How to Proceed)

1. **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡πâ‡∏≠‡∏á‡∏ñ‡∏¥‡πà‡∏ô:** ‡∏•‡∏≠‡∏á‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏•‡πá‡∏Å ‡πÄ‡∏ä‡πà‡∏ô GPT-2 ‡∏î‡πâ‡∏ß‡∏¢ FastAPI ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì `[Intermediate]`
2. **‡∏ó‡∏î‡∏•‡∏≠‡∏á Docker:** ‡∏™‡∏£‡πâ‡∏≤‡∏á container ‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏î‡πâ‡∏ß‡∏¢ Docker ‡πÅ‡∏•‡∏∞ deploy ‡πÇ‡∏°‡πÄ‡∏î‡∏• `[Intermediate/Advanced]`
3. **‡πÉ‡∏ä‡πâ‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå‡∏ü‡∏£‡∏µ:** ‡∏•‡∏≠‡∏á deploy ‡∏ö‡∏ô Hugging Face Spaces ‡∏´‡∏£‡∏∑‡∏≠ AWS Free Tier `[Intermediate]`
4. **‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û:** ‡πÉ‡∏ä‡πâ vLLM ‡∏´‡∏£‡∏∑‡∏≠ TGI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î latency ‡πÅ‡∏•‡∏∞‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô `[Advanced]`
5. **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢:** ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ authentication ‡πÅ‡∏•‡∏∞‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô prompt injection `[Advanced]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏ó‡∏î‡∏™‡∏≠‡∏ö load ‡πÅ‡∏•‡∏∞ scalability ‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡∏•‡πà‡∏≠‡∏¢‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á
- ‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢ ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå ‡πÄ‡∏ä‡πà‡∏ô AWS ‡∏´‡∏£‡∏∑‡∏≠ GCP
- ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ API ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏¢‡∏∞ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 9: ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö LLM (Research Papers on LLMs)

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Large Language Models (LLMs) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏î‡πâ*

### 9.1 ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (Foundational Papers)

| ‡∏ä‡∏∑‡πà‡∏≠ paper                                      | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                     | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
| :--------------------------------------------- | :------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------- |
| Attention Is All You Need                      | ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ Transformer ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLM ‡∏™‡∏°‡∏±‡∏¢‡πÉ‡∏´‡∏°‡πà (2017)                                   | [Arxiv](https://arxiv.org/abs/1706.03762)                                                       |
| BERT: Pre-training of Deep Bidirectional Transformers | ‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠ BERT ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ pre-training ‡πÅ‡∏ö‡∏ö bidirectional (2018)                                | [Arxiv](https://arxiv.org/abs/1810.04805)                                                       |
| Improving Language Understanding by Generative Pre-Training | ‡∏á‡∏≤‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á GPT ‡∏à‡∏≤‡∏Å OpenAI (2018)                                                       | [OpenAI](https://cdn.openai.com/research-papers/improving-language-understanding-by-generative-pre-training.pdf) |
| Language Models are Few-Shot Learners          | ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ GPT-3 ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ few-shot learning (2020)                                          | [Arxiv](https://arxiv.org/abs/2005.14165)                                                       |

### 9.2 ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (Training and Optimization)

| ‡∏ä‡∏∑‡πà‡∏≠ paper                                      | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                     | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
| :--------------------------------------------- | :------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------- |
| LoRA: Low-Rank Adaptation of Large Language Models | ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ fine-tuning ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏î‡πâ‡∏ß‡∏¢ low-rank updates (2021)                            | [Arxiv](https://arxiv.org/abs/2106.09685)                                                       |
| QLoRA: Efficient Finetuning of Quantized LLMs  | ‡∏£‡∏ß‡∏° quantization ‡∏Å‡∏±‡∏ö LoRA ‡πÄ‡∏û‡∏∑‡πà‡∏≠ fine-tuning ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡πâ‡∏≠‡∏¢ (2023)                      | [Arxiv](https://arxiv.org/abs/2305.14314)                                                       |
| FlashAttention: Fast and Memory-Efficient Exact Attention | ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ attention ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ (2022)                                        | [Arxiv](https://arxiv.org/abs/2205.14135)                                                       |
| ZeRO: Memory Optimizations Toward Training Trillion Parameter Models | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡∏•‡πâ‡∏≤‡∏ô‡∏•‡πâ‡∏≤‡∏ô‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå (2019)                             | [Arxiv](https://arxiv.org/abs/1910.02054)                                                       |

### 9.3 ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ (Evaluation and Capabilities)

| ‡∏ä‡∏∑‡πà‡∏≠ paper                                      | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                     | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
| :--------------------------------------------- | :------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------- |
| HumanEval: Evaluating Large Language Models   | ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á LLM (2021)                                       | [Arxiv](https://arxiv.org/abs/2107.03374)                                                       |
| TruthfulQA: Measuring How Models Mimic Human Lies | ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡∏Ç‡∏≠‡∏á LLM (2021)                                            | [Arxiv](https://arxiv.org/abs/2109.07958)                                                       |
| MMLU: Measuring Massive Multitask Language Understanding | ‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏´‡∏•‡∏≤‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤‡∏Ç‡∏≠‡∏á LLM (2021)                                                | [Arxiv](https://arxiv.org/abs/2009.03300)                                                       |
| Large Language Models Can Predict Neuroscience Results | LLM ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå (2024)                                     | [Nature](https://www.nature.com/articles/s41562-024-02040-5)                                    |

### 9.4 ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏à‡∏£‡∏¥‡∏¢‡∏ò‡∏£‡∏£‡∏° (Safety and Ethics)

| ‡∏ä‡∏∑‡πà‡∏≠ paper                                      | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                     | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
| :--------------------------------------------- | :------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------- |
| Direct Preference Optimization: Your Language Model is Secretly a Reward Model | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ù‡∏∂‡∏Å LLM ‡∏î‡πâ‡∏ß‡∏¢ preference ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ reward model (2023)                                   | [Arxiv](https://arxiv.org/abs/2305.18290)                                                       |
| Red Teaming Language Models with Language Models | ‡πÉ‡∏ä‡πâ LLM ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ä‡πà‡∏≠‡∏á‡πÇ‡∏´‡∏ß‡πà‡∏Ç‡∏≠‡∏á LLM ‡∏≠‡∏∑‡πà‡∏ô (2022)                                              | [Arxiv](https://arxiv.org/abs/2202.03286)                                                       |
| On the Dangers of Stochastic Parrots          | ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÅ‡∏•‡∏∞ bias ‡πÉ‡∏ô LLM (2021)                                                    | [ACM](https://dl.acm.org/doi/10.1145/3442188.3445922)                                           |
| A Survey on LLM Security and Privacy: The Good, The Bad, and The Ugly | ‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡πÉ‡∏ô LLM (2024)                                              | [ScienceDirect](https://www.sciencedirect.com/science/article/pii/S2666659624000082)            |

### 9.5 ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà (Recent Papers and Emerging Trends)

| ‡∏ä‡∏∑‡πà‡∏≠ paper                                      | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                     | ‡∏•‡∏¥‡∏á‡∏Å‡πå                                                                                             |
| :--------------------------------------------- | :------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------- |
| Llama 2: Open Foundation and Fine-Tuned Chat Models | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î Llama 2 ‡πÇ‡∏°‡πÄ‡∏î‡∏• open-source ‡∏à‡∏≤‡∏Å Meta (2023)                                       | [Arxiv](https://arxiv.org/abs/2307.09288)                                                       |
| ORPO: Monolithic Preference Optimization      | ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ù‡∏∂‡∏Å LLM ‡∏î‡πâ‡∏ß‡∏¢ preference ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á (2024)                                     | [Arxiv](https://arxiv.org/abs/2403.07691)                                                       |
| A Survey of Large Language Models             | ‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô LLM ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡πâ‡∏≤‡∏ó‡∏≤‡∏¢ (2023)                                   | [Arxiv](https://arxiv.org/abs/2303.18223)                                                       |
| Multimodal Large Language Models: A Survey    | ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° LLM ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (2024)                                | [Arxiv](https://arxiv.org/abs/2404.18465)                                                       |

### 9.6 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤ paper (How to Proceed)

1. **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:** ‡∏≠‡πà‡∏≤‡∏ô "Attention Is All You Need" ‡πÅ‡∏•‡∏∞ "BERT" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLM `[Beginner]`
2. **‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•:** ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ "LoRA" ‡πÅ‡∏•‡∏∞ "FlashAttention" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ optimization `[Intermediate]`
3. **‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ:** ‡∏•‡∏≠‡∏á‡∏≠‡πà‡∏≤‡∏ô "HumanEval" ‡∏´‡∏£‡∏∑‡∏≠ "MMLU" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡∏¥‡∏ò‡∏µ‡∏ß‡∏±‡∏î‡∏ú‡∏• LLM `[Intermediate/Advanced]`
4. **‡∏™‡∏≥‡∏£‡∏ß‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢:** ‡∏≠‡πà‡∏≤‡∏ô "Stochastic Parrots" ‡πÅ‡∏•‡∏∞ "Red Teaming" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏π‡πâ‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á `[Advanced]`
5. **‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå:** ‡∏≠‡πà‡∏≤‡∏ô paper ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î ‡πÄ‡∏ä‡πà‡∏ô "ORPO" ‡∏´‡∏£‡∏∑‡∏≠ "Multimodal LLMs" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏° `[Advanced]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- Paper ‡∏ö‡∏≤‡∏á‡∏â‡∏ö‡∏±‡∏ö‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏´‡∏£‡∏∑‡∏≠ machine learning ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à
- ‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ ‡∏ì ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 6 ‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏° 2568 ‡πÅ‡∏ï‡πà‡∏ö‡∏≤‡∏á‡∏≠‡∏±‡∏ô‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏≠‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå
- ‡∏≠‡πà‡∏≤‡∏ô abstract ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ß‡πà‡∏≤ paper ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 10: ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏û‡∏¥‡πÄ‡∏®‡∏© ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ ‡πÅ‡∏•‡∏∞ Framework ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö LLM

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏û‡∏¥‡πÄ‡∏®‡∏© ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ (Tools) ‡πÅ‡∏•‡∏∞ Framework ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô LLM ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏•‡∏∞‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á*

### 10.1 ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (Core Principles)

| ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£                          | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                   | ‡∏•‡∏¥‡∏á‡∏Å‡πå/‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                                                 |
| :----------------------------- | :----------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------- |
| Attention Mechanism            | ‡∏Å‡∏•‡πÑ‡∏Å‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô Self-Attention ‡πÉ‡∏ô Transformer                | [Attention Paper](https://arxiv.org/abs/1706.03762)                              |
| Pre-training and Fine-tuning   | ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô (pre-training) ‡πÅ‡∏•‡πâ‡∏ß‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞ (fine-tuning)       | [BERT Paper](https://arxiv.org/abs/1810.04805)                                   |
| Autoregressive Modeling        | ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô GPT                                            | [GPT Paper](https://arxiv.org/abs/2005.14165)                                    |
| Scaling Laws                   | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô ‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô                | [Scaling Laws](https://arxiv.org/abs/2001.08361)                                 |

### 10.2 ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ (Methodologies)

| ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£                          | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                   | ‡∏•‡∏¥‡∏á‡∏Å‡πå/‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                                                 |
| :----------------------------- | :----------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------- |
| Masked Language Modeling (MLM) | ‡∏ã‡πà‡∏≠‡∏ô‡∏ö‡∏≤‡∏á‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô ‡πÉ‡∏ô BERT                                                | [BERT Paper](https://arxiv.org/abs/1810.04805)                                   |
| Instruction Tuning             | ‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô                                     | [Instruction Tuning](https://arxiv.org/abs/2308.10792)                           |
| Reinforcement Learning from Human Feedback (RLHF) | ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ feedback ‡∏à‡∏≤‡∏Å‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå ‡πÄ‡∏ä‡πà‡∏ô ‡πÉ‡∏ô Llama 2                                | [Llama 2 Paper](https://arxiv.org/abs/2307.09288)                                |
| Knowledge Distillation         | ‡∏ñ‡πà‡∏≤‡∏¢‡∏ó‡∏≠‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏ç‡πà‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏•‡πá‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û                    | [Distillation Paper](https://arxiv.org/abs/1503.02531)                           |

### 10.3 ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏û‡∏¥‡πÄ‡∏®‡∏© (Special Techniques)

| ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ                          | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                   | ‡∏•‡∏¥‡∏á‡∏Å‡πå/‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                                                 | ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á                                                      |
| :----------------------------- | :----------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------- | :-------------------------------------------------------------------- |
| LoRA (Low-Rank Adaptation)     | Fine-tuning ‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£                                | [LoRA Paper](https://arxiv.org/abs/2106.09685)                            | [LoRA Example](https://github.com/huggingface/peft/tree/main/examples/lora) |
| QLoRA                          | ‡∏£‡∏ß‡∏° quantization ‡∏Å‡∏±‡∏ö LoRA ‡πÄ‡∏û‡∏∑‡πà‡∏≠ fine-tuning ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡πâ‡∏≠‡∏¢                          | [QLoRA Paper](https://arxiv.org/abs/2305.14314)                           | [QLoRA Colab](https://colab.research.google.com/drive/1VoYNfYdk7zLVRWj8DHRcvcK) |
| FlashAttention                 | Attention ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏ç‡πà                                   | [FlashAttention Paper](https://arxiv.org/abs/2205.14135)                  | [FlashAttention Code](https://github.com/Dao-AILab/flash-attention)     |
| Prompt Engineering             | ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö prompt ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ LLM ‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡πÉ‡∏ä‡πâ few-shot examples                        | [Prompt Guide](https://huggingface.co/docs/transformers/tasks/prompting)  | [Prompt Example](https://github.com/huggingface/notebooks/blob/main/examples/prompt_engineering.ipynb) |

### 10.4 ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ (Tools)

| ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠                      | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                   | ‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏´‡∏•‡∏±‡∏Å                                                                         | ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á                                                      |
| :----------------------------- | :----------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------- | :-------------------------------------------------------------------- |
| DeepSpeed                      | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏à‡∏≤‡∏Å Microsoft ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞ inference ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà                              | [DeepSpeed](https://www.deepspeed.ai/)                                           | [DeepSpeed Examples](https://github.com/microsoft/DeepSpeed/tree/master/examples) |
| vLLM                           | ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ inference ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö PagedAttention                                       | [vLLM](https://vllm.ai/)                                                         | [vLLM Examples](https://github.com/vllm-project/vllm/tree/main/examples)  |
| Unsloth                        | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ fine-tuning ‡πÅ‡∏•‡∏∞ quantization ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥                       | [Unsloth](https://github.com/unslothai/unsloth)                                  | [Unsloth Colab](https://colab.research.google.com/drive/1zB1t1qFO5n4bdnqP4KauS2sV_lPtP2Q) |
| BitsAndBytes                   | ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö quantization ‡πÄ‡∏ä‡πà‡∏ô 4-bit ‡∏´‡∏£‡∏∑‡∏≠ 8-bit                                        | [BitsAndBytes](https://github.com/TimDettmers/bitsandbytes)                      | [Quantization Colab](https://colab.research.google.com/drive/1VoYNfYdk7zLVRWj8DHRcvcK) |
| Colossal-AI                    | ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö parallelism ‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö                                  | [Colossal-AI](https://www.colossalai.org/)                                       | [Colossal-AI Examples](https://github.com/hpcaitech/ColossalAI/tree/main/examples) |

### 10.5 Framework

| Framework                      | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                   | ‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏´‡∏•‡∏±‡∏Å                                                                         | ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á                                                      |
| :----------------------------- | :----------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------- | :-------------------------------------------------------------------- |
| Hugging Face Transformers      | Framework ‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô LLM ‡πÄ‡∏ä‡πà‡∏ô BERT, GPT, Llama                                 | [Transformers](https://huggingface.co/docs/transformers/index)                   | [Transformers Examples](https://github.com/huggingface/transformers/tree/main/examples) |
| PyTorch                        | Framework ‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤ LLM ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏™‡∏π‡∏á                                   | [PyTorch](https://pytorch.org/)                                                  | [PyTorch Tutorials](https://pytorch.org/tutorials/)                     |
| TensorFlow                     | Framework ‡∏≠‡∏µ‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å LLM ‡πÅ‡∏°‡πâ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö LLM ‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ PyTorch                       | [TensorFlow](https://www.tensorflow.org/)                                        | [TF Examples](https://github.com/tensorflow/models/tree/master/official/nlp) |
| LangChain                      | Framework ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏î‡πâ‡∏ß‡∏¢ LLM ‡πÄ‡∏ä‡πà‡∏ô RAG ‡∏´‡∏£‡∏∑‡∏≠ agents               | [LangChain](https://python.langchain.com/docs/get_started/introduction)          | [LangChain Templates](https://github.com/langchain-ai/langchain/tree/master/templates) |
| LlamaIndex                     | Framework ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° LLM ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ                                    | [LlamaIndex](https://docs.llamaindex.ai/en/stable/)                              | [LlamaIndex Examples](https://github.com/run-llama/llama_index/tree/main/examples) |

### 10.6 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (How to Proceed)

1. **‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£:** ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏≠‡πà‡∏≤‡∏ô paper ‡πÄ‡∏ä‡πà‡∏ô "Attention Is All You Need" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô `[Beginner]`
2. **‡∏•‡∏≠‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:** ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ MLM ‡∏´‡∏£‡∏∑‡∏≠ autoregressive modeling ‡∏î‡πâ‡∏ß‡∏¢ Hugging Face `[Intermediate]`
3. **‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏û‡∏¥‡πÄ‡∏®‡∏©:** ‡∏ó‡∏î‡∏•‡∏≠‡∏á LoRA ‡∏´‡∏£‡∏∑‡∏≠ FlashAttention ‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á `[Intermediate/Advanced]`
4. **‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠:** ‡πÉ‡∏ä‡πâ DeepSpeed ‡∏´‡∏£‡∏∑‡∏≠ vLLM ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡πÉ‡∏´‡∏ç‡πà ‡πÅ‡∏•‡∏∞ Unsloth ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡πÄ‡∏•‡πá‡∏Å `[Advanced]`
5. **‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏î‡πâ‡∏ß‡∏¢ Framework:** ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏î‡πâ‡∏ß‡∏¢ LangChain ‡∏´‡∏£‡∏∑‡∏≠‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ PyTorch `[Intermediate/Advanced]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ö‡∏ô Colab ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ GPU ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
- ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏´‡∏£‡∏∑‡∏≠ Framework ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡πá‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
- ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏¢‡∏∞ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡∏á‡∏Å‡∏≤‡∏£ LLM ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏£‡πá‡∏ß

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 11: ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ Model AI, Dataset ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡πÅ‡∏•‡∏∞‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô LLM ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå*

### 11.1 ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ Model AI (Choosing an AI Model)

| ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢                          | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                   | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•                                                                 |
| :----------------------------- | :----------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------- |
| ‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• (Model Size)         | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏ç‡πà (‡πÄ‡∏ä‡πà‡∏ô 70B parameters) ‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏î‡∏µ‡πÅ‡∏ï‡πà‡πÉ‡∏ä‡πâ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏°‡∏≤‡∏Å ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£ | ‡πÉ‡∏´‡∏ç‡πà: Llama 3 (70B), ‡πÄ‡∏•‡πá‡∏Å: Phi-3 (3.8B)                                     |
| ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (Task)           | ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏≤‡∏°‡∏á‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤, ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•, ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î                                      | ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤: Grok, ‡πÅ‡∏õ‡∏•: mBART, ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î: CodeLlama                              |
| ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏û‡∏¥‡πÄ‡∏®‡∏© (Specialization) | ‡∏ö‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡∏ù‡∏∂‡∏Å‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏á‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡πÄ‡∏ä‡πà‡∏ô ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå                              | ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢: OpenThaiGPT, ‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå: BioGPT                                      |
| ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Availability) | ‡πÇ‡∏°‡πÄ‡∏î‡∏• open-source ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ü‡∏£‡∏µ ‡πÅ‡∏ï‡πà‡∏ö‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡πÄ‡∏á‡∏¥‡∏ô                         | Open-source: Mistral 7B, ‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠: Llama 3                                     |
| ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ (Resources)      | ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ GPU ‡∏ô‡πâ‡∏≠‡∏¢ ‡∏≠‡∏≤‡∏à‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà quantized ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏•‡πá‡∏Å                                      | Quantized: GPTQ Llama 2, ‡πÄ‡∏•‡πá‡∏Å: TinyLlama                                    |

**‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö:**
- ‡∏ñ‡πâ‡∏≤‡∏á‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏•‡πá‡∏Å ‡πÄ‡∏ä‡πà‡∏ô Phi-3 ‡∏´‡∏£‡∏∑‡∏≠ Mistral 7B
- ‡πÉ‡∏ä‡πâ Hugging Face Model Hub ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•: [Hugging Face Models](https://huggingface.co/models)

### 11.2 ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ Dataset (Choosing a Dataset)

| ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢                          | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                                                   | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Dataset                                                             |
| :----------------------------- | :----------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------- |
| ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Size)           | ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏¢‡∏≠‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏•‡∏∞‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å                           | ‡πÉ‡∏´‡∏ç‡πà: The Pile (800GB), ‡πÄ‡∏•‡πá‡∏Å: TinyStories (1GB)                             |
| ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Quality)         | ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î bias ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û                            | ‡∏™‡∏∞‡∏≠‡∏≤‡∏î: Alpaca, ‡∏°‡∏µ noise: OpenWebText                                         |
| ‡∏†‡∏≤‡∏©‡∏≤ (Language)               | ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô ‡πÑ‡∏ó‡∏¢ ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤                                      | ‡πÑ‡∏ó‡∏¢: Thai National Corpus, ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©: C4, ‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤: Multilingual C4             |
| ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå (Purpose)         | Pre-training ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ Instruction tuning ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏π‡πà‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°-‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö                        | Pre-training: Wikipedia, Instruction: Dolly 15k                              |
| ‡∏•‡∏¥‡∏Ç‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå (Licensing)         | ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ü‡∏£‡∏µ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢                           | ‡∏ü‡∏£‡∏µ: Common Crawl, ‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠: BooksCorpus                                       |

**‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö:**
- ‡∏´‡∏≤‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Hugging Face Datasets: [Hugging Face Datasets](https://huggingface.co/datasets)
- ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏à‡∏≥‡∏Å‡∏±‡∏î ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ data augmentation ‡∏´‡∏£‡∏∑‡∏≠ synthetic data ‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≤‡∏Å GPT

### 11.3 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ (Other Key Concepts)

| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå/‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î                 | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢                                                                                   |
| :----------------------------- | :----------------------------------------------------------------------------------------- |
| Overfitting                    | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏à‡∏ô‡πÑ‡∏°‡πà generalized ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà                           |
| Underfitting                   | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏ï‡πà‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö                     |
| Epoch                          | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ù‡∏∂‡∏Å‡∏ú‡πà‡∏≤‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏Ñ‡πà‡∏≤‡πÄ‡∏¢‡∏≠‡∏∞‡πÄ‡∏Å‡∏¥‡∏ô‡∏≠‡∏≤‡∏à overfitting                       |
| Batch Size                     | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å ‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡∏ç‡πà‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏°‡∏≤‡∏Å ‡∏Ñ‡πà‡∏≤‡πÄ‡∏•‡πá‡∏Å‡∏ù‡∏∂‡∏Å‡∏ô‡∏≤‡∏ô                 |
| Learning Rate                  | ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡∏£‡∏±‡∏ö‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å ‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÅ‡∏°‡πà‡∏ô ‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ä‡πâ‡∏≤‡πÅ‡∏ï‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥              |
| Zero-shot Learning             | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ù‡∏∂‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏° ‡πÄ‡∏ä‡πà‡∏ô GPT-3 ‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡πÉ‡∏´‡∏°‡πà                     |
| Few-shot Learning              | ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏°‡πà‡∏Å‡∏µ‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏´‡∏°‡πà ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á fine-tune ‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö            |
| Transfer Learning              | ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ‡∏á‡∏≤‡∏ô‡∏≠‡∏∑‡πà‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡πÉ‡∏ä‡πâ BERT ‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°                     |
| Hyperparameter Tuning          | ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô learning rate ‡∏´‡∏£‡∏∑‡∏≠ batch size ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î                   |

### 11.4 ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

| ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠                          | ‡∏•‡∏¥‡∏á‡∏Å‡πå/‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                                                                 |
| :----------------------------- | :-------------------------------------------------------------------------------- |
| ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•                | [Hugging Face Model Selection](https://huggingface.co/docs/transformers/model_doc) |
| ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Dataset ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥         | [Awesome Datasets](https://github.com/huggingface/datasets/wiki)                  |
| ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå ML ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô             | [ML Glossary](https://developers.google.com/machine-learning/glossary)            |

### 11.5 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (How to Proceed)

1. **‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢:** ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£ ‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞ `[Beginner]`
2. **‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏•‡πá‡∏Å:** ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á Mistral 7B ‡∏´‡∏£‡∏∑‡∏≠ Phi-3 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏ç‡πà `[Intermediate]`
3. **‡∏´‡∏≤ Dataset ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞:** ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô Alpaca ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö instruction tuning `[Intermediate]`
4. **‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á:** ‡∏•‡∏≠‡∏á fine-tune ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö hyperparameter ‡πÄ‡∏ä‡πà‡∏ô batch size `[Intermediate/Advanced]`
5. **‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•:** ‡πÉ‡∏ä‡πâ metric ‡πÄ‡∏ä‡πà‡∏ô BLEU ‡∏´‡∏£‡∏∑‡∏≠ accuracy ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà `[Advanced]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏™‡πÄ‡∏Å‡∏•‡πÄ‡∏•‡πá‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡∏Ç‡∏¢‡∏≤‡∏¢‡πÑ‡∏õ‡πÉ‡∏´‡∏ç‡πà
- ‡∏ñ‡πâ‡∏≤‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏à‡∏≥‡∏Å‡∏±‡∏î ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà quantized ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å
- ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÄ‡∏ä‡πà‡∏ô README ‡∏ö‡∏ô Hugging Face) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏ß‡πâ‡πÉ‡∏ô query ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô ‡∏ã‡∏∂‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• AI, ‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Å‡πÅ‡∏•‡∏∞‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ, ‡∏ú‡∏π‡πâ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•, ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÉ‡∏´‡∏ç‡πà‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢:

---
## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 12: ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•


## 12.1 ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• AI (Model Categories)

‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡πÑ‡∏î‡πâ:

### **Multimodal**
‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°, ‡∏†‡∏≤‡∏û, ‡πÄ‡∏™‡∏µ‡∏¢‡∏á:
- **Audio-Text-to-Text**: ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
- **Image-Text-to-Text**: ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏û‡∏¥‡πà‡∏°
- **Visual Question Answering (VQA)**: ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô "‡∏£‡∏ñ‡πÉ‡∏ô‡∏†‡∏≤‡∏û‡∏™‡∏µ‡∏≠‡∏∞‡πÑ‡∏£?"
- **Document Question Answering**: ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å PDF
- **Video-Text-to-Text**: ‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
- **Visual Document Retrieval**: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô ‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤
- **Any-to-Any**: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÑ‡∏õ‡∏™‡∏π‡πà‡∏≠‡∏µ‡∏Å‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û ‡∏´‡∏£‡∏∑‡∏≠‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á

### **Computer Vision**
‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠:
- **Depth Estimation**: ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÉ‡∏ô‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡πÉ‡∏ô‡∏†‡∏≤‡∏û‡∏ñ‡πà‡∏≤‡∏¢
- **Image Classification**: ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏†‡∏≤‡∏û "‡πÅ‡∏°‡∏ß" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏´‡∏°‡∏≤"
- **Object Detection**: ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÉ‡∏ô‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô ‡∏ß‡∏á‡∏Å‡∏•‡∏°‡∏£‡∏≠‡∏ö‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå‡πÉ‡∏ô‡∏†‡∏≤‡∏û
- **Image Segmentation**: ‡πÅ‡∏ö‡πà‡∏á‡∏†‡∏≤‡∏û‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏¢‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏
- **Text-to-Image**: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô "‡∏ß‡∏≤‡∏î‡∏†‡∏≤‡∏û‡∏ö‡πâ‡∏≤‡∏ô‡∏™‡∏µ‡πÅ‡∏î‡∏á"
- **Image-to-Text**: ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡πà‡∏≤‡∏ô‡∏õ‡πâ‡∏≤‡∏¢‡πÉ‡∏ô‡∏†‡∏≤‡∏û (OCR)
- **Image-to-Image**: ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏°‡πà ‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏†‡∏≤‡∏û‡∏Ç‡∏≤‡∏ß‡∏î‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏™‡∏µ
- **Image-to-Video**: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô ‡∏†‡∏≤‡∏û‡∏ô‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏ä‡∏±‡∏ô
- **Unconditional Image Generation**: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç ‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏™‡∏∏‡πà‡∏°‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• generative
- **Video Classification**: ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ ‡πÄ‡∏ä‡πà‡∏ô ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ô‡∏µ‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö "‡∏Å‡∏µ‡∏¨‡∏≤" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥"
- **Text-to-Video**: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô "‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏Ñ‡∏ô‡πÄ‡∏î‡∏¥‡∏ô‡πÉ‡∏ô‡∏™‡∏ß‡∏ô"
- **Zero-Shot Image Classification**: ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏°‡πà‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
- **Mask Generation**: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏°‡∏≤‡∏™‡∏Å‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏∞‡∏ö‡∏∏‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô "‡∏Ñ‡∏ô" ‡πÉ‡∏ô‡∏†‡∏≤‡∏û
- **Zero-Shot Object Detection**: ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÉ‡∏´‡∏°‡πà‡πÜ ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏±‡πâ‡∏ô
- **Text-to-3D**: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• 3 ‡∏°‡∏¥‡∏ï‡∏¥‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô "‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• 3D ‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå"
- **Image-to-3D**: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• 3 ‡∏°‡∏¥‡∏ï‡∏¥‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û 2D ‡πÄ‡∏õ‡πá‡∏ô 3D
- **Image Feature Extraction**: ‡∏î‡∏∂‡∏á‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏∞‡∏ö‡∏∏‡∏™‡∏µ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡πÄ‡∏î‡πà‡∏ô‡πÜ
- **Keypoint Detection**: ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏ï‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå

### **Natural Language Processing (NLP)**
‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°:
- **Text Classification**: ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ "‡∏ö‡∏ß‡∏Å" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏•‡∏ö"
- **Token Classification**: ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏≥‡∏´‡∏£‡∏∑‡∏≠ token ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û" ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà (NER)
- **Table Question Answering**: ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô "‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?"
- **Question Answering**: ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô "‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏´‡∏•‡∏ß‡∏á‡∏Ç‡∏≠‡∏á‡πÑ‡∏ó‡∏¢‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?"
- **Zero-Shot Classification**: ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ù‡∏∂‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏±‡πâ‡∏ô‡πÜ
- **Translation**: ‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≤‡∏Å‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
- **Summarization**: ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏¢‡πà‡∏≠‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô‡∏•‡∏á
- **Feature Extraction**: ‡∏î‡∏∂‡∏á‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢
- **Text Generation**: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà ‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏±‡πâ‡∏ô
- **Text2Text Generation**: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏õ‡∏•
- **Fill-Mask**: ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô "‡∏â‡∏±‡∏ô ___ ‡∏ó‡∏µ‡πà‡∏ö‡πâ‡∏≤‡∏ô" -> "‡∏â‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡∏ö‡πâ‡∏≤‡∏ô"
- **Sentence Similarity**: ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡πÄ‡∏ä‡πà‡∏ô "‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ô‡∏µ‡πâ‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?"

### **Audio**
‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á:
- **Text-to-Speech (TTS)**: ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á
- **Text-to-Audio**: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
- **Automatic Speech Recognition (ASR)**: ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°
- **Audio-to-Audio**: ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏µ‡∏Å‡πÅ‡∏ö‡∏ö ‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ô‡πâ‡∏≥‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ä‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ç‡∏¥‡∏á
- **Audio Classification**: ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô "‡∏ô‡∏Å" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå"
- **Voice Activity Detection (VAD)**: ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡πÉ‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

### **Tabular**
‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏£‡∏≤‡∏á:
- **Tabular Classification**: ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤ "‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏£‡∏≤‡∏¢‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ã‡∏∑‡πâ‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"
- **Tabular Regression**: ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏à‡∏≤‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢

### **Time Series Forecasting**
‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏≤‡∏Ñ‡∏≤‡∏´‡∏∏‡πâ‡∏ô

### **Reinforcement Learning**
‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏ö‡∏ö‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏Å‡∏≥‡∏•‡∏±‡∏á:
- **Robotics**: ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏´‡∏∏‡πà‡∏ô‡∏¢‡∏ô‡∏ï‡πå ‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏≠‡∏ô‡∏´‡∏∏‡πà‡∏ô‡∏¢‡∏ô‡∏ï‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏î‡∏¥‡∏ô

### **Graph Machine Learning**
‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏™‡∏±‡∏á‡∏Ñ‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏°‡πÄ‡∏•‡∏Å‡∏∏‡∏•

---

## 12.2 ‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Å‡πÅ‡∏•‡∏∞‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ (Frameworks and Libraries)

‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• AI:

- **PyTorch**: ‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Å‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢ ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô
- **TensorFlow**: ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô production ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà
- **JAX**: ‡πÄ‡∏ô‡πâ‡∏ô‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏π‡πà‡∏Ç‡∏ô‡∏≤‡∏ô
- **Safetensors**: ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•
- **Transformers**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏à‡∏≤‡∏Å Hugging Face ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• NLP ‡πÅ‡∏•‡∏∞ Multimodal
- **PEFT (Parameter-Efficient Fine-Tuning)**: ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ô‡πâ‡∏≠‡∏¢‡∏•‡∏á
- **TensorBoard**: ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ visualize ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
- **GGUF**: ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô llama.cpp
- **Diffusers**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô generative ‡πÄ‡∏ä‡πà‡∏ô Text-to-Image
- **stable-baselines3**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö reinforcement learning
- **ONNX**: ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏•‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Å
- **sentence-transformers**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
- **ml-agents**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö reinforcement learning ‡πÉ‡∏ô Unity
- **TF-Keras**: Keras API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö TensorFlow
- **MLX**: ‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö machine learning ‡∏ö‡∏ô Apple Silicon
- **Adapters**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ adapters
- **setfit**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö few-shot learning
- **Keras**: API ‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
- **timm**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• Computer Vision
- **sample-factory**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö reinforcement learning ‡πÅ‡∏ö‡∏ö asynchronous
- **Flair**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NLP
- **Transformers.js**: Transformers ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö JavaScript
- **OpenVINO**: ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ optimize ‡πÅ‡∏•‡∏∞ deploy ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏ô Intel hardware
- **spaCy**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ NLP ‡∏ó‡∏µ‡πà‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
- **fastai**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö deep learning ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢
- **BERTopic**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö topic modeling
- **ESPnet**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö speech processing
- **Joblib**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö parallel computing
- **NeMo**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö conversational AI
- **Core ML**: ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏ô Apple devices
- **OpenCLIP**: ‡πÇ‡∏°‡πÄ‡∏î‡∏• CLIP ‡πÅ‡∏ö‡∏ö open-source
- **LiteRT**: (‡∏≠‡∏≤‡∏à‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á TensorFlow Lite) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏ô mobile
- **Rust**: ‡∏†‡∏≤‡∏©‡∏≤‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏ö‡∏≤‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ
- **Scikit-learn**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö machine learning ‡πÅ‡∏ö‡∏ö‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏°
- **fastText**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö text classification
- **KerasHub**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NLP ‡∏´‡∏£‡∏∑‡∏≠ CV (‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô KerasNLP/KerasCV)
- **speechbrain**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö speech processing
- **PaddlePaddle**: ‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Å‡∏à‡∏≤‡∏Å Baidu
- **Asteroid**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö audio source separation
- **Fairseq**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö sequence modeling
- **AllenNLP**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NLP
- **llamafile**: ‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Llama
- **Graphcore**: ‡∏Æ‡∏≤‡∏£‡πå‡∏î‡πÅ‡∏ß‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI
- **Stanza**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ NLP ‡∏à‡∏≤‡∏Å Stanford
- **paddlenlp**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ NLP ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PaddlePaddle
- **Habana**: ‡∏Æ‡∏≤‡∏£‡πå‡∏î‡πÅ‡∏ß‡∏£‡πå‡∏à‡∏≤‡∏Å Intel
- **SpanMarker**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NER (‡∏≠‡∏≤‡∏à‡∏à‡∏∞)
- **pyannote.audio**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö speaker diarization
- **unity-sentis**: ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ AI ‡πÉ‡∏ô Unity (‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô Sentis)
- **DDUF**: ‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡πÅ‡∏ô‡πà‡∏ä‡∏±‡∏î ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡πÄ‡∏â‡∏û‡∏≤‡∏∞


## 12.3 ‡∏ú‡∏π‡πâ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• (Inference Providers)

‡∏ú‡∏π‡πâ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÄ‡∏≠‡∏á:

- **Together AI**: ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• open-source
- **SambaNova**: ‡πÄ‡∏ô‡πâ‡∏ô‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô AI
- **Replicate**: ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô generative ‡πÄ‡∏ä‡πà‡∏ô Text-to-Image
- **fal**: ‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡πÅ‡∏ô‡πà‡∏ä‡∏±‡∏î ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏â‡∏û‡∏≤‡∏∞
- **HF Inference API**: API ‡∏à‡∏≤‡∏Å Hugging Face ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
- **Fireworks**: ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• generative ‡πÅ‡∏•‡∏∞ NLP
- **Hyperbolic**: ‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡πÅ‡∏ô‡πà‡∏ä‡∏±‡∏î
- **Nebius AI Studio**: ‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡πÅ‡∏ô‡πà‡∏ä‡∏±‡∏î
- **Novita**: ‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡πÅ‡∏ô‡πà‡∏ä‡∏±‡∏î
- **Misc**: ‡∏ú‡∏π‡πâ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏≠‡∏∑‡πà‡∏ô‡πÜ
- **Inference Endpoints**: ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏à‡∏≤‡∏Å Hugging Face ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö deploy ‡πÇ‡∏°‡πÄ‡∏î‡∏•
- **AutoTrain Compatible**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
- **text-generation-inference**: ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• text generation
- **Eval Results**: ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
- **Merge**: ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô


## 12.4 ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (File Formats and Data Tools)

‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:

- **Croissant**: ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö machine learning
- **Datasets**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏à‡∏≤‡∏Å Hugging Face ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ dataset
- **polars**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ dataframes ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
- **pandas**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏£‡∏≤‡∏á
- **Dask**: ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö parallel computing ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà
- **WebDataset**: ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà ‡πÄ‡∏ä‡πà‡∏ô ‡∏†‡∏≤‡∏û‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
- **Distilabel**: ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö distillation ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
- **Argilla**: ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö data annotation
- **FiftyOne**: ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ visualize ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ dataset ‡∏†‡∏≤‡∏û


## 12.5 ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (Additional Features)

‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•:

- **4-bit precision**: ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 4 ‡∏ö‡∏¥‡∏ï
- **8-bit precision**: ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 8 ‡∏ö‡∏¥‡∏ï
- **custom_code**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
- **text-embeddings-inference**: ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô text embeddings
- **Carbon Emissions**: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏•‡πà‡∏≠‡∏¢‡∏Ñ‡∏≤‡∏£‡πå‡∏ö‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
- **Mixture of Experts (MoE)**: ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏¢‡πà‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û

## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 13: ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏´‡∏°‡πà ‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà ‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏µ 2025

*‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏´‡∏°‡πà ‡πÜ ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏à‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ AI ‡πÅ‡∏•‡∏∞‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏ô‡∏±‡∏Å‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡∏ú‡∏π‡πâ‡∏™‡∏ô‡πÉ‡∏à‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡πâ‡∏≤‡∏ß‡∏ó‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏ô‡∏õ‡∏µ 2025*

---

### 13.1 ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (Key Code Resources)

‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏´‡∏•‡πà‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ AI ‡πÅ‡∏•‡∏∞‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå‡πÉ‡∏ô‡∏õ‡∏µ 2025:

- **Python**: ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô AI, Machine Learning ‡πÅ‡∏•‡∏∞ Data Science ‡∏î‡πâ‡∏ß‡∏¢‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏µ‡πà‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á ‡πÄ‡∏ä‡πà‡∏ô PyTorch, TensorFlow ‡πÅ‡∏•‡∏∞ Transformers
- **JavaScript/TypeScript**: ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏Ç‡πâ‡∏≤‡∏°‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏° ‡πÇ‡∏î‡∏¢ TypeScript ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏¥‡∏¢‡∏°‡πÉ‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£
- **Rust**: ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏ô‡πâ‡∏ô‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢
- **Go**: ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢ Google ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏π‡πà‡∏Ç‡∏ô‡∏≤‡∏ô

**‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:**
- [GeeksforGeeks](https://www.geeksforgeeks.org/) - ‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥
- [Stack Overflow](https://stackoverflow.com/) - ‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÇ‡∏•‡∏Å
- [GitHub](https://github.com/) - ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏£‡∏ß‡∏°‡πÇ‡∏Ñ‡πâ‡∏î open-source ‡πÅ‡∏•‡∏∞‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
- [Hugging Face](https://huggingface.co/) - ‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏∏‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡πÅ‡∏•‡∏∞‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô NLP, Computer Vision ‡πÅ‡∏•‡∏∞ Multimodal

**‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö:**
- ‡πÉ‡∏ä‡πâ GitHub ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏≥‡∏£‡∏ß‡∏à repository ‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏° ‡πÄ‡∏ä‡πà‡∏ô ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å Transformers ‡∏´‡∏£‡∏∑‡∏≠ Diffusers
- ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏ä‡∏∏‡∏°‡∏ä‡∏ô Stack Overflow ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç

---

### 13.2 ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏´‡∏°‡πà (Emerging Techniques)

‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏´‡∏°‡πà ‡πÜ ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô AI ‡πÉ‡∏ô‡∏õ‡∏µ 2025:

- **AI-Assisted Coding**: 
  - **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢**: ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏¢‡πà‡∏≤‡∏á GitHub Copilot, Amazon CodeWhisperer ‡πÅ‡∏•‡∏∞ Tabnine ‡πÉ‡∏ä‡πâ AI ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÇ‡∏Ñ‡πâ‡∏î ‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ö‡∏±‡πä‡∏Å
  - **‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå**: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
  - **‡∏•‡∏¥‡∏á‡∏Å‡πå**: [GitHub Copilot](https://github.com/features/copilot), [Amazon CodeWhisperer](https://aws.amazon.com/codewhisperer/)
- **Low-Code/No-Code Platforms**: 
  - **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢**: ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡πÄ‡∏ä‡πà‡∏ô OutSystems, Bubble ‡πÅ‡∏•‡∏∞ Microsoft Power Apps ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏°‡∏≤‡∏Å
  - **‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå**: ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏•‡∏î‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô
  - **‡∏•‡∏¥‡∏á‡∏Å‡πå**: [OutSystems](https://www.outsystems.com/), [Bubble](https://bubble.io/)
- **Quantum Computing**: 
  - **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢**: ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏ß‡∏≠‡∏ô‡∏ï‡∏±‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÉ‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏•‡∏Å‡∏∏‡∏•
  - **‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå**: ‡∏≠‡∏≤‡∏à‡∏õ‡∏è‡∏¥‡∏ß‡∏±‡∏ï‡∏¥‡∏á‡∏≤‡∏ô AI ‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï
  - **‡∏•‡∏¥‡∏á‡∏Å‡πå**: [IBM Quantum](https://www.ibm.com/quantum), [Google Quantum AI](https://quantumai.google/)

**‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö:**
- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ AI-Assisted Coding ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏° productivity ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ü‡∏£‡∏µ‡∏à‡∏≤‡∏Å GitHub
- ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Quantum Computing ‡∏•‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå‡∏à‡∏≤‡∏Å IBM

---

### 13.3 ‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà ‡πÜ (Emerging Trends)

‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÉ‡∏ô‡∏õ‡∏µ 2025:

- **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ (Green Tech)**:
  - **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢**: ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå‡∏ó‡∏µ‡πà‡∏•‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£ optimize ‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Green Coding
  - **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**: ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Carbon Emissions ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• AI (‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≤‡∏Å Hugging Face)
  - **‡∏•‡∏¥‡∏á‡∏Å‡πå**: [Green Software Foundation](https://greensoftware.foundation/)
- **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏ó‡∏≤‡∏á‡πÑ‡∏ã‡πÄ‡∏ö‡∏≠‡∏£‡πå (Cybersecurity)**:
  - **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢**: ‡∏Å‡∏≤‡∏£‡∏ú‡∏™‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (Security by Design) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏£‡∏±‡πà‡∏ß‡πÑ‡∏´‡∏•‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
  - **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**: ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ AI ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏±‡∏¢‡∏Ñ‡∏∏‡∏Å‡∏Ñ‡∏≤‡∏°‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå
  - **‡∏•‡∏¥‡∏á‡∏Å‡πå**: [OWASP](https://owasp.org/), [SANS Institute](https://www.sans.org/)
- **‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö Edge (Edge Computing)**:
  - **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢**: ‡∏Å‡∏≤‡∏£‡∏¢‡πâ‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô IoT devices ‡πÅ‡∏•‡∏∞‡∏™‡∏°‡∏≤‡∏£‡πå‡∏ó‡πÇ‡∏ü‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß
  - **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**: ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏ö‡∏ô‡∏™‡∏°‡∏≤‡∏£‡πå‡∏ó‡πÇ‡∏ü‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏π‡πâ‡∏à‡∏≥‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
  - **‡∏•‡∏¥‡∏á‡∏Å‡πå**: [Edge AI Insights](https://www.edge-ai-vision.com/)

**‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö:**
- ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Green Tech ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Carbon Emissions ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ú‡πà‡∏≤‡∏ô Hugging Face
- ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ Edge Computing ‡∏ú‡πà‡∏≤‡∏ô‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏à‡∏≤‡∏Å Edge AI Insights ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö IoT

---

### 13.4 ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (Additional Resources)

| **‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠**               | **‡∏•‡∏¥‡∏á‡∏Å‡πå/‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**                                      |
|--------------------------|-----------------------------------------------------------|
| ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡πÄ‡∏£‡∏µ‡∏¢‡∏ô AI ‡πÅ‡∏•‡∏∞ Coding | [Coursera](https://www.coursera.org/)                     |
| ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ   | [MIT Technology Review](https://www.technologyreview.com/) |
| ‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡∏ô‡∏±‡∏Å‡∏û‡∏±‡∏í‡∏ô‡∏≤          | [Reddit r/MachineLearning](https://www.reddit.com/r/MachineLearning/) |
| ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á AI          | [Kaggle](https://www.kaggle.com/)                         |
| ‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£ AI ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î       | [AI Weekly](https://www.aiweekly.co/)                    |

---

### 13.5 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (How to Proceed)

1. **‡∏™‡∏≥‡∏£‡∏ß‡∏à‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠**: ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ GitHub Copilot ‡∏´‡∏£‡∏∑‡∏≠ Low-Code Platforms ‡πÄ‡∏ä‡πà‡∏ô Bubble `[Beginner]`
2. **‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏´‡∏°‡πà**: ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏Ñ‡∏≠‡∏£‡πå‡∏™ Quantum Computing ‡∏à‡∏≤‡∏Å IBM ‡∏´‡∏£‡∏∑‡∏≠ Coursera `[Intermediate]`
3. **‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå**: ‡∏≠‡πà‡∏≤‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å MIT Technology Review ‡∏´‡∏£‡∏∑‡∏≠ AI Weekly ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î `[Intermediate]`
4. **‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ**: ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Edge Computing ‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå IoT ‡∏´‡∏£‡∏∑‡∏≠ optimize ‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡∏ï‡πà‡∏≠‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏° `[Advanced]`
5. **‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏ä‡∏∏‡∏°‡∏ä‡∏ô**: ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏° Kaggle ‡∏´‡∏£‡∏∑‡∏≠ Reddit ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ `[Beginner/Intermediate]`

**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:**
- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏á‡πà‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô GitHub ‡∏´‡∏£‡∏∑‡∏≠ Coursera
- ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠‡∏ú‡πà‡∏≤‡∏ô‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡πÅ‡∏•‡∏∞‡∏ä‡∏∏‡∏°‡∏ä‡∏ô
- ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏´‡∏°‡πà ‡πÜ ‡πÉ‡∏ô‡∏™‡πÄ‡∏Å‡∏•‡πÄ‡∏•‡πá‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡∏Ç‡∏¢‡∏≤‡∏¢‡πÑ‡∏õ‡∏™‡∏π‡πà‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÉ‡∏´‡∏ç‡πà

‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö **‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 14** ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏° Colab Notebooks ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI ‡πÅ‡∏•‡∏∞ Large Language Models (LLMs) ‡πÑ‡∏ß‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÄ‡∏ó‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ ‡πÇ‡∏î‡∏¢‡πÄ‡∏ô‡πâ‡∏ô‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° ‡πÅ‡∏•‡∏∞‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡πÉ‡∏´‡∏°‡πà‡πÜ ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ï‡πá‡∏°‡∏ó‡∏µ‡πà

---

<a name="section14"></a>
## üåü ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 14: ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏´‡∏°‡πà ‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà

‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏° **Colab Notebooks** ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö AI ‡πÅ‡∏•‡∏∞ Large Language Models (LLMs) ‡πÇ‡∏î‡∏¢‡πÄ‡∏ô‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤ ‡∏ó‡∏î‡∏•‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û

### 14.1 ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç

‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡∏Ç‡∏≠‡∏á Colab Notebooks ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å‡πÅ‡∏á‡πà‡∏°‡∏∏‡∏°‡∏Ç‡∏≠‡∏á AI ‡πÅ‡∏•‡∏∞ LLMs ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÑ‡∏õ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á:

- **The Large Language Model Course**  
  ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏° Colab Notebooks ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á LLMs ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô ‡πÑ‡∏õ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£ deploy ‡πÇ‡∏°‡πÄ‡∏î‡∏•  
  [Link](https://towardsdatascience.com/the-large-language-model-course-8e8e8e8e8e8e)

- **GitHub - philogicae/ai-notebooks-colab**  
  ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏° Colab Notebooks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Å‡∏±‡∏ö Stable Diffusion, LLMs ‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ AI ‡∏≠‡∏∑‡πà‡∏ô‡πÜ  
  [Link](https://github.com/philogicae/ai-notebooks-colab)

- **GitHub - amrzv/awesome-colab-notebooks**  
  ‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏≠‡∏á Colab Notebooks ‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏ä‡πà‡∏ô NSynth, LLMs, ‡πÅ‡∏•‡∏∞ Federated Learning  
  [Link](https://github.com/amrzv/awesome-colab-notebooks)

- **GitHub - mlabonne/llm-course**  
  ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏ó‡∏µ‡πà‡πÄ‡∏ô‡πâ‡∏ô LLMs ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡∏°‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏° roadmaps ‡πÅ‡∏•‡∏∞ Colab Notebooks ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£ fine-tune Llama 2, quantization, ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•  
  [Link](https://github.com/mlabonne/llm-course)

- **GitHub - JonusNattapong/Notebook-Git-Colab**  
  ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ AI ‡πÅ‡∏•‡∏∞ LLMs ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á notebooks, ‡∏Ñ‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå ‡πÅ‡∏•‡∏∞ datasets  
  [Link](https://github.com/JonusNattapong/Notebook-Git-Colab)

### 14.2 ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏´‡∏°‡πà

‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ô‡πâ‡∏ô Colab Notebooks ‡∏ó‡∏µ‡πà‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏´‡∏°‡πà‡πÜ ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ AI ‡πÅ‡∏•‡∏∞ LLMs:

- **Unsloth Notebooks**  
  Notebooks ‡∏ó‡∏µ‡πà‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£ fine-tune ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô Llama 3.1 ‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏à‡∏≤‡∏Å Unsloth  
  [Link](https://unsloth.ai/notebooks)

- **Axolotl - Documentation**  
  ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞ Colab Notebooks ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö distributed training ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ dataset formats  
  [Link](https://axolotl.ai/docs)

- **Mastering LLMs by Hamel Husain**  
  ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÅ‡∏•‡∏∞ notebooks ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö fine-tuning, RAG, evaluation ‡πÅ‡∏•‡∏∞ prompt engineering  
  [Link](https://hamelhusain.com/mastering-llms)

- **LoRA insights by Sebastian Raschka**  
  ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞ Colab Notebooks ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô LoRA (Low-Rank Adaptation) ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û  
  [Link](https://sebastianraschka.com/lora-insights)

### 14.3 ‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå‡πÉ‡∏´‡∏°‡πà

‡∏™‡∏≥‡∏£‡∏ß‡∏à‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£ AI ‡πÅ‡∏•‡∏∞ LLMs ‡∏ú‡πà‡∏≤‡∏ô Colab Notebooks ‡πÅ‡∏•‡∏∞‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:

- **Scaling test-time compute**  
  ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÅ‡∏•‡∏∞ notebooks ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏ç‡πà  
  [Link](https://towardsdatascience.com/scaling-test-time-compute-8e8e8e8e8e8e)

- **Preference alignment**  
  ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå ‡∏•‡∏î toxicity ‡πÅ‡∏•‡∏∞ hallucinations  
  [Link](https://towardsdatascience.com/preference-alignment-8e8e8e8e8e8e)

- **Multimodal Models**  
  ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó ‡πÄ‡∏ä‡πà‡∏ô ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏°‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô Colab  
  [Link](https://towardsdatascience.com/multimodal-models-8e8e8e8e8e8e)

### 14.4 ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô ‡∏¢‡∏±‡∏á‡∏°‡∏µ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏° Colab Notebooks ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å:

- **Google Colab Official**  
  ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏≤‡∏Å Google Colab ‡∏ó‡∏µ‡πà‡∏°‡∏µ notebooks ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞ tutorials  
  [Link](https://colab.google/notebooks)

- **Hugging Face Notebooks**  
  ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏° Colab Notebooks ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ Hugging Face transformers ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏ä‡πà‡∏ô sentiment analysis, text generation  
  [Link](https://huggingface.co/docs/transformers/notebooks)

- **Kaggle Notebooks**  
  ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏° notebooks ‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÇ‡∏•‡∏Å ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡πÅ‡∏•‡∏∞ datasets  
  [Link](https://www.kaggle.com/notebooks)

### 14.5 ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ ‡∏•‡∏≠‡∏á‡∏ó‡∏≥‡∏ï‡∏≤‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

- **‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏™‡∏ô‡πÉ‡∏à**: ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì  
- **‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Å‡∏±‡∏ö notebooks**: ‡πÉ‡∏ä‡πâ Colab Notebooks ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£  
- **‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÉ‡∏´‡∏°‡πà‡πÜ**: ‡∏≠‡πà‡∏≤‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞ papers ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î  
- **‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏ä‡∏∏‡∏°‡∏ä‡∏ô**: ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå ‡πÄ‡∏ä‡πà‡∏ô Reddit ‡∏´‡∏£‡∏∑‡∏≠ GitHub discussions ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ


## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=JonusNattapong/Notebook-Git-Colab&type=Date)](https://www.star-history.com/#JonusNattapong/Notebook-Git-Colab&Date)